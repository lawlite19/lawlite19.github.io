[{"title":"R树索引","date":"2022-03-27T03:38:15.000Z","path":"2022/03/27/R树索引/","text":"前言B树 B树是一棵平衡树，它是把一维直线分为若干段线段，当我们查找满足某个要求的点的时候，只要去查找它所属的线段即可。这种思想其实就是先找一个大的空间，再逐步缩小所要查找的空间，最终在一个自己设定的最小不可分空间内找出满足要求的解。 R树介绍 二维 R 树索引不同于传统的等级（一维）B 树索引。空间数据是二维的，所以无法使用 B 树索引组织空间数据。 同样，使用 R 树索引不能表示非空间数据。R 树是一种用矩形表示结点的树状结构来组织数据的访问方法。 R树数据结构 R树是B树在高维空间的扩展，是一棵平衡树。 每个R树的叶子结点包含了多个指向不同数据的指针，这些数据可以是存放在硬盘中的，也可以是存在内存中。 M 为一个节点中的最大条目数。取 m &lt;= M/2，约定此 m 为一个节点中的最小条目数。此时，R 树具有如下性质： 若叶节点不是根节点，则每个叶节点所包含的索引记录个数介于 m 与 M 之间； 对于叶节点中的索引记录（I，tuple-identifier），I 是其最小外包矩形； 若非叶节点不是根节点，则其中包含的子节点个数介于 m 与 M 之间； 对于非叶节点中的条目（I，child-pointer），I 表示能够覆盖其所有子节点的外包矩形的外包矩形。 根节点若非叶节点，则其至少有两个子节点。 所有叶子节点都在同一层。 代码实现##GeoTools实现 R树构建1234567891011121314151617181920UIManager.setLookAndFeel(UIManager.getCrossPlatformLookAndFeelClassName());// 显示打开shp文件的窗口File file = JFileDataStoreChooser.showOpenFile(\"shp\", null);if (file == null) &#123; return;&#125;STRtree stRtree = new STRtree();FileDataStore store = FileDataStoreFinder.getDataStore(file);SimpleFeatureSource featureSource = store.getFeatureSource();SimpleFeatureCollection features = featureSource.getFeatures();SimpleFeatureIterator featureIterator = features.features();while (featureIterator.hasNext()) &#123; SimpleFeature simpleFeature = featureIterator.next(); Geometry geometry = (Geometry) simpleFeature.getDefaultGeometry(); stRtree.insert(geometry.getEnvelopeInternal(), simpleFeature);&#125;// 构建RTreestRtree.build(); 查询12345// RTree查询Envelope envelope = new Envelope(new Coordinate(10, 20));List&lt;?&gt; result = stRtree.query(envelope);System.out.println(\"query size: \" + result.size());result.forEach(System.out::println); GeoTools实现说明STR算法 geotools中R树的实现使用的是STR算法， 对矩形的分组只考虑每个矩形的中心点，STR的基本思想是将所有的矩形分配到$\\left \\lceil r/n \\right \\rceil $（取上界）个分组中； 首先，对矩形按x坐标排序，然后划分成 $\\sqrt{r/n}$ 个slice； 然后，对slice内的矩形按y坐标排序，进一步划分成 $\\sqrt{r/n}$ 份； 最后递归的向上构建，直到根节点。 InsertstRtree.insert(Envelope itemEnv, Object item)时序调用如下 插入的一条记录为ItemBoundable 对象，包含一个Envelope和插入的数据 insert的数据实际就是叶子节点，RTree build的时候根据叶子节点向上构建。 Build stRtree.build();真正构建R树 createHigherLevels递归构建R树，递归结束的条件就是父节点只有一个，即为根节点 12345678private AbstractNode createHigherLevels(List boundablesOfALevel, int level) &#123; Assert.isTrue(!boundablesOfALevel.isEmpty()); List parentBoundables = createParentBoundables(boundablesOfALevel, level + 1); if (parentBoundables.size() == 1) &#123; return (AbstractNode) parentBoundables.get(0); &#125; return createHigherLevels(parentBoundables, level + 1);&#125; createParentBoundables，根据给定的子节点信息，获取父节点的信息 GeoTool中STRtree对象每个节点的子节点默认大小为10个 将子节点根据Envelope中心点按x轴排序，然后划分成 $\\sqrt{r/n}$ 个slice，比如r=288, n=10，即划分为6个slice，每个slice包含288/6=48个节点 1234567891011121314151617181920212223protected List createParentBoundables(List childBoundables, int newLevel) &#123; Assert.isTrue(!childBoundables.isEmpty()); int minLeafCount = (int) Math.ceil((childBoundables.size() / (double) getNodeCapacity())); ArrayList sortedChildBoundables = new ArrayList(childBoundables); Collections.sort(sortedChildBoundables, xComparator); List[] verticalSlices = verticalSlices(sortedChildBoundables, (int) Math.ceil(Math.sqrt(minLeafCount))); return createParentBoundablesFromVerticalSlices(verticalSlices, newLevel);&#125; private List createParentBoundablesFromVerticalSlices(List[] verticalSlices, int newLevel) &#123; Assert.isTrue(verticalSlices.length &gt; 0); List parentBoundables = new ArrayList(); for (int i = 0; i &lt; verticalSlices.length; i++) &#123; parentBoundables.addAll( createParentBoundablesFromVerticalSlice(verticalSlices[i], newLevel)); &#125; return parentBoundables;&#125; protected List createParentBoundablesFromVerticalSlice(List childBoundables, int newLevel) &#123; return super.createParentBoundables(childBoundables, newLevel);&#125; 其中super.createParentBoundables针对每个slice，按照y坐标排序，每10个节点划分到一个group中 其中父节点使用的是createNode(newLevel)创建，创建的为AbstractNode对象， 12345678910111213141516171819protected List createParentBoundables(List childBoundables, int newLevel) &#123; Assert.isTrue(!childBoundables.isEmpty()); ArrayList parentBoundables = new ArrayList(); parentBoundables.add(createNode(newLevel)); ArrayList sortedChildBoundables = new ArrayList(childBoundables); Collections.sort(sortedChildBoundables, getComparator()); for (Iterator i = sortedChildBoundables.iterator(); i.hasNext(); ) &#123; Boundable childBoundable = (Boundable) i.next(); if (lastNode(parentBoundables).getChildBoundables().size() == getNodeCapacity()) &#123; parentBoundables.add(createNode(newLevel)); &#125; lastNode(parentBoundables).addChildBoundable(childBoundable); &#125; return parentBoundables;&#125; protected AbstractNode lastNode(List nodes) &#123; return (AbstractNode) nodes.get(nodes.size() - 1);&#125; 父节点的Envelope对象计算方式如下，即遍历父节点对应的子节点，找到能将子节点包围住的矩形框 1234567891011121314151617181920212223242526272829303132333435363738protected Object computeBounds() &#123; Envelope bounds = null; for (Iterator i = getChildBoundables().iterator(); i.hasNext(); ) &#123; Boundable childBoundable = (Boundable) i.next(); if (bounds == null) &#123; bounds = new Envelope((Envelope)childBoundable.getBounds()); &#125; else &#123; bounds.expandToInclude((Envelope)childBoundable.getBounds()); &#125; &#125; return bounds;&#125; public void expandToInclude(Envelope other) &#123; if (other.isNull()) &#123; return; &#125; if (isNull()) &#123; minx = other.getMinX(); maxx = other.getMaxX(); miny = other.getMinY(); maxy = other.getMaxY(); &#125; else &#123; if (other.minx &lt; minx) &#123; minx = other.minx; &#125; if (other.maxx &gt; maxx) &#123; maxx = other.maxx; &#125; if (other.miny &lt; miny) &#123; miny = other.miny; &#125; if (other.maxy &gt; maxy) &#123; maxy = other.maxy; &#125; &#125; &#125; Query 先判断根节点是否是否包含 123456789101112protected List query(Object searchBounds) &#123; build(); ArrayList matches = new ArrayList(); if (isEmpty()) &#123; //Assert.isTrue(root.getBounds() == null); return matches; &#125; if (getIntersectsOp().intersects(root.getBounds(), searchBounds)) &#123; queryInternal(searchBounds, root, matches); &#125; return matches;&#125; 然后递归查找子节点 如上我们说的，insert的叶子节点是ItemBoundable对象，父节点是AbstractNode对象，根据此可以判断是否到达叶子节点 12345678910111213141516171819 private void queryInternal(Object searchBounds, AbstractNode node, List matches) &#123; List childBoundables = node.getChildBoundables(); for (int i = 0; i &lt; childBoundables.size(); i++) &#123; Boundable childBoundable = (Boundable) childBoundables.get(i); if (! getIntersectsOp().intersects(childBoundable.getBounds(), searchBounds)) &#123; continue; &#125; if (childBoundable instanceof AbstractNode) &#123; queryInternal(searchBounds, (AbstractNode) childBoundable, matches); &#125; else if (childBoundable instanceof ItemBoundable) &#123; matches.add(((ItemBoundable)childBoundable).getItem()); &#125; else &#123; Assert.shouldNeverReachHere(); &#125; &#125;&#125; Reference https://www.codedump.info/post/20200609-btree-1/ https://desktop.arcgis.com/zh-cn/arcmap/10.3/manage-data/using-sql-with-gdbs/the-rtree-index.htm Guttman, A.; “R-trees: a dynamic index structure for spatial searching,” ACM, 1984, 14 STR: a simple and efficient algorithm for R-tree packing","comments":true,"tags":[]},{"title":"Ubuntu16.04安装Nvidia驱动cuda,cudnn和tensorflow-gpu","date":"2018-10-25T07:25:54.000Z","path":"2018/10/25/Ubuntu16.04安装Nvidia驱动cuda, cudnn和tensorflow-gpu/","text":"之前有在阿里云GPU服务器上弄过： 点击查看， 这里从装Nvidia开始一、 安装Nvidia驱动 1.1 查找需要安装的Nvidia版本1.1.1 官网 官网上查找： https://www.nvidia.com/Download/index.aspx?lang=en-us 这里是 GeForce GTX 1080 TI 如下图，推荐 410 版本的 1.1.2 命令行查看推荐驱动 查看驱动：ubuntu-drivers devices， 如下图 123456789101112ubuntu@ubuntu-System-Product-Name:~$ ubuntu-drivers devices== cpu-microcode.py ==driver : intel-microcode - distro free== /sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0 ==vendor : NVIDIA Corporationmodalias : pci:v000010DEd00001B06sv00001458sd0000374Dbc03sc00i00driver : nvidia-410 - third-party free recommendeddriver : nvidia-384 - distro non-freedriver : xserver-xorg-video-nouveau - distro free builtindriver : nvidia-390 - third-party freedriver : nvidia-396 - third-party free 注意这里添加了ppa, 若是没有，可能最新的只有nvidia-384， 但是若想安装cuda-9.0 需要大于384.81, 不然后面安装tensorflow-gpu 之后也会报错 图片对应网址：https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html 添加 ppa: sudo add-apt-repository ppa:graphics-drivers/ppa （注意联网，去掉代理） sudo apt update 然后执行ubuntu-drivers devices就可以看到如上的结果 安装： 可能需要的依赖：sudo apt install dkms build-essential linux-headers-generic 有些可能需要禁用nouveau模块，查看：https://blog.csdn.net/u012235003/article/details/54575758 sudo apt-get install linux-headers-$(uname -r) sudo apt install nvidia-410 重启机器 查看： nvidia-smi 显示如下结果 123456789101112131415161718192021(wangyongzhi_ml) ubuntu@ubuntu-System-Product-Name:/usr/local/cuda-10.0/bin$ nvidia-smiThu Oct 25 15:49:46 2018+-----------------------------------------------------------------------------+| NVIDIA-SMI 410.66 Driver Version: 410.66 CUDA Version: 10.0 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. ||===============================+======================+======================|| 0 GeForce GTX 108... Off | 00000000:01:00.0 On | N/A || 0% 44C P8 20W / 250W | 42MiB / 11174MiB | 0% Default |+-------------------------------+----------------------+----------------------+| 1 GeForce GTX 108... Off | 00000000:02:00.0 Off | N/A || 0% 50C P8 20W / 250W | 2MiB / 11178MiB | 0% Default |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes: GPU Memory || GPU PID Type Process name Usage ||=============================================================================|| 0 949 G /usr/lib/xorg/Xorg 39MiB |+-----------------------------------------------------------------------------+ 跑个程序的使用情况 1234567891011121314151617181920212223ubuntu@ubuntu-System-Product-Name:~$ nvidia-smiThu Oct 25 21:20:00 2018+-----------------------------------------------------------------------------+| NVIDIA-SMI 410.66 Driver Version: 410.66 CUDA Version: 10.0 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. ||===============================+======================+======================|| 0 GeForce GTX 108... Off | 00000000:01:00.0 On | N/A || 0% 53C P2 128W / 250W | 10776MiB / 11174MiB | 44% Default |+-------------------------------+----------------------+----------------------+| 1 GeForce GTX 108... Off | 00000000:02:00.0 Off | N/A || 0% 52C P8 21W / 250W | 10631MiB / 11178MiB | 0% Default |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes: GPU Memory || GPU PID Type Process name Usage ||=============================================================================|| 0 949 G /usr/lib/xorg/Xorg 39MiB || 0 3009 C python 10725MiB || 1 3009 C python 10619MiB |+-----------------------------------------------------------------------------+ 二、安装cuda 官网： https://developer.nvidia.com/cuda-toolkit-archive 选择想要安装的版本，这里选择的是cuda-9.0, 下载 安装 chmod +x cuda_9.0.176_384.81_linux-run sudo ./cuda_9.0.176_384.81_linux-run 根据提示安装选择即可 添加环境变量 vim ~/.bashrc 加入环境变量 123# cuda9.0export PATH=/usr/local/cuda-9.0/bin/:$PATH;export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64/:$LD_LIBRARY_PATH; 测试1 nvcc -V 如下图，版本为V9.0.17612345(wangyongzhi_ml) ubuntu@ubuntu-System-Product-Name:~/wangyongzhi/software$ nvcc -Vnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2017 NVIDIA CorporationBuilt on Fri_Sep__1_21:08:03_CDT_2017Cuda compilation tools, release 9.0, V9.0.176 测试2 如果上面安装过程中选择了安装Examples, 会在 ~ 文件夹下生成测试NVIDIA_CUDA-9.0_Samples 的文件 进入： cd NVIDIA_CUDA-9.0_Samples make 进入 NVIDIA_CUDA-9.0_Samples/bin/x86_64/linux/release 文件夹 执行： ./deviceQuery, 可以看到类似如下信息 123456789101112131415161718192021222324./deviceQuery Starting... CUDA Device Query (Runtime API) version (CUDART static linking)Detected 2 CUDA Capable device(s)Device 0: &quot;GeForce GTX 1080 Ti&quot; CUDA Driver Version / Runtime Version 10.0 / 9.0 CUDA Capability Major/Minor version number: 6.1 Total amount of global memory: 11174 MBytes (11717181440 bytes) (28) Multiprocessors, (128) CUDA Cores/MP: 3584 CUDA Cores GPU Max Clock rate: 1683 MHz (1.68 GHz) Memory Clock rate: 5505 Mhz Memory Bus Width: 352-bit L2 Cache Size: 2883584 bytes Maximum Texture Dimension Size (x,y,z) 1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384) Maximum Layered 1D Texture Size, (num) layers 1D=(32768), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(32768, 32768), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 2048 Maximum number of threads per block: 1024 三、安装cudnn 官网：https://developer.nvidia.com/rdp/cudnn-download 选择cuda对应的版本, 我的选择如下图 安装 tar -zxvf cudnn-9.0-linux-x64-v7.3.1.20.tgz 将解压得到的cuda 文件夹下的内容拷贝到对应的 /usr/local/cuda-9.0文件夹下即可 四、安装Anaconda和tensorflow-gpu 官网： https://www.anaconda.com/download/#linux 下载安装即可，我这里选择的是 python3.7 版本 安装之后添加到环境变量： 12# anaconda3export PATH=/home/ubuntu/anaconda3/bin:$PATH 创建虚拟环境，防止污染他人使用环境 conda create -n xxx python-3.6 conda install tensorflow-gpu 测试 12import tensorflow as tfsess = tf.Session(config=tf.ConfigProto(log_device_placement=True)) 打印如下信息： 123456789101112131415161718192021222018-10-25 16:25:35.683507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties:name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683pciBusID: 0000:01:00.0totalMemory: 10.91GiB freeMemory: 10.72GiB2018-10-25 16:25:35.783459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2018-10-25 16:25:35.783843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 1 with properties:name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683pciBusID: 0000:02:00.0totalMemory: 10.92GiB freeMemory: 10.76GiB2018-10-25 16:25:35.784321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 12018-10-25 16:25:36.069610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:2018-10-25 16:25:36.069634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0 12018-10-25 16:25:36.069637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0: N Y2018-10-25 16:25:36.069639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1: Y N2018-10-25 16:25:36.069852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10367 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)2018-10-25 16:25:36.101498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10409 MB memory) -&gt; physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)Device mapping:/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1/job:localhost/replica:0/task:0/device:GPU:1 -&gt; device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.12018-10-25 16:25:36.134430: I tensorflow/core/common_runtime/direct_session.cc:288] Device mapping:/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1/job:localhost/replica:0/task:0/device:GPU:1 -&gt; device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1 五、 多个cuda版本切换 安装cuda-9.0 会在 /usr/local/ 目录下 如下图，它会创建一个软连接指向了 /usr/local/cuda-9.0/12345678910111213141516(wangyongzhi_ml) ubuntu@ubuntu-System-Product-Name:/usr/local$ ll总用量 48drwxr-xr-x 12 root root 4096 10月 25 14:51 ./drwxr-xr-x 13 root root 4096 10月 25 09:39 ../drwxr-xr-x 2 root root 4096 4月 21 2016 bin/lrwxrwxrwx 1 root root 19 10月 25 00:41 cuda -&gt; /usr/local/cuda-9.0/drwxr-xr-x 19 root root 4096 10月 25 14:52 cuda-10.0/drwxr-xr-x 18 root root 4096 10月 25 00:41 cuda-9.0/drwxr-xr-x 2 root root 4096 4月 21 2016 etc/drwxr-xr-x 2 root root 4096 4月 21 2016 games/drwxr-xr-x 2 root root 4096 4月 21 2016 include/drwxr-xr-x 4 root root 4096 4月 21 2016 lib/lrwxrwxrwx 1 root root 9 10月 24 14:52 man -&gt; share/man/drwxr-xr-x 2 root root 4096 4月 21 2016 sbin/drwxr-xr-x 8 root root 4096 4月 21 2016 share/drwxr-xr-x 2 root root 4096 4月 21 2016 src/ 所以正常安装cuda 其他版本，然后创建软连接指向对应的版本即可 12sudo rm -rf cudasudo ln -s /usr/local/cuda-10.0 /usr/local/cuda Reference https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html https://blog.csdn.net/u012235003/article/details/54575758","comments":true,"tags":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://lawlite.cn/tags/Tensorflow/"},{"name":"Cudnn","slug":"Cudnn","permalink":"http://lawlite.cn/tags/Cudnn/"}]},{"title":"Triplet-Loss原理及其实现","date":"2018-10-16T06:32:35.000Z","path":"2018/10/16/Triplet-Loss原理及其实现/","text":"一、 Triplet loss1、介绍 Triplet loss最初是在 FaceNet: A Unified Embedding for Face Recognition and Clustering 论文中提出的，可以学到较好的人脸的embedding 为什么不适用 softmax函数呢，softmax最终的类别数是确定的，而Triplet loss学到的是一个好的embedding，相似的图像在embedding空间里是相近的，可以判断是否是同一个人脸。2、原理 输入是一个三元组 &lt;a, p, n&gt; a： anchor p： positive, 与 a 是同一类别的样本 n： negative, 与 a 是不同类别的样本 公式是： $$L = max(d(a, p) - d(a, n) + margin, 0)$$ 所以最终的优化目标是拉近 a, p 的距离， 拉远 a, n 的距离 easy triplets: $L = 0$ 即 $d(a, p) +margin &lt; d(a, n)$，这种情况不需要优化，天然a, p的距离很近， a, n的距离远 hard triplets: $d(a, n) &lt; d(a, p)$, 即a, p的距离远 semi-hard triplets: $d(a, p) &lt; d(a, n) &lt; d(a, p) + margin$, 即a, n的距离靠的很近，但是有一个margin FaceNet 中是随机选取semi-hard triplets 进行训练的, （也可以选择 hard triplets 或者两者一起进行训练） 3、训练方法3.1 offline 训练集所有数据经过计算得到对应的 embeddings, 可以得到 很多&lt;i, j, k&gt; 的三元组，然后再计算 triplet loss 效率不高，因为需要过一遍所有的数据得到三元组，然后训练反向更新网络3.2 online 从训练集中抽取B个样本，然后计算 B 个embeddings，可以产生 $B^3$ 个 triplets （当然其中有不合法的，因为需要的是&lt;a, p, n&gt;） 实际使用中采用此方法，又分为两种策略 （是在一篇行人重识别的论文中提到的 In Defense of the Triplet Loss for Person Re-Identification），假设 $B = PK$, 其中P个身份的人，每个身份的人K张图片（一般K 取 4） Batch All: 计算batch_size中所有valid的的hard triplet 和 semi-hard triplet， 然后取平均得到Loss 注意因为很多 easy triplets的情况，所以平均会导致Loss很小，所以是对所有 valid 的所有求平均 （下面代码中会介绍） 可以产生 $PK(K-1)(PK-K)$个 triplets PK个 anchor K-1 个 positive PK-K 个 negative Batch Hard: 对于每一个anchor， 选择距离最大的d(a, p) 和 距离最大的 d(a, n) 所以公有 $PK$ 个 三元组triplets 二、 Tensorflow 中的实现 全部代码 Tensorflow 中有实现好的triplet loss 接口，这里自己实现，（实现起来还是有点绕的, 有一些小细节问题） 使用numpy也仿照实现了，便于调试查看中间的结果, 全部代码1、Batch All1.1 计算两两embeddings的距离 numpy 中的实现，便于调试理解， 点击查看 输入大小是（batch_size, vector_size）大小的 embeddings 向量 因为 $(a-b)^2 = a^2 -2ab + b^2$, 矩阵相乘 $embeddings \\times embeddings^T$ 中包含a*b的值，对象线上是向量平方的值，所以可以直接使用矩阵计算 如果不使用平方，就开根号， 注意根号下不能为0，0开根号是没有问题的，但是Tensorflow梯度反向传播是就会导致无穷大，所以加上一个平滑项1e-16，最后再修改回来。 12345678910111213141516171819202122232425def _pairwise_distance(embeddings, squared=False): ''' 计算两两embedding的距离 ------------------------------------------ Args： embedding: 特征向量， 大小（batch_size, vector_size） squared: 是否距离的平方，即欧式距离 Returns： distances: 两两embeddings的距离矩阵，大小 （batch_size, batch_size） ''' # 矩阵相乘,得到（batch_size, batch_size），因为计算欧式距离|a-b|^2 = a^2 -2ab + b^2, # 其中 ab 可以用矩阵乘表示 dot_product = tf.matmul(embeddings, tf.transpose(embeddings)) # dot_product对角线部分就是 每个embedding的平方 square_norm = tf.diag_part(dot_product) # |a-b|^2 = a^2 - 2ab + b^2 # tf.expand_dims(square_norm, axis=1)是（batch_size, 1）大小的矩阵，减去 （batch_size, batch_size）大小的矩阵，相当于每一列操作 distances = tf.expand_dims(square_norm, axis=1) - 2.0 * dot_product + tf.expand_dims(square_norm, axis=0) distances = tf.maximum(distances, 0.0) # 小于0的距离置为0 if not squared: # 如果不平方，就开根号，但是注意有0元素，所以0的位置加上 1e*-16 distances = distances + mask * 1e-16 distances = tf.sqrt(distances) distances = distances * (1.0 - mask) # 0的部分仍然置为0 return distances 1.2 计算valid mask numpy 中的实现， 点击查看 上面得到了 (batch_size, batch_size) 大小的距离矩阵，然后就可以计算所有 embeddings 组成的三元组&lt;i, j, k&gt;损失 但是不是所有的三元组都是 valid 的, 要是&lt;a, p, n&gt;的形式，所以计算一个3D的mask，然后乘上得到的 (batch_size, batch_size, batch_size)的所有三元组的损失即可，如何得到mask呢 &lt;i, j, k&gt;要满足 i, j, k不相等 labels[i] == labels[j] and labels[i] != labels[k] 123456789101112131415161718192021222324252627282930def _get_triplet_mask(labels): ''' 得到一个3D的mask [a, p, n], 对应triplet（a, p, n）是valid的位置是True ---------------------------------- Args: labels: 对应训练数据的labels, shape = (batch_size,) Returns: mask: 3D,shape = (batch_size, batch_size, batch_size) ''' # 初始化一个二维矩阵，坐标(i, j)不相等置为1，得到indices_not_equal indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool) indices_not_equal = tf.logical_not(indices_equal) # 因为最后得到一个3D的mask矩阵(i, j, k)，增加一个维度，则 i_not_equal_j 在第三个维度增加一个即，(batch_size, batch_size, 1), 其他同理 i_not_equal_j = tf.expand_dims(indices_not_equal, 2) i_not_equal_k = tf.expand_dims(indices_not_equal, 1) j_not_equal_k = tf.expand_dims(indices_not_equal, 0) # 想得到i!=j!=k, 三个不等取and即可, 最后可以得到当下标（i, j, k）不相等时才取True distinct_indices = tf.logical_and(tf.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k) # 同样根据labels得到对应i=j, i!=k label_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1)) i_equal_j = tf.expand_dims(label_equal, 2) i_equal_k = tf.expand_dims(label_equal, 1) valid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k)) # mask即为满足上面两个约束，所以两个3D取and mask = tf.logical_and(distinct_indices, valid_labels) return mask 1.3 计算triplet loss numpy 中的实现， 点击查看 1.1 中计算得到了两两embeddings的距离，大小 （batch_size, batch_size）, 需要得到所有三元组的triplet loss， 即（batch_size, batch_size, batch_size)大小 为什么triplet_loss = anchor_positive_dist - anchor_negative_dist + margin 可以得到所有(i, j, k)的triplet loss， 如下图，x0y平面的是anchor_positive_dist的距离矩阵（其实是3D的, 想象一下） x0z平面是anchor_negative_dist的距离矩阵（也是3D的） 两个相减, 比如0-0 = 0就相当于i=0, j=0的距离，减去 j=0, k=0的距离 以此类推，得到所有三元组的loss 123456789101112131415161718192021222324252627282930313233343536def batch_all_triplet_loss(labels, embeddings, margin, squared=False): ''' triplet loss of a batch ------------------------------- Args: labels: 标签数据，shape = （batch_size,） embeddings: 提取的特征向量， shape = (batch_size, vector_size) margin: margin大小， scalar Returns: triplet_loss: scalar, 一个batch的损失值 fraction_postive_triplets : valid的triplets占的比例 ''' # 得到每两两embeddings的距离，然后增加一个维度，一维需要得到（batch_size, batch_size, batch_size）大小的3D矩阵 # 然后再点乘上valid 的 mask即可 pairwise_dis = _pairwise_distance(embeddings, squared=squared) anchor_positive_dist = tf.expand_dims(pairwise_dis, 2) assert anchor_positive_dist.shape[2] == 1, \"&#123;&#125;\".format(anchor_positive_dist.shape) anchor_negative_dist = tf.expand_dims(pairwise_dis, 1) assert anchor_negative_dist.shape[1] == 1, \"&#123;&#125;\".format(anchor_negative_dist.shape) triplet_loss = anchor_positive_dist - anchor_negative_dist + margin mask = _get_triplet_mask(labels) mask = tf.to_float(mask) triplet_loss = tf.multiply(mask, triplet_loss) triplet_loss = tf.maximum(triplet_loss, 0.0) # 计算valid的triplet的个数，然后对所有的triplet loss求平均 valid_triplets = tf.to_float(tf.greater(triplet_loss, 1e-16)) num_positive_triplets = tf.reduce_sum(valid_triplets) num_valid_triplets = tf.reduce_sum(mask) fraction_postive_triplets = num_positive_triplets / (num_valid_triplets + 1e-16) triplet_loss = tf.reduce_sum(triplet_loss) / (num_positive_triplets + 1e-16) return triplet_loss, fraction_postive_triplets 2、Batch Hard numpy 中的实现，点击查看 因为最后只有$PK$个triplet, 从 positive 中选择距离最大的，从 negative 中选择距离最小的即可2.1 计算positive mask 满足 a!=p and a, p label一致即可 之后用mask 乘上计算的pairwice_distances， 然后取每行最大值即为每个样本对应 positive 的最大距离123456789101112131415def _get_anchor_positive_triplet_mask(labels): ''' 得到合法的positive的mask， 即2D的矩阵，[a, p], a!=p and a和p相同labels ------------------------------------------------ Args: labels: 标签数据，shape = (batch_size, ) Returns: mask: 合法的positive mask, shape = (batch_size, batch_size) ''' indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool) indices_not_equal = tf.logical_not(indices_equal) # （i, j）不相等 labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1)) # labels相等， mask = tf.logical_and(indices_not_equal, labels_equal) # 取and即可 return mask 2.2 计算negative mask 只需 [a, n] 对应的 labels 不一致即可12345678910111213def _get_anchor_negative_triplet_mask(labels): ''' 得到negative的2D mask, [a, n] 只需a, n不同且有不同的labels ------------------------------------------------ Args: labels: 标签数据，shape = (batch_size, ) Returns: mask: negative mask, shape = (batch_size, batch_size) ''' labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1)) mask = tf.logical_not(labels_equal) return mask 2.3 batch hard loss 计算最大 positive 距离时直接取 valid 的每一行的最大值即可 计算最小negative 距离时不能直接取每一行的最小值，因为 invalid 位置的值为 0，所以可以在 invalid 位置加上每一行的最大值，然后就可以取每一行的最小值了123456789101112131415161718192021222324252627282930def batch_hard_triplet_loss(labels, embeddings, margin, squared=False): ''' batch hard triplet loss of a batch， 每个样本最大的positive距离 - 对应样本最小的negative距离 ------------------------------------ Args: labels: 标签数据，shape = （batch_size,） embeddings: 提取的特征向量， shape = (batch_size, vector_size) margin: margin大小， scalar Returns: triplet_loss: scalar, 一个batch的损失值 ''' pairwise_distances = _pairwise_distance(embeddings) mask_anchor_positive = _get_anchor_positive_triplet_mask(labels) mask_anchor_positive = tf.to_float(mask_anchor_positive) anchor_positive_dist = tf.multiply(mask_anchor_positive, pairwise_distances) hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=1, keepdims=True) # 取每一行最大的值即为最大positive距离 tf.summary.scalar(\"hardest_positive_dis\", tf.reduce_mean(hardest_positive_dist)) '''取每一行最小值得时候，因为invalid [a, n]置为了0， 所以不能直接取，这里对应invalid位置加上每一行的最大值即可，然后再取最小的值''' mask_anchor_negative = _get_anchor_negative_triplet_mask(labels) mask_anchor_negative = tf.to_float(mask_anchor_negative) max_anchor_negative_dist = tf.reduce_max(pairwise_distances, axis=1, keepdims=True) # 每一样最大值 anchor_negative_dist = pairwise_distances + max_anchor_negative_dist * (1.0 - mask_anchor_negative) # (1.0 - mask_anchor_negative)即为invalid位置 hardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=1, keepdims=True) tf.summary.scalar(\"hardest_negative_dist\", tf.reduce_mean(hardest_negative_dist)) triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0) triplet_loss = tf.reduce_mean(triplet_loss) return triplet_loss 三、具体使用 使用 mnist 数据集和 triplet loss 训练，最后得到的 embeddings应该是同一类别的靠在一起 因为只有 10 个类别，所以直接随机取 batch 大小的数据，这里batch_size=64, 注意如果类别很多时，就不能随机构建batch 了， 需要选 P 个类别，然后每个类别选 K 张图 3.1 构建模型 上一篇介绍了 tensorflow的高级API, 这里使用 Estimator 构建模型 全部代码：点击查看3.1.1 使用Estimator params 指定超参数， 这里保存为json 格式的文件， 配置为： 123456789101112131415161718192021&#123; &quot;learning_rate&quot;: 1e-3, &quot;batch_size&quot;: 64, &quot;num_epochs&quot;: 20, &quot;num_channels&quot;: 32, &quot;use_batch_norm&quot;: false, &quot;bn_momentum&quot;: 0.9, &quot;margin&quot;: 0.5, &quot;embedding_size&quot;: 64, &quot;triplet_strategy&quot;: &quot;batch_all&quot;, &quot;squared&quot;: false, &quot;image_size&quot;: 28, &quot;num_labels&quot;: 10, &quot;train_size&quot;: 50000, &quot;eval_size&quot;: 10000, &quot;num_parallel_calls&quot;: 4, &quot;save_summary_steps&quot;: 50&#125; 1234567891011121314def main(argv): args = parser.parse_args(argv[1:]) tf.logging.info(\"创建模型....\") with open(args.model_config) as f: params = json.load(f) config = tf.estimator.RunConfig(model_dir=args.model_dir, tf_random_seed=100) # config cls = tf.estimator.Estimator(model_fn=my_model, config=config, params=params) # 建立模型 tf.logging.info(\"开始训练模型,共&#123;&#125; epochs....\".format(params['num_epochs'])) cls.train(input_fn = lambda: train_input_fn(args.data_dir, params)) # 训练模型，指定输入 tf.logging.info(\"测试集评价模型....\") res = cls.evaluate(input_fn = lambda: test_input_fn(args.data_dir, params)) # 测试模型，指定输入 for key in res: print(\"评价---&#123;&#125; : &#123;&#125;\".format(key, res[key])) 3.1.2 model_fn函数 下面都有对应注释 计算 embedding_mean_norm 中每一行 embeding 公式为： $||A||_F = [\\sum_{i,j} abs(a_{i,j})^2]^{1/2}$ , 然后再取均值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def my_model(features, labels, mode, params): ''' model_fn指定函数，构建模型，训练等 --------------------------------- Args: features: 输入，shape = (batch_size, 784) labels: 输出，shape = (batch_size, ) mode: str, 阶段 params: dict, 超参数 ''' is_training = (mode == tf.estimator.ModeKeys.TRAIN) images = features images = tf.reshape(images, shape=[-1, params['image_size'], params['image_size'], 1]) # reshape (batch_size, img_size, img_size, 1) with tf.variable_scope(\"model\"): embeddings = build_model(is_training, images, params) # 简历模型 if mode == tf.estimator.ModeKeys.PREDICT: # 如果是预测阶段，直接返回得到embeddings predictions = &#123;'embeddings': embeddings&#125; return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions) '''调用对应的triplet loss''' labels = tf.cast(labels, tf.int64) if params['triplet_strategy'] == 'batch_all': loss, fraction = batch_all_triplet_loss(labels, embeddings, margin=params['margin'], squared=params['squared']) elif params['triplet_strategy'] == 'batch_hard': loss = batch_hard_triplet_loss(labels, embeddings, margin=params['margin'], squared=params['squared']) else: raise ValueError(\"triplet_strategy 配置不正确: &#123;&#125;\".format(params['triplet_strategy'])) embedding_mean_norm = tf.reduce_mean(tf.norm(embeddings, axis=1)) # 这里计算了embeddings的二范数的均值 tf.summary.scalar(\"embedding_mean_norm\", embedding_mean_norm) with tf.variable_scope(\"metrics\"): eval_metric_ops = &#123;'embedding_mean_norm': tf.metrics.mean(embedding_mean_norm)&#125; if params['triplet_strategy'] == 'batch_all': eval_metric_ops['fraction_positive_triplets'] = tf.metrics.mean(fraction) if mode == tf.estimator.ModeKeys.EVAL: return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops) tf.summary.scalar('loss', loss) if params['triplet_strategy'] == \"batch_all\": tf.summary.scalar('fraction_positive_triplets', fraction) tf.summary.image('train_image', images, max_outputs=1) # 1代表1个channel optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate']) global_step = tf.train.get_global_step() if params['use_batch_norm']: '''如果使用BN，需要估计batch上的均值和方差，tf.get_collection(tf.GraphKeys.UPDATE_OPS)就可以得到 tf.control_dependencies计算完之后再进行里面的操作 ''' with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): train_op = optimizer.minimize(loss, global_step=global_step) else: train_op = optimizer.minimize(loss, global_step=global_step) return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op) 3.1.3 构建模型，得到embeddings12345678910111213141516171819202122232425262728def build_model(is_training, images, params): ''' 建立模型 ---------------------------- Args： is_training: bool, 是否是训练阶段，可以从mode中判断 images： (batch_size, 28*28*1), 输入mnist数据 params: dict, 一些超参数 Returns: out: 输出的embeddings, shape = (batch_size, 64) ''' num_channel = params['num_channels'] bn_momentum = params['bn_momentum'] channels = [num_channel, num_channel * 2] out = images for i, c in enumerate(channels): with tf.variable_scope(\"block_&#123;&#125;\".format(i)): out = tf.layers.conv2d(out, c, 3, padding='same') if params['use_batch_norm']: out = tf.layers.batch_normalization(out, momentum=bn_momentum, training=is_training) out = tf.nn.relu(out) out = tf.layers.max_pooling2d(out, 2, 2) assert out.shape[1:] == [7, 7, num_channel * 2] out = tf.reshape(out, [-1, 7*7*num_channel*2]) with tf.variable_scope(\"fc_1\"): out = tf.layers.dense(out, params['embedding_size']) return out 3.2 训练结果3.2.1 batch all python train_with_triplet_loss.py 可以在 tensorboard 中查看 tensorboard --logdir experiment/model/ embeddings_mean_norm [ 可以看到是上升的，因为我们要学到可分性好的 embeddings， 那么其方差应该是偏大的，均值应该是变大的 ] fraction positive 这个是收敛的，因为随着优化占的比例是越来越少 loss 注意这里的 loss 一般不是收敛的，因为是计算的 semi-hard 和 hard 的距离均值，因为每次是先选择出 semi-hard 和 hard 的 triplet, 那么上次优化后的可能就选择不到了，所以 loss 并不会收敛，但是fraction_postive_triplets 是收敛的，因为随着优化占的比例是越来越少的 3.2.2 batch hard embeddings mean norm positive and negative distance 这里我原以为应该是 negative 应该是增大的，positive 应该是减小的，但实际结果是 positive 也是增大的，因为我们计算 loss 是triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)， 只要 negative 的距离大于 positive + margin 就是 0 了，所以只要满足就行， 用BN 训练的效果可能更好一点。（有什么其他看法的可以交流一下） loss batch hard 的 loss 就应该是收敛的了 3.3 可视化embedding 全部代码： 点击查看 之前在 tensorflow 工具中使用过： 点击查看 这里将可视化 embeddings 的训练数据都放在 experiment/log文件夹下 另外我使用 tensorflow 1.11 出现问题，这里使用的版本是 tensorflow 1.10 加载训练的模型，预测得到embeddings 1234567891011121314args = parser.parse_args(argv[1:])with open(args.model_config) as f: params = json.load(f)tf.logging.info(\"创建模型....\")config = tf.estimator.RunConfig(model_dir=args.model_dir, tf_random_seed=100) # configcls = tf.estimator.Estimator(model_fn=my_model, config=config, params=params) # 建立模型tf.logging.info(\"预测....\")predictions = cls.predict(input_fn=lambda: test_input_fn(args.data_dir, params))embeddings = np.zeros((10000, params['embedding_size']))for i, p in enumerate(predictions): embeddings[i] = p['embeddings']tf.logging.info(\"embeddings shape: &#123;&#125;\".format(embeddings.shape)) 获得label数据，保存为 metadata.tsv文件 123456789with tf.Session() as sess: # Obtain the test labels dataset = mnist_dataset.test(args.data_dir) dataset = dataset.map(lambda img, lab: lab) dataset = dataset.batch(10000) labels_tensor = dataset.make_one_shot_iterator().get_next() labels = sess.run(labels_tensor) np.savetxt(os.path.join(args.log_dir, 'metadata.tsv'), labels, fmt='%d') 可视化embedding 123456789101112131415161718192021shutil.copy(args.sprite_filename, args.log_dir)'''可视化embeddings'''with tf.Session() as sess: # 1. Variable embedding_var = tf.Variable(embeddings, name=\"mnist_embeddings\") #tf.global_variables_initializer().run() # 不需要 # 2. 保存到文件中，embeddings.ckpt saver = tf.train.Saver() sess.run(embedding_var.initializer) saver.save(sess, os.path.join(args.log_dir, 'embeddings.ckpt')) # 3. 关联metadata.tsv, 和mnist_10k_sprite.png summary_writer = tf.summary.FileWriter(args.log_dir) config = projector.ProjectorConfig() embedding = config.embeddings.add() embedding.tensor_name = embedding_var.name embedding.metadata_path = 'metadata.tsv' embedding.sprite.image_path = 'mnist_10k_sprite.png' embedding.sprite.single_image_dim.extend([28, 28]) projector.visualize_embeddings(summary_writer, config) 3.3.1 batch all PCA 结果 3.3.2 batch hard Reference https://omoindrot.github.io/triplet-loss#batch-hard-strategy https://github.com/omoindrot/tensorflow-triplet-loss https://github.com/lawlite19/Blog-Back-Up https://github.com/omoindrot/tensorflow-triplet-loss/issues/6 FaceNet：https://arxiv.org/pdf/1503.03832.pdf Person Re-Identification： https://arxiv.org/pdf/1703.07737.pdf","comments":true,"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://lawlite.cn/tags/DeepLearning/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://lawlite.cn/tags/Tensorflow/"}]},{"title":"Tensorflow高级API","date":"2018-05-31T02:43:08.000Z","path":"2018/05/31/Tensorflow高级API/","text":"一、Estimator1、介绍 编程堆栈 Estimator：代表一个完整的模型。Estimator API 提供一些方法来训练模型、判断模型的准确率并生成预测。 数据集：构建数据输入管道。Dataset API 提供一些方法来加载和操作数据，并将数据馈送到您的模型中。Dataset API 与 Estimator API 合作无间 2、鸢尾花进行分类 数据集介绍：4个属性，分为3类： 花萼长度 花萼宽度 花瓣长度 花瓣宽度 品种（标签） 5.1 3.3 1.7 0.5 0（山鸢尾） 5.0 2.3 3.3 1.0 1（变色鸢尾） 6.4 2.8 5.6 2.2 2（维吉尼亚鸢尾） 网络模型 3、实现 Estimator 是 TensorFlow 对完整模型的高级表示。它会处理初始化、日志记录、保存和恢复等细节部分，并具有很多其他功能，以便您可以专注于模型。 3.1 预创建模型 完整代码：点击查看 导入包和参数配置 123456789import tensorflow as tfimport argparseimport iris_data# 超参数parser = argparse.ArgumentParser()parser.add_argument('--batch_size', default=100, type=int, help=\"batch size\")parser.add_argument('--train_steps', default=1000, type=int, help=\"number of training steps\") 构建模型 特征列：feature_column:特征列是一个对象，用于说明模型应该如何使用特征字典中的原始输入数据。在构建 Estimator 模型时，您会向其传递一个特征列的列表，其中包含您希望模型使用的每个特征。tf.feature_column 模块提供很多用于向模型表示数据的选项。 对于鸢尾花问题，4 个原始特征是数值，因此我们会构建一个特征列的列表，以告知 Estimator 模型将这 4 个特征都表示为 32 位浮点值。 实例化 Estimator: 使用的是预创建模型 cls = tf.estimator.DNNClassifier()模型 训练模型 cls.train(input_fn, hooks=None, steps=None, max_steps=None, saving_listeners=None)： input_fn指定输入的函数，包含 (features, labels) 的 tf.data.Dataset 类型的数据 steps 参数告知方法在训练多少步后停止训练。 评估经过训练的模型：eval_res = cls.evaluate(input_fn, steps=None, hooks=None, checkpoint_path=None, name=None) 输入和训练数据一致 返回的有{&#39;accuracy&#39;: 1.0, &#39;loss&#39;: 3.936471, &#39;average_loss&#39;: 0.1312157, &#39;global_step&#39;: 100} 预测: predictions = cls.predict(input_fn, predict_keys=None, hooks=None, checkpoint_path=None, yield_single_examples=True) 输入数据为 batch_size 的测试数据，不包含 label，返回生成器结果 1234567891011121314151617181920212223242526272829303132333435def main(argv): args = parser.parse_args(argv[1:]) # 加载数据， pandas类型 (train_x, train_y), (test_x, test_y) = iris_data.load_data() # feature columns描述如何使用输入数据 my_feature_columns = [] for key in train_x.keys(): my_feature_columns.append(tf.feature_column.numeric_column(key = key)) # 建立模型 cls = tf.estimator.DNNClassifier(hidden_units=[10,10], feature_columns=my_feature_columns, n_classes=3) # 训练模型 cls.train(input_fn=lambda:iris_data.train_input_fn(train_x, train_y, args.batch_size), steps=args.train_steps) # 评价模型 eval_res = cls.evaluate(input_fn=lambda:iris_data.eval_input_fn(test_x, test_y, args.batch_size)) print(\"\\n Test Set accuracy: &#123;:0.3f&#125;\\n\".format(eval_res['accuracy'])) # 预测 expected = ['Setosa', 'Versicolor', 'Virginica'] predict_x = &#123; 'SepalLength': [5.1, 5.9, 6.9], 'SepalWidth': [3.3, 3.0, 3.1], 'PetalLength': [1.7, 4.2, 5.4], 'PetalWidth': [0.5, 1.5, 2.1], &#125; predictions = cls.predict(input_fn=lambda:iris_data.eval_input_fn(predict_x, labels=None, batch_size=args.batch_size)) template = ('\\n Prediction is \"&#123;&#125;\" (&#123;:.1f&#125;%), expected \"&#123;&#125;\"' ) for pred_dict, expec in zip(predictions, expected): class_id = pred_dict['class_ids'][0] prob = pred_dict['probabilities'][class_id] print(template.format(iris_data.SPECIES[class_id], 100*prob, expec)) 运行函数 tf.app.run(main=main)会先解析命令行参数,然后执行main函数123if __name__ == \"__main__\": tf.logging.set_verbosity(tf.logging.INFO) tf.app.run(main=main) 保存和加载模型 指定模型地址即可：model_dir,在第一次训练时会保存模型 如果未在 Estimator 的构造函数中指定 model_dir，则 Estimator 会将检查点文件写入由 Python 的 tempfile.mkdtemp 函数选择的临时目录中,可以print(classifier.model_dir)查看 检查点频率： 默认 每 10 分钟（600 秒）写入一个检查点。 在 train 方法开始（第一次迭代）和完成（最后一次迭代）时写入一个检查点。 只在目录中保留 5 个最近写入的检查点。 自己配置：123456my_checkpoint_config = tf.estimator.RunConfig(save_checkpoints_secs = 20*60, # 每20分钟保存一次 keep_checkpoint_max = 10) # 保存10个最近的检查点cls = tf.estimator.DNNClassifier(hidden_units=[10,10], feature_columns=my_feature_columns, n_classes=3, model_dir='model/', config=my_checkpoint_config) 加载模型 不需要改动，一旦存在检查点，TensorFlow 就会在您每次调用 train()、evaluate() 或 predict() 时重建模型。 3.2 自定义模型 完整代码：点击查看 预创建的 Estimator 是 tf.estimator.Estimator 基类的子类，而自定义 Estimator 是 tf.estimator.Estimator 的实例 创建模型 模型函数（即 model_fn）会实现机器学习算法 params 参数会传递给自己实现的模型123456cls = tf.estimator.Estimator(model_fn=my_model, params=&#123; 'feature_columns': my_feature_columns, 'hidden_units': [10, 10], 'num_classes': 3 &#125;) 自定义my_model函数： 输入层指定输入的数据和对应的feature columns 隐藏层通过tf.layers.dense()创建 通过mode来判断是训练、评价还是预测操作，返回必须是tf.estimator.EstimatorSpec 对象 12345678910111213141516171819202122232425262728293031323334353637383940def my_model(features, labels, mode, params): '''自定义模型 --------------------------------------------- features: 输入数据 labels : 标签数据 mode : 指示是训练、评价还是预测 params : 构建模型的参数 ''' net = tf.feature_column.input_layer(features=features, feature_columns=params['feature_columns']) # 输入层 for units in params['hidden_units']: # 隐藏层，遍历参数配置 net = tf.layers.dense(inputs=net, units=units, activation=tf.nn.relu) logits = tf.layers.dense(net, params['num_classes'], activation=None) pred = tf.argmax(logits, 1) # 预测结果 if mode == tf.estimator.ModeKeys.PREDICT: predictions = &#123; 'class_ids': pred[:, tf.newaxis], 'probabilities': tf.nn.softmax(logits), 'logits': logits, &#125; return tf.estimator.EstimatorSpec(mode, predictions=predictions) # 计算loss loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits) # 计算评价信息 accuracy = tf.metrics.accuracy(labels=labels, predictions=pred, name='acc_op') metrics = &#123;'accuracy': accuracy&#125; tf.summary.scalar(name='accuracy', tensor=accuracy[1]) if mode == tf.estimator.ModeKeys.EVAL: return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics) # 训练操作 assert mode == tf.estimator.ModeKeys.TRAIN optimizer = tf.train.AdagradOptimizer(learning_rate=0.1) train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step()) return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op) 在 TensorBoard 中查看自定义 Estimator 的训练结果。（预定义的模型结果展示更丰富一些） tensorboard --logdir=PATH global_step/sec：这是一个性能指标，显示我们在进行模型训练时每秒处理的批次数（梯度更新）。 loss：所报告的损失。 accuracy：准确率由下列两行记录： eval_metric_ops={‘my_accuracy’: accuracy})（评估期间）。 tf.summary.scalar(‘accuracy’, accuracy1)（训练期间）。 二、Dataset tf.data 模块包含一系列类，可让轻松地加载数据、操作数据并通过管道将数据传送到模型中。 1、基本输入 从数组中提取接片，上面用到的代码 feature：特征数据，为feature-name: array的字典或者DataFrame labels: 标签数组 from_tensor_slices 会按第一个维度进行切片，比如输入为[6000, 28, 28]维度的数据，切片后返回6000个28， 28的Dataset 对象 shuffle 方法使用一个固定大小的缓冲区，在条目经过时随机化处理条目。在这种情况下，buffer_size 大于 Dataset 中样本的数量，确保数据完全被随机化处理。 repeat 方法会在结束时重启 Dataset。要限制周期数量，请设置 count 参数。 batch 方法会收集大量样本并将它们堆叠起来以创建批次。这为批次的形状增加了一个维度。新的维度将添加为第一个维度。 1234567def train_input_fn(features, labels, batch_size): \"\"\"训练集输入函数\"\"\" dataset = tf.data.Dataset.from_tensor_slices((dict(features,), labels)) # 转化为Dataset dataset = dataset.shuffle(buffer_size=1000).repeat().batch(batch_size) # Shuffle, batch return dataset 2、读取CSV文件 代码 处理一行数据，line: tf.string类型 1234567CSV_TYPES = [[0.0], [0.0], [0.0], [0.0], [0]]def _parse_line(line): '''解析一行数据''' field = tf.decode_csv(line, record_defaults=CSV_TYPES) features = dict(zip(CSV_COLUMN_NAMES, field)) labels = features.pop(\"Species\") return features, labels 处理text 文件，得到dataset 读取文本类型为：&lt;SkipDataset shapes: (), types: tf.string&gt; 然后使用map 函数，每个对象处理123456def csv_input_fn(csv_path, batch_size): '''csv文件输入函数''' dataset = tf.data.TextLineDataset(csv_path).skip(1) # 跳过第一行 dataset = dataset.map(_parse_line) # 应用map函数处理dataset中的每一个元素 dataset = dataset.shuffle(1000).repeat().batch(batch_size) return dataset Reference https://tensorflow.google.cn/get_started/get_started_for_beginners?hl=zh-cn https://tensorflow.google.cn/get_started/premade_estimators?hl=zh-cn https://github.com/tensorflow/models/blob/master/samples/core/get_started/iris_data.py","comments":true,"tags":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://lawlite.cn/tags/Tensorflow/"}]},{"title":"风格迁移 Style transfer","date":"2018-02-28T11:30:05.000Z","path":"2018/02/28/风格迁移Style-transfer/","text":"一、介绍 将一张图片的艺术风格应用在另外一张图片上 使用深度卷积网络CNN提取一张图片的内容和提取一张图片的风格， 然后将两者结合起来得到最后的结果 二、 方法 我们知道 CNN 可以捕捉图像的高层次特征，如上图所示，内容图片经过CNN可以得到对应的图像表述(representation, 就是经过卷积操作的feature map)，然后经过重构可以得到近似原图的效果 特别是前面几层经过重构得到的结果和原图更接近，也说明前几层保留的图片细节会更多，因为后面还有pooling层，自然会丢弃调一些信息 这里的网络使用的是VGG-16 (如下图)，包含 13 个卷积层，3 个全连接层 1、内容损失 假设一个卷积层包含 ${N_l}$ 个过滤器 filters，则可以得到 ${N_l}$ 个feature maps，假设 feature map的大小是 $M_l$ (长乘宽)，则可以通过一个矩阵来存储 l 层的数据 $$F^l \\in R^{N_l \\times M_l} $$ $F^l_{i,j}$ 表示第 l 层的第 i 个filter 在 j 位置上的激活值 所以现在一张内容图片$\\overrightarrow p$，一张生成图片$\\overrightarrow x$(初始值为高斯分布), 经过一层卷积层l可以得到其对应的特征表示：$P^l$ 和 $F_l$, 则对应的损失采用均方误差: $$L_{content}(\\overrightarrow p, \\overrightarrow x, l) = {1 \\over 2} \\sum_{ij}(F^l_{ij}-P^l_{ij})^2$$ $F$ 和 $P$是两个矩阵，大小是$N_l \\times M_l$，即l层过滤器的个数 和 feature map 的长乘宽的值 2、风格损失 风格的表示这里采用格拉姆矩阵(Gram Matrix): $G^l \\in R^{N_l \\times N_l}$ $$G^l_{ij} = {\\sum_k F^l_{ik}F^l_{jk}}$$ 格拉姆矩阵计算的是两两特征的相关性 , 即哪两个特征是同时出现的，哪两个特征是此消彼长的等，能够保留图像的风格 ( 比如一幅画中有人和树，它们可以出现在任意位置，格拉姆矩阵可以衡量它们之间的关系，可以认为是这幅画的风格信息 ) 假设$\\overrightarrow a$是风格图像，$\\overrightarrow x$是生成图像，$A^l$ 和 $G^l$ 表示在 $l$ 层的格拉姆矩阵，则这一层的损失为：$$E_l = {1 \\over 4N^2_lM^2_l}{\\sum_{i,j} (G^l_{ij}-A^l_{ij})^2}$$ 提取风格信息是我们会使用多个卷积层的输出，所以总损失为：$$L_{style}(\\overrightarrow a, \\overrightarrow x) = {\\sum^L_lw_lE_l}$$ 这里$w_l$是每一层损失的权重 3、总损失函数 通过白噪声初始化(就是高斯分布)一个输出的结果，然后通过网络对这个结果进行风格和内容两方面的约束进行修正$$L_{total}(\\overrightarrow p,\\overrightarrow a,\\overrightarrow x)=\\alpha L_{content}(\\overrightarrow p, \\overrightarrow x) +\\beta L_{style}(\\overrightarrow a, \\overrightarrow x)$$ 三、代码实现1、说明 全部代码：点击查看 图像使用一张建筑图和梵高的星空 2、加载并预处理图片和初始化输出图片 输出图片采用高斯分布初始化 12345678910111213141516171819202122232425262728293031import numpy as npfrom keras import backend as Kfrom keras.applications.vgg16 import preprocess_inputfrom keras.preprocessing.image import load_img, img_to_arrayfrom keras.applications import VGG16from scipy.optimize import fmin_l_bfgs_bfrom matplotlib import pyplot as plt'''图片路径'''content_image_path = './data/buildings.jpg'style_image_path = './data/starry-sky.jpg'generate_image_path = './data/output.jpg''''加载图片并初始化输出图片'''target_height = 512target_width = 512target_size = (target_height, target_width)content_image = load_img(content_image_path, target_size=target_size)content_image_array = img_to_array(content_image)content_image_array = K.variable(preprocess_input(np.expand_dims(content_image_array, 0)), dtype='float32')style_image = load_img(style_image_path, target_size=target_size)style_image_array = img_to_array(style_image)style_image_array = K.variable(preprocess_input(np.expand_dims(style_image_array, 0)), dtype='float32')generate_image = np.random.randint(256, size=(target_width, target_height, 3)).astype('float64')generate_image = preprocess_input(np.expand_dims(generate_image, 0))generate_image_placeholder = K.placeholder(shape=(1, target_width, target_height, 3)) 3、获取网络中对应层的输出12345678910111213141516171819202122232425262728def get_feature_represent(x, layer_names, model): '''图片的特征图表示 参数 ---------------------------------------------- x : 输入， 这里并没有使用，可以看作一个输入的标识 layer_names : list CNN网络层的名字 model : CNN模型 返回值 ---------------------------------------------- feature_matrices : list 经过CNN卷积层的特征表示，这里大小是(filter个数, feature map的长*宽) ''' feature_matrices = [] for ln in layer_names: select_layer = model.get_layer(ln) feature_raw = select_layer.output feature_raw_shape = K.shape(feature_raw).eval(session=tf_session) N_l = feature_raw_shape[-1] M_l = feature_raw_shape[1]*feature_raw_shape[2] feature_matrix = K.reshape(feature_raw, (M_l, N_l)) feature_matrix = K.transpose(feature_matrix) feature_matrices.append(feature_matrix) return feature_matrices 4、内容损失函数1234567891011121314151617def get_content_loss(F, P): '''计算内容损失 参数 --------------------------------------- F : tensor, float32 生成图片特征图矩阵 P : tensor, float32 内容图片特征图矩阵 返回值 --------------------------------------- content_loss : tensor, float32 内容损失 ''' content_loss = 0.5*K.sum(K.square(F-P)) return content_loss 5、Gram矩阵和风格损失12345678910111213141516171819202122232425def get_gram_matrix(F): '''计算gram矩阵''' G = K.dot(F, K.transpose(F)) return Gdef get_style_loss(ws, Gs, As): '''计算风格损失 参数 --------------------------------------- ws : array 每一层layer的权重 Gs : list 生成图片每一层得到的特征表示组成的list As : list 风格图片每一层得到的特征表示组成的list ''' style_loss = K.variable(0.) for w, G, A in zip(ws, Gs, As): M_l = K.int_shape(G)[1] N_l = K.int_shape(G)[0] G_gram = get_gram_matrix(G) A_gram = get_gram_matrix(A) style_loss += w*0.25*K.sum(K.square(G_gram-A_gram))/(N_l**2*M_l**2) return style_loss 6、总损失1234567891011121314151617def get_total_loss(generate_image_placeholder, alpha=1.0, beta=10000.0): '''总损失 ''' F = get_feature_represent(generate_image_placeholder, layer_names=[content_layer_name], model=gModel)[0] Gs = get_feature_represent(generate_image_placeholder, layer_names=style_layer_names, model=gModel) content_loss = get_content_loss(F, P) style_loss = get_style_loss(ws, Gs, As) total_loss = alpha*content_loss + beta*style_loss return total_lossdef calculate_loss(gen_image_array): '''调用总损失函数，计算得到总损失数值''' if gen_image_array != (1, target_width, target_height, 3): gen_image_array = gen_image_array.reshape((1, target_width, target_height, 3)) loss_fn = K.function(inputs=[gModel.input], outputs=[get_total_loss(gModel.input)]) return loss_fn([gen_image_array])[0].astype('float64') 7、损失函数梯度1234567def get_grad(gen_image_array): '''计算损失函数的梯度''' if gen_image_array != (1, target_width, target_height, 3): gen_image_array = gen_image_array.reshape((1, target_width, target_height, 3)) grad_fn = K.function([gModel.input], K.gradients(get_total_loss(gModel.input), [gModel.input])) grad = grad_fn([gen_image_array])[0].flatten().astype('float64') return grad 8、生成结果后处理 因为之前preprocess_input函数中做了处理，这里进行逆处理还原1234567891011121314def postprocess_array(x): '''生成图片后处理，因为之前preprocess_input函数中做了处理，这里进行逆处理还原 ''' if x.shape != (target_width, target_height, 3): x = x.reshape((target_width, target_height, 3)) x[..., 0] += 103.939 x[..., 1] += 116.779 x[..., 2] += 123.68 x = x[..., ::-1] # BGR--&gt;RGB x = np.clip(x, 0, 255) x = x.astype('uint8') return x 9、定义模型并优化123456789101112131415161718192021222324'''定义VGG模型'''tf_session = K.get_session()cModel = VGG16(include_top=False, input_tensor=content_image_array)sModel = VGG16(include_top=False, input_tensor=style_image_array)gModel = VGG16(include_top=False, input_tensor=generate_image_placeholder)content_layer_name = 'block4_conv2'style_layer_names = [ 'block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1']'''得到对应的representation矩阵'''P = get_feature_represent(x=content_image_array, layer_names=[content_layer_name], model=cModel)[0]As = get_feature_represent(x=style_image_array, layer_names=style_layer_names, model=sModel)ws = np.ones(len(style_layer_names))/float(len(style_layer_names))'''使用fmin_l_bfgs_b进行损失函数优化'''iterations = 600x_val = generate_image.flatten()xopt, f_val, info = fmin_l_bfgs_b(func=calculate_loss, x0=x_val, fprime=get_grad, maxiter=iterations, disp=True)x_out = postprocess_array(xopt) 10、输出结果 初始化输出图片 迭代200次，${\\beta \\over \\alpha} = 10^3$ 迭代500轮，${\\beta \\over \\alpha} = 10^4$ 四、总结 style tranfer通过白噪声初始化(就是高斯分布)一个输出的结果，然后通过优化损失对这个结果进行风格和内容两方面的约束修正 图片的风格信息使用的是 Gram矩阵来表示 其中超参数风格损失的权重ws、内容损失和风格损失的权重$\\alpha$, $\\beta$可以进行调整查看结果 论文给出的${\\beta \\over \\alpha} = 10^3或10^4$结果较好，可以自己适当增加看看最后的结果 Reference Paper: https://arxiv.org/pdf/1508.06576.pdf https://www.cs.toronto.edu/~frossard/post/vgg16/ https://zhuanlan.zhihu.com/p/33910138","comments":true,"tags":[{"name":"Style transfer","slug":"Style-transfer","permalink":"http://lawlite.cn/tags/Style-transfer/"},{"name":"Keras","slug":"Keras","permalink":"http://lawlite.cn/tags/Keras/"}]},{"title":"阿里云GPU服务器上Torch安装与使用","date":"2017-12-25T01:35:30.000Z","path":"2017/12/25/阿里云GPU服务器上Torch安装与使用/","text":"一、介绍 阿里云的GPU也有了竞价服务，每小时大概1块多，还是可以接受的 主要想跑github上的一个论文代码，使用的GPU,(奈何实验室没有GPU)， 本来我已经改成CPU版本的了，但是他训练好的模型是基于GPU的，所以还需要重新训练，结果非常的慢… 包含以下内容： 购买竞价GPU 通过SSH连接云服务器 安装Torch、hdf5、cjson、loadcaffe 安装cuda、cudnn、cunn 二、购买GPU服务器 进入阿里云GPU介绍页，点击访问，界面如下，我选择的是GN5(P100) 选择竞价实例 选择GPU 选择Ubuntu版本和带宽 这里按使用流量，所以带宽设置大点没有影响 在控制台可以看到服务器信息，下面需要使用公网IP连接 三、连接GPU服务器以及软件的安装1、使用SecureCRT连接服务器 2、安装前准备工作 apt clean apt update 安装git命令行：apt install git 生成ssh-key : ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 将/root/.ssh/id_rsa.pub中内容加入到github 3、安装Torch 网址：http://torch.ch/docs/getting-started.html git clone https://github.com/torch/distro.git ~/torch --recursive cd ~/torch bash install-deps ./install.sh source ~/.bashrc 输入th查看安装是否成功 4、 安装hdf5 地址: https://github.com/deepmind/torch-hdf5/blob/master/doc/usage.md apt-get install libhdf5-serial-dev hdf5-tools git clone https://github.com/deepmind/torch-hdf5 cd torch-hdf5 luarocks make hdf5-0-0.rockspec LIBHDF5_LIBDIR=&quot;/usr/lib/x86_64-linux-gnu/&quot; 注意这里 luarocks 是 Torch 里的，在 /root/torch/install/bin 目录下 5、 安装 cjson 和 loadcaffe luarocks install lua-cjson apt-get install libprotobuf-dev protobuf-compiler luarocks install loadcaffe 6、安装Cuda 网址：点击查看 选择对应的cuda版本 sudo dpkg -i cuda-repo-ubuntu1604-9-1-local_9.1.85-1_amd64.deb sudo apt-key add /var/cuda-repo-&lt;version&gt;/7fa2af80.pub sudo apt-get update sudo apt-get install cuda 安装完成后会在/usr/local/目录下出现cuda-9.1的目录 加入到环境变量 echo &quot;export PATH=/usr/local/cuda-9.1/bin/:\\$PATH; export LD_LIBRARY_PATH=/usr/local/cuda-9.1/lib64/:\\$LD_LIBRARY_PATH; &quot; &gt;&gt;~/.bashrc &amp;&amp; source ~/.bashrc 此时cuda已经安装成功，可以通过nvcc -V测试是否安装成功 nvidia-smi命令查看GPU使用情况 有时可能需要重启一下 7、安装cudnn 网址1：点击查看 网址2：下载cudnn 需要先注册登录才能下载 注意这里下载的版本，我这里使用的是5.1版本（尝试了最新的7.x版本，有问题） 直接luarocks install cudnn是可以成功安装的，但是有问题 下载的是压缩包,里面有两个文件夹 将include下的cudnn.h文件拷贝到/usr/local/cuda-9.1/include/文件夹下 将lib64下的libcudnn.so.5.1.10文件拷贝到/usr/local/cuda-9.1/lib64/文件夹下 并且创建软连接: ln -s libcudnn.so.5.1.10 libcudnn.so.5 添加环境变量：export CUDNN_PATH=&quot;/usr/local/cuda-9.1/lib64/libcudnn.so.5&quot; 四、测试 下面是我跑的一个程序 五、其他一些说明1、rz/sz文件传输 wget https://raw.githubusercontent.com/lawlite19/LinuxSoftware/master/rz-sz/lrzsz-0.12.20.tar.gz tar zxvf lrzsz-0.12.20.tar.gz cd lrzsz-0.12.20 ./configure &amp;&amp; make &amp;&amp; make install cd /usr/local/bin ln -s lrz rz ln -s lsz sz2、使用xftp等工具传输文件 服务器上需要安装ftp服务 apt install vsftpd 配置文件；vim /etc/vstfpd.conf 12345write_enable=YESuserlist_deny=NOuserlist_enable=YESuserlist_file=/etc/vsftpd.user_listseccomp_sandbox=NO 加入允许连接的用户 vim /etc/vstfpd.user_list 12rootlawlite 删除禁止连接的用户：vim /etc/ftpusers 使用xftp、FileZilla等工具连接即可 注意端口22 协议sftp 3、wget 下载百度云盘文件 wget -c ----referer=百度云盘分享地址 -O 要保存的文件名 &quot;百度云文件真实地址&quot; 文件的真实地址获取 浏览器按F12, 点击下载找到download?的信息 dlink为真实地址，注意去除转义字符\\ 比如： wget -c --referer=https://pan.baidu.com/s/1kV7Xo7H -O lstm1_rnn512_bestACC.zip &quot;https://d.pcs.baidu.com/file/4e4cd12ad77d7ac60d2cfcb8e009bf1c?fid=3174489928-250528-212189063946307&amp;time=1514127189&amp;rt=pr&amp;sign=FDTAERVCY-DCb740ccc5511e5e8fedcff06b081203-LWe3VIBsW3foAEVnTUqSROJQ46s%3D&amp;expires=8h&amp;chkv=1&amp;chkbd=1&amp;chkpc=et&amp;dp-logid=8301954057401711855&amp;dp-callid=0&amp;r=884079691&quot; Reference Cuda: https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=1604&amp;target_type=deblocal http://blog.csdn.net/u012235003/article/details/54575758 http://blog.csdn.net/hungryof/article/details/51557666 https://github.com/facebookarchive/fbcunn/blob/master/INSTALL.md#install-cuda Wget下载百度云： http://blog.csdn.net/zhongdajiajiao/article/details/51917886","comments":true,"tags":[{"name":"Cudnn","slug":"Cudnn","permalink":"http://lawlite.cn/tags/Cudnn/"},{"name":"GPU","slug":"GPU","permalink":"http://lawlite.cn/tags/GPU/"},{"name":"Torch","slug":"Torch","permalink":"http://lawlite.cn/tags/Torch/"},{"name":"阿里云","slug":"阿里云","permalink":"http://lawlite.cn/tags/阿里云/"}]},{"title":"论文记录_U-Net:Convolutional Networks for Biomedical Image Segmentation","date":"2017-10-18T11:30:05.000Z","path":"2017/10/18/论文记录-U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation/","text":"Keras 中的实现（可基于Theano和Tensorflow）：点击查看 Tensorflow 中的实现：点击查看 1、概述 2015年提出的用于生物图像分割的网络，并在当时取得了冠军 [实际也可用于其他领域，比如一些Kaggle图像分割比赛中也有使用，并且取得了很好的成绩] 一般的 CNN 是预测一张图片的类别，而图像分割需要预测每个像素属于的类别，使用是全卷积网络 FCN (fully convolutional network) 网络结构包括收缩 [就是 CNN 的卷积操作]和对应的扩展 [可以进行反卷积，这里采用上采样(upsample)] 收缩主要用于捕捉上下文特征 扩展用于定位 需要很少的训练集即可完成训练，很容易收敛 2、网络结构 左半部分收缩就是平常的CNN卷积操作 经过卷积、Relu 和 2x2 max pooling 右半部分扩展采用的上采样（upsampling）操作，同时拼接上对应的左半部分的feature maps 因为前面几层的卷积层分辨率比较高，定位比较准确 后面的几层卷积层分辨率比较低，分类比较准确 所以把低分辨率和高分辨率的feature map 拼接起来，得到更好的结果 如果预测时输入图片大小有问题，可以使用镜像拼接方式，同时也可以调整输入的大小是偶数，方便进行 2x2 max pooling 图中黄色部分待预测，需要蓝色部分作为输入，对称的方式生成周围的部分。 3、训练 损失函数使用逐像素的 softmax 函数和交叉熵损失函数的结合 Softmax函数：$${p_k(x)} = {e^{a_k(x)} \\over \\sum_{k’=1}^K e^{a_{k’(x)}}}$$ $a_k(x)$表示在feature maps中的的channel=k的feature map像素位置为x的激活值 $K$是类别数 [就是单个feature map上每个像素的类别概率] 训练需要标注对应的mask,就是类别的区域标记 因为使用了 Relu 激励函数，对应的权重初始化方法为标准差为$\\sqrt{2/N}$的高斯分布，具体关于不同激励函数对应的输出花方法可以看这里 训练集小的话可以做数据增强 4、Keras 中的实现 借鉴github上实现好的：点击查看，版本：Keras (2.0.8)，tensorflow (1.3.0) 两层卷积操作函数 判断是使用theano还是tensorflow作为backend， 因为他们对应的数据维度不同 可以使用BN和Dropout操作 两层卷积也就对应了上面U-net结构图的两个卷积操作12345678910111213141516def double_conv_layer(x, size, dropout, batch_norm): if K.image_dim_ordering() == &apos;th&apos;: axis = 1 else: axis = 3 conv = Conv2D(size, (3, 3), padding=&apos;same&apos;)(x) if batch_norm is True: conv = BatchNormalization(axis=axis)(conv) conv = Activation(&apos;relu&apos;)(conv) conv = Conv2D(size, (3, 3), padding=&apos;same&apos;)(conv) if batch_norm is True: conv = BatchNormalization(axis=axis)(conv) conv = Activation(&apos;relu&apos;)(conv) if dropout &gt; 0: conv = Dropout(dropout)(conv) return conv 构建网络 最后是1x1的卷积，使用的Sigmoid函数作为最后的输出概率123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def ZF_UNET_224(dropout_val=0.0, batch_norm=True): print(&quot;con&quot;) if K.image_dim_ordering() == &apos;th&apos;: inputs = Input((INPUT_CHANNELS, 224, 224)) axis = 1 else: inputs = Input((224, 224, INPUT_CHANNELS)) axis = 3 filters = 32 conv_224 = double_conv_layer(inputs, filters, dropout_val, batch_norm) pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224) conv_112 = double_conv_layer(pool_112, 2*filters, dropout_val, batch_norm) pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112) conv_56 = double_conv_layer(pool_56, 4*filters, dropout_val, batch_norm) pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56) conv_28 = double_conv_layer(pool_28, 8*filters, dropout_val, batch_norm) pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28) conv_14 = double_conv_layer(pool_14, 16*filters, dropout_val, batch_norm) pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14) conv_7 = double_conv_layer(pool_7, 32*filters, dropout_val, batch_norm) up_14 = concatenate([UpSampling2D(size=(2, 2))(conv_7), conv_14], axis=axis) up_conv_14 = double_conv_layer(up_14, 16*filters, dropout_val, batch_norm) up_28 = concatenate([UpSampling2D(size=(2, 2))(up_conv_14), conv_28], axis=axis) up_conv_28 = double_conv_layer(up_28, 8*filters, dropout_val, batch_norm) up_56 = concatenate([UpSampling2D(size=(2, 2))(up_conv_28), conv_56], axis=axis) up_conv_56 = double_conv_layer(up_56, 4*filters, dropout_val, batch_norm) up_112 = concatenate([UpSampling2D(size=(2, 2))(up_conv_56), conv_112], axis=axis) up_conv_112 = double_conv_layer(up_112, 2*filters, dropout_val, batch_norm) up_224 = concatenate([UpSampling2D(size=(2, 2))(up_conv_112), conv_224], axis=axis) up_conv_224 = double_conv_layer(up_224, filters, 0, batch_norm) conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1))(up_conv_224) conv_final = BatchNormalization(axis=axis)(conv_final) conv_final = Activation(&apos;sigmoid&apos;)(conv_final) model = Model(inputs, conv_final, name=&quot;ZF_UNET_224&quot;) return model 5、总结 图像分割能够获得很好的结果，要求的训练集比较小 包括了收缩和扩展两部分，扩展部分拼接了对应的收缩部分的feature maps Reference https://arxiv.org/abs/1505.04597# https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/ https://github.com/ZFTurbo/ZF_UNET_224_Pretrained_Model https://github.com/jakeret/tf_unet","comments":true,"tags":[{"name":"论文记录","slug":"论文记录","permalink":"http://lawlite.cn/tags/论文记录/"},{"name":"图像分割","slug":"图像分割","permalink":"http://lawlite.cn/tags/图像分割/"}]},{"title":"论文记录_MobileNets Efficient Convolutional Neural Networks for Mobile Vision Application","date":"2017-09-12T03:34:17.000Z","path":"2017/09/12/论文记录-MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Application/","text":"Tensorflow 中的实现：点击查看 Caffe 中的实现：点击查看 1、概述 Google在2017年提出的适用于手机端的神经网络模型 主要使用了深度可分离卷积Depthwise Separable Convolution 将卷积核进行分解计算来减少计算量 引入了两个超参数减少参数量和计算量 宽度乘数（Width Multiplier）: [减少输入和输出的 channels ] 分辨率乘数（Resolution Multiplier）：[减少输入输出的 feature maps 的大小] 2、深度可分离卷积（Depthwise Separable Convolution） 可以将一个标准卷积核分成一个深度卷积depthwise convolution 和 一个1X1的卷积（叫作逐点卷积pointwise convolution）。如下图所示 2.1 标准卷积 标准的卷积层是将维度为$D_F \\times D_F \\times M$的输入层转化为维度为$D_G \\times D_G \\times N$ [ 上篇论文中也有提到] $D_F$ 是输入feature map的长和宽，M 是输入的通道数（channels） $D_G$ 是输出feature map的长和宽，N 是输出的通道数 假设卷积核filter的大小是$D_k \\times D_k$，则标准卷积的计算量是$$D_k \\cdot D_k \\cdot M \\cdot N \\cdot D_F \\cdot D_F$$ 引用上篇论文中的图, 只看kernel matrix 部分，$D_k \\cdot D_k$就是一个方格的大小，然后乘上输入和输出的channels个数，然后作用在input feature maps 标准卷积是这样的, 即不管当前pixel有多少channels，卷积之后就是一个channel 2.2 Depthwise Separable Convolution 分为两个步骤 第一步深度卷积：卷积核的大小是$D_k \\times D_k \\times 1 \\times M$，所以总的计算量是：$$D_k \\cdot D_k \\cdot M \\cdot D_F \\cdot D_F$$ 第二步逐点卷积：卷积核大小是$1 \\times 1 \\times M \\times N$，所以总的计算量是：$$M \\cdot N \\cdot D_F \\cdot D_F$$ 所以和标准的卷积相比计算量比率为： $${D_k \\cdot D_k \\cdot M \\cdot D_F \\cdot D_F + M \\cdot N \\cdot D_F \\cdot D_F \\over D_k \\cdot D_k \\cdot M \\cdot N \\cdot D_F \\cdot D_F} = {1 \\over N} + {1 \\over D_k^2}$$ MobileNet使用的是3x3的卷积核，所以计算量可以减少8-9倍 (因为比率是1/N+1/9) 第一步深度卷积操作是在每一个channel上进行的卷积操作 第二步逐点卷积才是结合起来 3. 神经网络结构 MobileNet共有28层（深度卷积和逐点卷积分开来算） 之前标准的结构是卷积层之后跟上Batch Normalization层和Relu激活函数，这里引入Depthwise separable convolution之后的结构如下图 每一层都跟上了BN层和激活函数 总的结构 4. 宽度乘数（Width Multiplier） 引入超参数$\\alpha$, 目的是使模型变瘦, 即输入层的channels个数M，变成$\\alpha M$，输出层的channels个数N变成了$\\alpha N$ 所以引入宽度乘数后的总的计算量是$$D_k \\cdot D_k \\cdot \\alpha M \\cdot D_F \\cdot D_F + \\alpha M \\cdot \\alpha N \\cdot D_F \\cdot D_F$$ 一般$\\alpha \\in (0,1]$，常取的值是1, 0.75, 0.5, 0.25, 大约可以减少参数量和计算量的$\\alpha ^2$ 5. 分辨率乘数 （Resolution Multiplier） 引入超参数$\\rho$，目的是降低图片的分辨率 即作用在输入的feature map上 所以再引入分辨率乘数后总的计算量是：$$D_k \\cdot D_k \\cdot \\alpha M \\cdot \\rho D_F \\cdot \\rho D_F + \\alpha M \\cdot \\alpha N \\cdot \\rho D_F \\cdot \\rho D_F$$ 一般输入图片的分辨率是224, 192, 160 or 128 大约可以减少计算量的$\\rho ^2$ 6. 实验结果 关于超参数的选择，下图可以看出准确度和参数量和参数运算量的关系，之间有个trade off，合理选择参数即可 还在细粒度的识别，大规模地理位置识别，人脸属性提取，目标检测和人脸识别等任务上进行了测试，效果也很好 7. 总结 主要是基于depthwise separable convolution 引入了两个超参数 [ 第一个宽度乘数就是减少feature map，以此来降低模型厚度 ] [ 第二个分辨率乘数就是缩小feature map的大小，来减少计算量] [ 超参数的选择是有个trade off的 ] Reference https://arxiv.org/abs/1704.04861 https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md https://github.com/shicai/MobileNet-Caffe http://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/","comments":true,"tags":[{"name":"Paper阅读记录","slug":"Paper阅读记录","permalink":"http://lawlite.cn/tags/Paper阅读记录/"},{"name":"ModelCompression","slug":"ModelCompression","permalink":"http://lawlite.cn/tags/ModelCompression/"}]},{"title":"论文记录-Pruning Filters For Efficient ConvNets","date":"2017-09-10T02:32:12.000Z","path":"2017/09/10/论文记录-PruningFiltersForEfficientConvNets/","text":"1、概述 一些剪枝的操作主要是减少了全连接层的参数，全连接层的参数量占比最多（比如VGG-16中全连接层操作占了90%，计算量只占了不到1%）, 但是主要的计算量集中在卷层操作 论文就是提出了对卷积层进行剪枝操作，然后进行retrain，不会造成稀疏连接（像上篇论文一样，稀疏矩阵操作需要特殊的库等来处理） 全连接层可以使用平均池化层来代替以减少参数量 2、对Filters进行剪枝，以及Feature maps2.1 基础（CNN相关内容） 设第 i 层的卷积层的输入 channel 有 $n_i$ , $h_i$ 和 $w_i$ 表示输入的特征图feature map的高和宽 使用$n_{i+1}$ 个3D filters $F_{i,j} \\in R^{n_i \\times k \\times k}$， 则卷积操作可以将输入的feature maps $x_i \\in R^{n_i \\times h_i \\times w_i}$ 转化为 $x_{i+1} \\in R^{n_{i+1} \\times h_{i+1} \\times w_{i+1}}$ 关于CNN的基础不了解的可以查看这里 卷积操作的运算数量是：$n_{i+1}n_ik^2h_{i+1}w_{i+1}$ (对应到下图的kernel matrix) 所以如下图所示，取出一个feature map可以直接减少$n_ik^2h_{i+1}w_{i+1}$个运算 同时接下来的feature map也就没有了，附加移除$n_{i+2}k^2h_{i+2}w_{i+2}$个运算 所以减少m个 featuremaps 可以减少 $m/n_{i+1}$ 的计算量 下图的kernel matrix，一个 feature map 对应一列，所以是$m/n_{i+1}$ 2.2 去除哪些filters (在单层中) 向之前的论文介绍的，权重的绝对值越小，则权重的作用也就越小 [ 假设权重值都在0附近，进行乘积得到的值很小，所以对结果造成的影响也很小 ] [ 删除一些冗余的值还有可能防止过拟合 ] 本文使用的是filter的绝对值的和来衡量这个filter的作用，即 $\\sum |F_{i,j}|$ , ($l_1$范数) 选择前m个最小的绝对值删除 文章和随机选择相同数量的filters和选择最大值的结果比较，此方法最好 VGG-16在Cifar-10数据集上训练得到的卷积层的权重分布情况，可以看出每一卷积层的分布变化还是很大的 2.3 剪枝的敏感度(Sensitivity) 就是每一卷积层进行单独剪枝，查看在validation set上准确度的变化 对于VGG-16, 一些卷积层的filter数量是一样的，所以对于差不多 Sensitivity 的卷积层，使用相同的比例进行剪枝，而对于 Sensitivity 比较大的，选择最小的比例进行剪枝或者不进行剪枝 2.4 多层剪枝的策略 之前的一些剪枝策略是逐层剪枝，然后进行retraining，但是这样是非常耗时的 两种策略 独立剪枝：就是每一层是独立的，然后进行剪枝 贪心剪枝：就是考虑到上一层被剪掉的情况 如下图，第一种方法就是不考虑已经前面已经移除的filters（蓝色的），就是黄色的kernel仍然参与计算 而对于贪心剪枝就不用计算黄色的kernel了 3、 Retraining 剪枝之后，应该retraining，（和迁移学习很像，有些fine-tune的意思） 也是两种策略： 一次性剪枝然后 retrain 逐层剪枝进行 retrain 第二种策略结果可能会更好，但是需要更多的epochs 4、实验结果 剪枝之后进行retrain，在原来的基础之上得到的结果要比完全重新训练得到的结果好 和随机剪枝、减去最大值$l_1$范数的filters的结果比较 5、结论 剪枝filters，减少计算量 注意有Batch Normalization层的对应剪枝后，BN层也要对应删除 [其实感觉方法挺简单的] Reference https://arxiv.org/abs/1608.08710 http://lawlite.me/2017/09/07/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95-DeepCompression-CompressingDeepNeuralNetworksWithPruning-TrainedQuantizationAndHuffmanCoding/ http://blog.csdn.net/u013082989/article/details/53673602","comments":true,"tags":[{"name":"Paper阅读记录","slug":"Paper阅读记录","permalink":"http://lawlite.cn/tags/Paper阅读记录/"},{"name":"ModelCompression","slug":"ModelCompression","permalink":"http://lawlite.cn/tags/ModelCompression/"}]},{"title":"论文记录-Deep Compression:Compressing DeepNeural Networks With Pruning, Trained Quantization And Huffman Coding","date":"2017-09-07T02:43:52.000Z","path":"2017/09/07/论文记录-DeepCompression-CompressingDeepNeuralNetworksWithPruning-TrainedQuantizationAndHuffmanCoding/","text":"1、概述 压缩主要分为三个阶段：剪枝(pruning)、训练分层(trained quantization)以及 哈夫曼编码(Huffman coding) 可以压缩35到49倍，并且不影响精度 [模型压缩的主要用于还是能够用于小型的设备上，例如手机端等，比如Google的Mobile Net, 但是准确度肯定要比正常的电脑端训练的大网络低一些，在所难免] [一般的训练好的神经网络模型文件有几百兆的大小，比如Google预训练好的模型，计算量也很大，在手机端运行不太现实] 2、Pipline 剪枝可以压缩10倍左右，加上分层可以达到27到31倍，再加上哈夫曼编码可以达到35到49倍 剪枝：去除多余的连接，比如权重非常小的连接 分层：我感觉像是聚类，多个连接共享一个权重 3、剪枝 主要是删去权重值weight比较小的，(设置为0)，可以设置一个阈值(threshold) 所以权重矩阵变的比较稀疏，可以采用压缩行存储（Compressed Row Storage(CRS)）或列存储来存储稀疏矩阵 主要包括3个数组，浮点值数组val，两个整形数组col_index, row_ptr val(k) = a(i,j), col_index(k) = j row_ptr是每行数据第一个非0元素在val中的索引，最后加上一位非0元素的个数，即row_ptr(n+1) = a+1 比如 val 10 -2 3 9 3 7 8 7 3 … 9 13 4 2 -1 col_index 1 5 1 2 6 2 3 4 1 … 5 6 2 5 6 row_ptr 1 3 6 9 13 17 20 所以总共需要的大小为：2a+n+1 a为矩阵非零元素的个数 n为行数 4、训练分层量化 比如所有的权重聚成4类，cluster index表示每个权重对应的类别 梯度采用同一类别内进行累加，然后进行微调更新 假设有n个连接，每个连接的用b bits来表示，并假设有k个cluster, 只需要$log_2(k)$bits去表示索引，则压缩率可以为：$$r = {nb \\over nlog_2(k)+kb}$$ nb即为没有聚类前总共需要的bits $nlog_2(k)+kb$就是聚类索引的bits加上聚类后连接需要的bits 比如上面的例子为：${1632 \\over 162+4*32} = 3.2$ 4.1 权值共享 使用k-means算法进行聚类，确定每一层共享的权重，在一个cluster中的权重共享，注意这里没有跨层 将$W={\\{w_1, w_2, … ,w_n\\}}$聚为$C={\\{c_1,c_2, … ,c_k\\}}$类, 其中n&gt;&gt;k 优化函数为：$$\\mathop {\\arg \\min }\\limits_c \\sum\\limits_{i=1}^k \\sum\\limits_{w \\in c_i} |w-c_i|^2$$ 4.2 共享权重的初始化方法（三种） Forgy: 就是随机初始化方法初始化聚类的中心，如下图，因为权重分布有两个峰值，初始化的值都在峰值附近 基于密度的初始化方法：如下图，先是根据累积分布函数(CDF)线性等分y轴，然后根据CDF找到对应的x轴的坐标，即为聚类的中心。（也是在峰值附近，和Forgy方法相比更分散一些） 线性：就是根据权重的最小值和最大值等分，分散性最大 神经网络中一般权重值越大，它的作用也就越大，所以对于前两种初始化方法都是在峰值附近，也就意味着值少的地方很小的概率会被初始化，所以不太好，实验中线性初始化的效果最好（但是大权重值的是很少的） 4.3 前向和反向传播 计算时查表就可以了 反向传播用于更新聚类中心的权重值$${\\partial L \\over \\partial C_k} = \\sum\\limits_{ij}{\\partial L \\over \\partial W_{ij}} {\\partial W_{ij} \\over \\partial C_k} = \\sum\\limits_{ij} {\\partial L \\over\\partial W_{ij}}\\Gamma (I_{ij}=k)$$ 其中L是损失函数，$C_k$是第k个聚类的中心 $I_{ij}$为聚类中心的索引，如下图，就是同一类别梯度求和 5、哈夫曼编码 就是按照聚类中心的出现的概率从大到小排序进行Huffman编码 根据上面的结果，权重大都分布在两个峰值附近，所以利于huffman编码 6、结果及讨论 没有准确度损失 pruning 和 quantization 结合使用效果最好 和之前别人的工作的比较 SVD 压缩了模型但是精度损失较大 缺点就是在运行时现有的GPU不能进行间接的矩阵输入查找，以及相对索引 CSC 或 CSR, 还有剪枝的操作主要是在全连接层，但是计算量大的卷积层较少，虽然可以通过BLAS libraries或是specialized hardware进行加速，但是也是受限的（下篇Paper中也有提到） [我觉得剪枝和权值共享其实是能够防止过拟合的，所以准确度没有损失] [权值共享时是当前层的权值共享，不是整个网络的权值共享] Reference https://arxiv.org/abs/1510.00149 http://blog.csdn.net/bigpiglet_zju/article/details/20791881","comments":true,"tags":[{"name":"Paper阅读记录","slug":"Paper阅读记录","permalink":"http://lawlite.cn/tags/Paper阅读记录/"},{"name":"ModelCompression","slug":"ModelCompression","permalink":"http://lawlite.cn/tags/ModelCompression/"}]},{"title":"R语言学习","date":"2017-06-30T08:48:15.000Z","path":"2017/06/30/R语言学习/","text":"基础内容来自W3C，直接查看这里即可，这里只是个人学习的记录 只是最近感觉有必要学习一下R，哈哈 一、基础1、概述 R语言是用于统计分析，图形表示和报告的编程语言和软件环境。 解释型语言2、Windows上安装 下载地址：R-3.4.0，直接下载安装即可 IDE使用RStudio: 点击下载 3、数据类型 使用&lt;-进行赋值（RStudio中的快捷键是Alt+-） 变量分配有R对象，R对象的数据类型变为变量的数据类型。 使用class()来查看类型(1) Vector向量 创建使用c()函数 123&gt; apple = c('apple', 'banana')&gt; print(apple)[1] \"apple\" \"banana\" (2) List列表 列表是一个R对象，它可以在其中包含许多不同类型的元素 12345678910&gt; list &lt;- list(c('apple','banana'), 1, 2.0)&gt; print(list)[[1]][4] \"apple\" \"banana\"[[2]][5] 1[[3]][6] 2 (3) Matrix矩阵 矩阵被限制为二维12345&gt; M = matrix( c('a','a','b','c','b','a'), nrow = 2, ncol = 3, byrow = TRUE)&gt; print(M) [,1] [,2] [,3][1,] \"a\" \"a\" \"b\" [2,] \"c\" \"b\" \"a\" (4) Array数组 dim指定维度，这里穿创建3x3x2的三维矩阵，输入是向量（一致循环创建） 123456789101112131415&gt; a &lt;- array(c('green','yellow'),dim = c(3,3,2))&gt; print(a), , 1 [,1] [,2] [,3] [1,] \"green\" \"yellow\" \"green\" [2,] \"yellow\" \"green\" \"yellow\"[3,] \"green\" \"yellow\" \"green\" , , 2 [,1] [,2] [,3] [1,] \"yellow\" \"green\" \"yellow\"[2,] \"green\" \"yellow\" \"green\" [3,] \"yellow\" \"green\" \"yellow\" (5) Factor因子 因子是使用向量创建的r对象。 nlevels函数可以得到因子中不重复值的个数123456&gt; factor_content &lt;- factor(c('green', 'red', 'green', 'yellow', 'red', 'green'))&gt; print(factor_content)[1] green red green yellow red green Levels: green red yellow&gt; print(nlevels(factor_content))[1] 3 (6) Data Frame 数据帧 数据表 1234567891011&gt; BMI &lt;- data.frame(+ gender = c(\"Male\", \"Male\",\"Female\"), + height = c(152, 171.5, 165), + weight = c(81,93, 78),+ Age = c(42,38,26)+ )&gt; print(BMI) gender height weight Age1 Male 152.0 81 422 Male 171.5 93 383 Female 165.0 78 26 names(data.frame对象) 查看列名 row.names 查看行名 4、变量(1) 命名 有效的变量名称由字母，数字和点或下划线字符组成 列如：var_name2.，.var_name var.name(2) 赋值 可以使用=, &lt;-, -&gt; =和&lt;-的区别是一个是传值，一个是赋值，一般使用&lt;-123456789&gt; var.1 = c(0,1,2,3)&gt; var.2 &lt;- c(\"learn\",\"R\")&gt; c(TRUE,1) -&gt; var.3 &gt; print(var.1)[1] 0 1 2 3&gt; print(var.2)[1] \"learn\" \"R\" &gt; print(var.3)[1] 1 1 (3) 查找变量 使用ls()函数 12345&gt; print(ls()) [1] \"a\" \"aisles\" \"apple\" \"BMI\" \"data\" [6] \"departments\" \"factor_content\" \"list\" \"M\" \"orderp\" [11] \"orders\" \"ordert\" \"path\" \"products\" \"s\" [16] \"var.1\" \"var.2\" \"var.3\" 通过模式匹配查找 12&gt; print(ls(pattern = \"var\"))[1] \"var.1\" \"var.2\" \"var.3\" 以点.开头的变量名字会被隐藏，可以print(ls(all.name = TRUE))列出所有的 (4) 删除变量 单个变量通过rm(变量名)删除 删除所有变量：rm(list = ls()) 5、运算符(1) 算数运算符 %% : 求余 %/% : 相除求商 ^ : 指数(2) 关系运算符 和c等语言一样(3) 逻辑运算符 &amp; : 与and，两个&amp;&amp;只比较第一个（比如向量只比较第一个元素） | : 或or， 两个||一样 (4) 其他 : 12&gt; 2:8[1] 2 3 4 5 6 7 8 %in% : 元素是否在一个向量中 6、包(1) 介绍 R语言的包是R函数，编译代码和样本数据的集合。 存储在R语言环境中名为“library”的目录下 可用的R语言的包：点击查看(2) 常用命令 查看库的位置：.libPaths() 查看已安装所有软件包：library() 当前环境加载的所有包：search() 安装包：install.packages(&quot;Package Name&quot;) 加载到当前R语言环境中：library(&quot;package Name&quot;, lib.loc = &quot;path to library&quot;)(3) 手动安装包 将包作为.zip文件保存在本地系统中的适当位置。 安装：install.packages(&quot;E:/XML_3.98-1.3.zip&quot;, repos = NULL, type = &quot;source&quot;) 7、数据重塑Dataframe(1) 数据帧中加入行和列 cbind()连接多个向量 12345678910&gt; city &lt;- c(\"Tampa\",\"Seattle\",\"Hartford\",\"Denver\")&gt; state &lt;- c(\"FL\",\"WA\",\"CT\",\"CO\")&gt; zipcode &lt;- c(33602,98104,06161,80294)&gt; addresses &lt;- cbind(city,state,zipcode)&gt; print(addresses) city state zipcode[1,] \"Tampa\" \"FL\" \"33602\"[2,] \"Seattle\" \"WA\" \"98104\"[3,] \"Hartford\" \"CT\" \"6161\" [4,] \"Denver\" \"CO\" \"80294\" rbind()按行拼接(2) 合并数据帧 使用merge()函数合并两个数据帧。 数据帧必须具有相同的列名称，在其上进行合并。1234567891011121314151617181920212223242526&gt; library(MASS)&gt; merged.Pima &lt;- merge(x = Pima.te, y = Pima.tr,+ by.x = c(\"bp\", \"bmi\"),+ by.y = c(\"bp\", \"bmi\")+ )&gt; print(merged.Pima) bp bmi npreg.x glu.x skin.x ped.x age.x type.x npreg.y glu.y skin.y ped.y age.y type.y1 60 33.8 1 117 23 0.466 27 No 2 125 20 0.088 31 No2 64 29.7 2 75 24 0.370 33 No 2 100 23 0.368 21 No3 64 31.2 5 189 33 0.583 29 Yes 3 158 13 0.295 24 No4 64 33.2 4 117 27 0.230 24 No 1 96 27 0.289 21 No5 66 38.1 3 115 39 0.150 28 No 1 114 36 0.289 21 No6 68 38.5 2 100 25 0.324 26 No 7 129 49 0.439 43 Yes7 70 27.4 1 116 28 0.204 21 No 0 124 20 0.254 36 Yes8 70 33.1 4 91 32 0.446 22 No 9 123 44 0.374 40 No9 70 35.4 9 124 33 0.282 34 No 6 134 23 0.542 29 Yes10 72 25.6 1 157 21 0.123 24 No 4 99 17 0.294 28 No11 72 37.7 5 95 33 0.370 27 No 6 103 32 0.324 55 No12 74 25.9 9 134 33 0.460 81 No 8 126 38 0.162 39 No13 74 25.9 1 95 21 0.673 36 No 8 126 38 0.162 39 No14 78 27.6 5 88 30 0.258 37 No 6 125 31 0.565 49 Yes15 78 27.6 10 122 31 0.512 45 No 6 125 31 0.565 49 Yes16 78 39.4 2 112 50 0.175 24 No 4 112 40 0.236 38 No17 88 34.5 1 117 24 0.403 40 Yes 4 127 11 0.598 28 No&gt; nrow(merged.Pima)[1] 17 (3) 拆分和重组 melt()拆分数据 (以船舶的数据集为例) 需要安装reshape包 install.packages(&quot;reshape&quot;)12345678910111213141516171819202122232425262728293031323334353637383940414243&gt; library(MASS)&gt; print(ships) type year period service incidents1 A 60 60 127 02 A 60 75 63 03 A 65 60 1095 34 A 65 75 1095 45 A 70 60 1512 66 A 70 75 3353 187 A 75 60 0 08 A 75 75 2244 119 B 60 60 44882 3910 B 60 75 17176 2911 B 65 60 28609 5812 B 65 75 20370 5313 B 70 60 7064 1214 B 70 75 13099 4415 B 75 60 0 016 B 75 75 7117 1817 C 60 60 1179 118 C 60 75 552 119 C 65 60 781 020 C 65 75 676 121 C 70 60 783 622 C 70 75 1948 223 C 75 60 0 024 C 75 75 274 125 D 60 60 251 026 D 60 75 105 027 D 65 60 288 028 D 65 75 192 029 D 70 60 349 230 D 70 75 1208 1131 D 75 60 0 032 D 75 75 2051 433 E 60 60 45 034 E 60 75 0 035 E 65 60 789 736 E 65 75 437 737 E 70 60 1157 538 E 70 75 2161 1239 E 75 60 0 040 E 75 75 542 1 拆分 melt()将类型和年份以外的所有列转换为多行展示123456789101112131415161718192021222324252627282930313233343536373839library(reshape)molten.ships &lt;- melt(ships, id = c(\"type\",\"year\"))print(molten.ships) type year variable value1 A 60 period 602 A 60 period 753 A 65 period 604 A 65 period 75........................9 B 60 period 6010 B 60 period 7511 B 65 period 6012 B 65 period 7513 B 70 period 60......................41 A 60 service 12742 A 60 service 6343 A 65 service 1095......................70 D 70 service 120871 D 75 service 072 D 75 service 205173 E 60 service 4574 E 60 service 075 E 65 service 789......................101 C 70 incidents 6102 C 70 incidents 2103 C 75 incidents 0104 C 75 incidents 1105 D 60 incidents 0106 D 60 incidents 0...................... cast()重构数据 每年每种类型的船的总和1234567891011121314151617181920212223&gt; recasted.ship &lt;- cast(molten.ships, type+year~variable,sum)&gt; print(recasted.ship) type year period service incidents1 A 60 135 190 02 A 65 135 2190 73 A 70 135 4865 244 A 75 135 2244 115 B 60 135 62058 686 B 65 135 48979 1117 B 70 135 20163 568 B 75 135 7117 189 C 60 135 1731 210 C 65 135 1457 111 C 70 135 2731 812 C 75 135 274 113 D 60 135 356 014 D 65 135 480 015 D 70 135 1557 1316 D 75 135 2051 417 E 60 135 45 018 E 65 135 1226 1419 E 70 135 3318 1720 E 75 135 542 1 8、函数(1) 定义123function_name &lt;- function(arg_1, arg_2, ...) &#123; Function body &#125; (2) 自定义函数和调用12345678910&gt; new.function &lt;- function(a) &#123;+ for(i in 1:a) &#123;+ b &lt;- i^2+ print(b)+ &#125;+ &#125;&gt; new.function(3)[1] 1[1] 4[1] 9 9、字符串(1) 定义 可以使用单引号或双引号 123&gt; s &lt;- 'hello world!'&gt; print(s)[1] \"hello world!\" (2) 字符串操作 连接字符串：paste(..., sep = &quot; &quot;, collapse = NULL) ...表示要组合的任意数量的自变量。 sep表示参数之间的任何分隔符。 它是可选的。 collapse用于消除两个字符串之间的空格。但不是一个字符串的两个字内的空间。 格式化字符串：format(x, digits, nsmall, scientific, width, justify = c(&quot;left&quot;, &quot;right&quot;, &quot;centre&quot;, &quot;none&quot;)) x是向量输入。 digits是显示的总位数。 nsmall是小数点右边的最小位数。 科学设置为TRUE以显示科学记数法。 width指示通过在开始处填充空白来显示的最小宽度。 justify是字符串向左，右或中心的显示。 字符数：nchar() 大小写：toupper() 和 tolower() 截取：substring(x,first,last) 10、向量 向量是最基本的R语言数据对象，有六种类型的原子向量。 它们是逻辑，整数，双精度，复杂，字符和原始。(1) 序列运算符seq 12&gt; print(seq(1, 10, by=2))[1] 1 3 5 7 9 (2) 访问向量元素 使用索引访问向量的元素。 []括号用于建立索引。 索引从位置1开始。 位置索引 注意位置是从1开始的1234t &lt;- c(\"Sun\",\"Mon\",\"Tue\",\"Wed\",\"Thurs\",\"Fri\",\"Sat\")u &lt;- t[c(2,3,6)]print(u)[1] \"Mon\" \"Tue\" \"Fri\" 负数索引 使用负数是丢弃掉对应正数的索引123x &lt;- t[c(-2,-5)]print(x)[1] \"Sun\" \"Tue\" \"Wed\" \"Fri\" \"Sat\" 排序 1234&gt; v &lt;- c(3,8,4,5,0,11, -9, 304)&gt; v.result &lt;- sort(v)&gt; print(v.result)[1] -9 0 3 4 5 8 11 304 11、列表 可以通过索引和名字访问 12345678910111213141516171819202122232425262728&gt; list_data &lt;- list(c(\"Jan\",\"Feb\",\"Mar\"), matrix(c(3,9,5,1,-2,8), nrow = 2),+ list(\"green\",12.3))&gt; print(list_data)[[1]][1] \"Jan\" \"Feb\" \"Mar\"[[2]] [,1] [,2] [,3][1,] 3 5 -2[2,] 9 1 8[[3]][[3]][[1]][1] \"green\"[[3]][[2]][1] 12.3&gt; names(list_data) &lt;- c(\"1st Quarter\", \"A_Matrix\", \"A Inner list\")&gt; print(list_data[1])$`1st Quarter`[1] \"Jan\" \"Feb\" \"Mar\"&gt; print(list_data$A_Matrix) [,1] [,2] [,3][1,] 3 5 -2[2,] 9 1 8 合并列表：merged.list &lt;- c(list1,list2) 列表转向量：v1 &lt;- unlist(list1) 12、矩阵 矩阵是其中元素以二维矩形布局布置的R对象。 包含相同原子类型的元素。 matrix(data, nrow, ncol, byrow, dimnames) data数据是成为矩阵的数据元素的输入向量。 nrow是要创建的行数。 ncol是要创建的列数。 byrow是一个逻辑线索。如果为TRUE，则输入向量元素按行排列。 dimname是分配给行和列的名称。 13、数组14、因子 因子是用于对数据进行分类并将其存储为级别的数据对象。 它们可以存储字符串和整数。 它们在具有有限数量的唯一值的列中很有用。像“男性”，“女性”和True，False等。它们在统计建模的数据分析中很有用。 12345678910111213141516&gt; height &lt;- c(132,151,162,139,166,147,122)&gt; weight &lt;- c(48,49,66,53,67,52,40)&gt; gender &lt;- c(\"male\",\"male\",\"female\",\"female\",\"male\",\"female\",\"male\")&gt; &gt; input_data &lt;- data.frame(height,weight,gender)&gt; print(input_data) height weight gender1 132 48 male2 151 49 male3 162 66 female4 139 53 female5 166 67 male6 147 52 female7 122 40 male&gt; print(input_data$height)[1] 132 151 162 139 166 147 122 15、数据帧 summary() 12345678910111213141516171819202122232425&gt; emp.data &lt;- data.frame(+ emp_id = c (1:5), + emp_name = c(\"Rick\",\"Dan\",\"Michelle\",\"Ryan\",\"Gary\"),+ salary = c(623.3,515.2,611.0,729.0,843.25), + + start_date = as.Date(c(\"2012-01-01\", \"2013-09-23\", \"2014-11-15\", \"2014-05-11\",+ \"2015-03-27\")),+ stringsAsFactors = FALSE+ )&gt; # Print the summary.&gt; print(summary(emp.data)) emp_id emp_name salary start_date Min. :1 Length:5 Min. :515.2 Min. :2012-01-01 1st Qu.:2 Class :character 1st Qu.:611.0 1st Qu.:2013-09-23 Median :3 Mode :character Median :623.3 Median :2014-05-11 Mean :3 Mean :664.4 Mean :2014-01-14 3rd Qu.:4 3rd Qu.:729.0 3rd Qu.:2014-11-15 Max. :5 Max. :843.2 Max. :2015-03-27 &gt; print(emp.data) emp_id emp_name salary start_date1 1 Rick 623.30 2012-01-012 2 Dan 515.20 2013-09-233 3 Michelle 611.00 2014-11-154 4 Ryan 729.00 2014-05-115 5 Gary 843.25 2015-03-27 取数据前两行result &lt;- emp.data[1:2,] result &lt;- emp.data[c(3,5),c(2,4)] 扩展数据emp.data$dept &lt;- c(&quot;IT&quot;,&quot;Operations&quot;,&quot;IT&quot;,&quot;HR&quot;,&quot;Finance&quot;) 添加行：emp.finaldata &lt;- rbind(emp.data,emp.newdata) 二、dplyr包1、基本操作 安装：install.packages(&quot;dplyr&quot;)(1) 筛选 筛选行：filter() 前面是dataframe数据，后面是筛选的条件，这里是筛选列名为eval_set的数据 也可以使用管道的方式：datafame %&gt;% filter(eval_set == “prior”)1filter(dataframe, eval_set == \"prior\") 筛选列：select() 筛选列名为user_id, product_id的列，使用负号表示去除对应的列 可以使用管道的方式：ordert %&gt;% select(user_id, product_id, reordered)1select(ordert, user_id, product_id) (2) 排序arrange() 按给定的列名依次进行排序（默认升序） 管道的方式：orders_products %&gt;% arrange(user_id, order_number, product_id)1arrange(df, user_id, order_number, product_id) 降序排列 1arrange(df, desc(ArrDelay)) (3) 变形mutate() 对已有列进行数据运算并添加为新列 123mutate(hflights_df, gain = ArrDelay - DepDelay, speed = Distance / AirTime * 60) (4) 汇总123456789101112prd &lt;- orders_products %&gt;% arrange(user_id, order_number, product_id) %&gt;% group_by(user_id, product_id) %&gt;% mutate(product_time = row_number()) %&gt;% ungroup() %&gt;% group_by(product_id) %&gt;% summarise( prod_orders = n(), prod_reorders = sum(reordered), prod_first_orders = sum(product_time == 1), prod_second_orders = sum(product_time == 2) ) 2、分组 当对数据集通过 group_by() 添加了分组信息后,mutate(), arrange() 和 summarise() 函数会自动对这些 tbl 类数据执行分组操作 (R语言泛型函数的优势). 123456789101112prd &lt;- orders_products %&gt;% arrange(user_id, order_number, product_id) %&gt;% group_by(user_id, product_id) %&gt;% mutate(product_time = row_number()) %&gt;% ungroup() %&gt;% group_by(product_id) %&gt;% summarise( prod_orders = n(), prod_reorders = sum(reordered), prod_first_orders = sum(product_time == 1), prod_second_orders = sum(product_time == 2) ) Reference https://w3cschool.cn/r/ https://cran.rstudio.com/web/packages/dplyr/dplyr.pdf","comments":true,"tags":[{"name":"R","slug":"R","permalink":"http://lawlite.cn/tags/R/"}]},{"title":"Tensorflow学习-工具相关","date":"2017-06-24T11:30:05.000Z","path":"2017/06/24/Tensorflow学习-工具相关/","text":"Tensorflow版本(# 2017-06-24)：1.2.0 Python版本：3.5.3 包括： Tensorboard可视化 tfdbg调试 常用的高级函数 一、TensorBoard 可视化1、可视化计算图 全部代码：点击查看 数据集使用MNIST手写数字 加载数据 123456'''加载数据'''data = input_data.read_data_sets('MNIST_data', one_hot=True)print(\"Size of:\")print(\"\\t\\t training set:\\t\\t&#123;&#125;\".format(len(data.train.labels)))print(\"\\t\\t test set: \\t\\t\\t&#123;&#125;\".format(len(data.test.labels)))print(\"\\t\\t validation set:\\t&#123;&#125;\".format(len(data.validation.labels))) (1) 全连接网络 超参数 123456'''超参数'''img_size = 28img_flatten_size = img_size ** 2img_shape = (img_size, img_size)num_classes = 10learning_rate = 1e-4 定义添加一层的函数 num_layer指定是第几层 activation指定激励函数，若不指定跳过1234567891011121314'''定义添加一层'''def add_fully_layer(inputs, input_size, output_size, num_layer, activation=None): with tf.name_scope('layer_'+num_layer): with tf.name_scope('Weights'): W = tf.Variable(initial_value=tf.random_normal(shape=[input_size, output_size]), name='W') with tf.name_scope('biases'): b = tf.Variable(initial_value=tf.zeros(shape=[1, output_size]) + 0.1, name='b') with tf.name_scope('Wx_plus_b'): Wx_plus_b = tf.matmul(inputs, W) + b if activation is not None: outputs = activation(Wx_plus_b) else: outputs = Wx_plus_b return outputs 定义输入，计算图结构，loss和优化器 1234567891011121314151617'''placehoder'''with tf.name_scope('inputs'): x = tf.placeholder(tf.float32, shape=[None, img_flatten_size], name='x') y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y')'''结构'''hidden_layer1 = add_fully_layer(x, img_flatten_size, 20, '1', activation=tf.nn.relu)logits = add_fully_layer(hidden_layer1, 20, num_classes, '2')predictions = tf.nn.softmax(logits)'''loss'''#cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits)cross_entropy = -tf.reduce_sum(y*tf.log(predictions), reduction_indices=[1])with tf.name_scope('losses'): losses = tf.reduce_mean(cross_entropy)with tf.name_scope('train'): train_step = tf.train.AdamOptimizer(learning_rate).minimize(losses) 定义Session和tf.summary.FileWriter 1234'''session'''with tf.Session() as sess: sess.run(tf.global_variables_initializer()) writer = tf.summary.FileWriter('logs', sess.graph) # 将计算图写入文件 最后在logs的上级目录打开命令行输入：tensorboard --logdir=logs/，浏览器中输入网址：http://localhost:6006即可查看 结果 自定义的cross_entropy = -tf.reduce_sum(y*tf.log(predictions), reduction_indices=[1]) 使用tensorflow中自带的cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=predictions) 可以看出tf.name_scope定义的名字就是其中的方框，点击里面的可以查看里面对应的内容 (2) CNN卷积神经网络 添加一层卷积层和pooling层 这里默认pooling使用maxpooling, 大小为212345678910111213'''CNN 定义添加一层卷积层，包括pooling(使用maxpooling, size=2)'''def add_conv_layer(inputs, filter_size, input_channels, output_channels, num_layer, activation=tf.nn.relu): with tf.name_scope('conv_layer_'+num_layer): with tf.name_scope('Weights'): Weights = tf.Variable(tf.truncated_normal(stddev=0.1, shape=[filter_size, filter_size, input_channels, output_channels]), name='W') with tf.name_scope('biases'): b = tf.Variable(tf.constant(0.1, shape=[output_channels])) with tf.name_scope('conv2d'): conv2d_plus_b = tf.nn.conv2d(inputs, Weights, strides=[1,1,1,1], padding='SAME', name='conv') + b activation_conv_outputs = activation(conv2d_plus_b) with tf.name_scope('max_pool'): max_pool_outputs = tf.nn.max_pool(activation_conv_outputs, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') return max_pool_outputs 将卷积层展开 返回展开层和数量（因为全连接会用到）123456789'''将卷积层展开'''def flatten_layer(layer): ''' @param layer: the conv layer ''' layer_shape = layer.get_shape() # 获取形状(layer_shape == [num_images, img_height, img_width, num_channels]) num_features = layer_shape[1:4].num_elements() # [1:4] 是最后3个维度，就是展开的长度 layer_flat = tf.reshape(layer, [-1, num_features]) # 展开 return layer_flat, num_features 定义输入 需要将x转成图片矩阵的形式12345'''placehoder'''with tf.name_scope('inputs'): x = tf.placeholder(tf.float32, shape=[None, img_flatten_size], name='x') y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y') x_image = tf.reshape(x, shape = [-1, img_size, img_size, n_channels], name='x_images') 定义计算图结构 12345678910111213'''CNN卷积网络结构'''conv_layer1 = add_conv_layer(x_image, filter_size=5, input_channels=1, output_channels=32, num_layer='1')conv_layer2 = add_conv_layer(conv_layer1, filter_size=5, input_channels=32, output_channels=64, num_layer='2')'''全连接层'''conv_layer2_flat, num_features = flatten_layer(conv_layer2) # 将最后操作的数据展开hidden_layer1 = add_fully_layer(conv_layer2_flat, num_features, 1000, num_layer='1', activation=tf.nn.relu)logits = add_fully_layer(hidden_layer1, 1000, num_classes, num_layer='2')predictions = tf.nn.softmax(logits) 结果 CNN总结构 第一层卷积和pooling内部结构 (3) RNN_LSTM循环神经网络 声明placeholder 图片中每一行当做当前的输入，共有n_steps=28步遍历完一张图片，所以输入x的shape=(batch_size, n_steps, n_inputs) n_inputs就是一行的像素值12345'''placehoder'''with tf.name_scope('inputs'): '''RNN''' x = tf.placeholder(tf.float32, shape=[batch_size, n_steps, n_inputs], name='x') y = tf.placeholder(tf.float32, shape=[batch_size, num_classes], name='y') 添加一层cell 我们最后只需要遍历n_steps之后的输出即可（遍历完一张图然后分类），所以对应的是final_state[1]（有两个state, 一个是c state,一个是h state， 输出是h state） 12345678910111213'''RNN 添加一层cell'''def add_RNN_Cell(inputs): with tf.name_scope('RNN_LSTM_Cell'): with tf.name_scope('weights'): weights = tf.Variable(tf.random_normal(shape=[state_size, num_classes]), name='W') with tf.name_scope('biases'): biases = tf.Variable(tf.constant(0.1, shape=[num_classes,]), name='b') cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=state_size) init_state = cell.zero_state(batch_size, dtype=tf.float32) rnn_outputs, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=x, initial_state=init_state) logits = tf.matmul(final_state[1], weights) + biases return logits 网络结果和loss 123456789'''RNN网络结构'''logits = add_RNN_Cell(inputs=x)predictions = tf.nn.softmax(logits) '''loss'''#cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=predictions)cross_entropy = -tf.reduce_sum(y*tf.log(predictions), reduction_indices=[1])with tf.name_scope('losses'): losses = tf.reduce_mean(cross_entropy) 结果 总体结构 RNN内部结构 2、可视化训练过程 全部代码：点击查看(1) 权重weights，偏置biases，损失值loss 加入一层全连接层的函数变成这样 加入tf.summary.histogram(name=layer_name+&#39;/Weights&#39;, values=W)即可123456789101112131415161718192021222324'''定义添加一层全连接层'''def add_fully_layer(inputs, input_size, output_size, num_layer, activation=None): layer_name = 'layer_' + num_layer with tf.name_scope(layer_name): with tf.name_scope('Weights'): low = -4*np.sqrt(6.0/(input_size + output_size)) # use 4 for sigmoid, 1 for tanh activation high = 4*np.sqrt(6.0/(input_size + output_size)) #'''xavier方法初始化''' ##sigmoid #Weights = tf.Variable(tf.random_uniform(shape=[input_size, output_size], minval=low, maxval=high, dtype=tf.float32), name='W') ##relu W = tf.Variable(initial_value=tf.random_uniform(shape=[input_size, output_size], minval=low, maxval=high, dtype=tf.float32)/2, name='W') tf.summary.histogram(name=layer_name+'/Weights', values=W) # summary.histogram with tf.name_scope('biases'): b = tf.Variable(initial_value=tf.zeros(shape=[1, output_size]) + 0.1, name='b') tf.summary.histogram(name=layer_name+'/biases', values=b) # summary.histogram with tf.name_scope('Wx_plus_b'): Wx_plus_b = tf.matmul(inputs, W) + b if activation is not None: outputs = activation(Wx_plus_b) else: outputs = Wx_plus_b tf.summary.histogram(name=layer_name+'/outputs', values=outputs) # summary.histogram return outputs 损失 损失因为是个具体的数，所以使用scalar （上面的权重和偏置都是矩阵，向量）1tf.summary.scalar(name='loss_value', tensor=losses) 训练时merge merged = tf.summary.merge_all()合并所有的summary 对于loss, 训练时执行merge, 然后随步数不断加入 merged_result = sess.run(merged, feed_dict=feed_dict_train) # 执行merged writer.add_summary(summary=merged_result, global_step=i)123456789101112131415'''训练'''def optimize(n_epochs): with tf.Session() as sess: merged = tf.summary.merge_all() writer = tf.summary.FileWriter('logs', sess.graph) # 将计算图写入文件 sess.run(tf.global_variables_initializer()) for i in range(n_epochs): batch_x, batch_y = data.train.next_batch(batch_size) feed_dict_train = &#123;x: batch_x, y: batch_y&#125; sess.run(train_step, feed_dict=feed_dict_train) if i % 20 == 0: print(\"epoch:&#123;0&#125;, accuracy:&#123;1&#125;\".format(i, sess.run(accuracy, feed_dict=feed_dict_train))) merged_result = sess.run(merged, feed_dict=feed_dict_train) # 执行merged writer.add_summary(summary=merged_result, global_step=i) # 加入到writeroptimize(1001) 结果 loss 权重和偏置的数据分布 3、可视化embedding 全部代码： 点击查看 12345678910111213141516171819202122232425262728293031323334353637383940414243#-*- coding: utf-8 -*-# Author: Lawlite# Date: 2017/07/26# Associate Blog: http://lawlite.me/2017/06/24/Tensorflow学习-工具相关/#1、可视化embedding# License: MITimport numpy as npimport tensorflow as tffrom tensorflow.contrib.tensorboard.plugins import projectorfrom tensorflow.examples.tutorials.mnist import input_dataimport osMNIST_DATA_PATH = 'MNIST_data'LOG_DIR = 'log'SPRITE_IMAGE_FILE = 'mnist_10k_sprite.png'META_DATA_FILE = 'metadata.tsv'IMAGE_NUM = 100mnist = input_data.read_data_sets(MNIST_DATA_PATH, one_hot=False)plot_array = mnist.test.images[:IMAGE_NUM] # 取前100个图片np.savetxt(os.path.join(LOG_DIR, META_DATA_FILE), mnist.test.labels[:IMAGE_NUM], fmt='%d') # label 保存为metadata.tsv文件'''可视化embedding, 3个步骤'''with tf.Session() as sess: '''1、 将2D矩阵放入Variable中''' embeddings_var = tf.Variable(plot_array, name='embedding') tf.global_variables_initializer().run() '''2、 保存到文件中''' saver = tf.train.Saver() sess.run(embeddings_var.initializer) saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\")) '''3、 关联metadata和sprite图片''' summary_writer = tf.summary.FileWriter(LOG_DIR) config = projector.ProjectorConfig() embedding = config.embeddings.add() embedding.tensor_name = embeddings_var.name embedding.metadata_path = META_DATA_FILE embedding.sprite.image_path = SPRITE_IMAGE_FILE embedding.sprite.single_image_dim.extend([28, 28]) projector.visualize_embeddings(summary_writer, config) 结果 二、Tensorflow 调试tfdbg 官网教程：点击查看 Youtube视频简短教程：点击查看 Tensorflow Debugger (tfdbg)是专业的调试工具，可以查看计算图中内容部的数据等1、本地调试 (1) 加入代码 导入调试的包：from tensorflow.python import debug as tf_debug Wrapper Session和添加filter: filter也可以自己定义123with tf.Session() as sess: sess = tf_debug.LocalCLIDebugWrapperSession(sess) sess.add_tensor_filter(filter_name='inf or nan', tensor_filter=tf_debug.has_inf_or_nan) (2) 运行 命令行中执行：python xxx.py --debug即可进入调试 支持鼠标点击的可以直接点击查看变量的信息 run或者r可以查看所有的tensor的名字等信息 第一次run还没有初始化变量，pt tenser_name打印tensor的信息 再执行一次就是初始化变量 可以进行slice 更多命令行","comments":true,"tags":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://lawlite.cn/tags/Tensorflow/"}]},{"title":"（Unfinished）RNN-循环神经网络之LSTM和GRU-04介绍及推导","date":"2017-06-21T14:45:44.000Z","path":"2017/06/21/RNN-循环神经网络之LSTM和GRU-04介绍及推导/","text":"（Unfinished）尚未完成一、说明 关于LSTM的cell结构和一些计算在之前已经介绍了，可以点击这里查看 本篇博客主要涉及一下内容： LSTM前向计算说明(之前的博客中LSTM部分实际已经提到过，这里结合图更详细说明) 二、LSTM前向计算step by step1、结构review 我们知道RNN的结构如下图 注意cell中的神经元可以有多个 LSTM就是对cell结构的改进 符号说明 LSTM的关键就是state,就是对应上面的主线数据的传递 2、前向计算step by step(1) 决定抛弃的信息 遗忘门 (forget gate layer) $\\sigma$是Sigmoid激励函数，因为它的值域是(0,1)，0代表遗忘所有信息，1代表保留所有信息 (2) 决定存储的新信息 包括两个部分 第一个是输入门 (input gate layer)，对应的是Sigmoid函数 第二个是经过tanh激励函数 (3) 更新state$C_{t-1}$成$C_t$ $f_t$是经过Sigmoid函数的，所以值域在(0,1)之间，$C_{t-1}$点乘0-1之间的数实际就是对$C_{t-1}$的一种缩放，（可以认为是记住之前信息的程度） 然后加入进来的新的信息 (4) 最后计算输出 输出门(output gate layer) 最后再放一下之前的图, 数据流向可能更清晰 三、GRU (Gated Recurrent Unit)1、结构和前向计算 如下图所示 相比LSTM，GRU结合了遗忘门和输入门 同样也合并了cell state和hidden state （就是LSTM中的c和h） GRU比LSTM更加简单 Reference https://colah.github.io/posts/2015-08-Understanding-LSTMs/ https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html#dealing-with-vanishing-and-exploding-gradients http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf http://lawlite.me/2016/12/20/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95-UnderstandingTheDifficultyOfTrainingDeepFeedforwardNeuralNetworks/","comments":true,"tags":[{"name":"Python","slug":"Python","permalink":"http://lawlite.cn/tags/Python/"},{"name":"RNN","slug":"RNN","permalink":"http://lawlite.cn/tags/RNN/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://lawlite.cn/tags/DeepLearning/"},{"name":"LSTM","slug":"LSTM","permalink":"http://lawlite.cn/tags/LSTM/"},{"name":"GRU","slug":"GRU","permalink":"http://lawlite.cn/tags/GRU/"}]},{"title":"RNN-LSTM循环神经网络-03Tensorflow进阶实现","date":"2017-06-21T08:54:28.000Z","path":"2017/06/21/RNN-LSTM循环神经网络-03Tensorflow进阶实现/","text":"全部代码：点击这里查看 关于Tensorflow实现一个简单的二元序列的例子可以点击这里查看 关于RNN和LSTM的基础可以查看这里 这篇博客主要包含以下内容 训练一个RNN模型逐字符生成文本数据(最后的部分) 使用Tensorflow的scan函数实现dynamic_rnn动态创建的效果 使用multiple RNN创建多层的RNN 实现Dropout和Layer Normalization的功能 一、模型说明和数据处理1、模型说明 我们要使用RNN学习一个语言模型(language model)去生成字符序列 githbub上有别人实现好的 Torch中的实现：https://github.com/karpathy/char-rnn Tensorflow中的实现：https://github.com/sherjilozair/char-rnn-tensorflow 接下来我们来看如何实现2、数据处理 数据集使用莎士比亚的一段文集，点击这里查看, 实际也可以使用别的 大小写字符视为不同的字符 下载并读取数据 12345678'''下载数据并读取数据'''file_url = 'https://raw.githubusercontent.com/jcjohnson/torch-rnn/master/data/tiny-shakespeare.txt'file_name = 'tinyshakespeare.txt'if not os.path.exists(file_name): urllib.request.urlretrieve(file_url, filename=file_name)with open(file_name, 'r') as f: raw_data = f.read() print(\"数据长度\", len(raw_data)) 处理字符数据，转换为数字 使用set去重，得到所有的唯一字符 然后一个字符对应一个数字（使用字典） 然后遍历原始数据，得到所有字符对应的数字12345678'''处理字符数据，转换为数字'''vocab = set(raw_data) # 使用set去重，这里就是去除重复的字母(大小写是区分的)vocab_size = len(vocab) idx_to_vocab = dict(enumerate(vocab)) # 这里将set转为了字典，每个字符对应了一个数字0,1,2,3..........(vocab_size-1)vocab_to_idx = dict(zip(idx_to_vocab.values(), idx_to_vocab.keys())) # 这里将字典的(key, value)转换成(value, key)data = [vocab_to_idx[c] for c in raw_data] # 处理raw_data, 根据字符，得到对应的value,就是数字del raw_data 生成batch数据 Tensorflow models给出的PTB模型：https://github.com/tensorflow/models/tree/master/tutorials/rnn/ptb 12345678910'''超参数'''num_steps=200 # 学习的步数batch_size=32state_size=100 # cell的sizenum_classes = vocab_sizelearning_rate = 1e-4def gen_epochs(num_epochs, num_steps, batch_size): for i in range(num_epochs): yield reader.ptb_iterator_oldversion(data, batch_size, num_steps) ptb_iterator函数实现： 返回数据X,Y的shape=[batch_size, num_steps]1234567891011121314151617181920212223242526272829303132def ptb_iterator_oldversion(raw_data, batch_size, num_steps): \"\"\"Iterate on the raw PTB data. This generates batch_size pointers into the raw PTB data, and allows minibatch iteration along these pointers. Args: raw_data: one of the raw data outputs from ptb_raw_data. batch_size: int, the batch size. num_steps: int, the number of unrolls. Yields: Pairs of the batched data, each a matrix of shape [batch_size, num_steps]. The second element of the tuple is the same data time-shifted to the right by one. Raises: ValueError: if batch_size or num_steps are too high. \"\"\" raw_data = np.array(raw_data, dtype=np.int32) data_len = len(raw_data) batch_len = data_len // batch_size data = np.zeros([batch_size, batch_len], dtype=np.int32) for i in range(batch_size): data[i] = raw_data[batch_len * i:batch_len * (i + 1)] epoch_size = (batch_len - 1) // num_steps if epoch_size == 0: raise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\") for i in range(epoch_size): x = data[:, i*num_steps:(i+1)*num_steps] y = data[:, i*num_steps+1:(i+1)*num_steps+1] yield (x, y) 二、使用tf.scan函数和dynamic_rnn1、为什么使用tf.scan和dynamic_rnn 之前我们实现的第一个例子中没有用dynamic_rnn的部分是将输入的三维数据[batch_size,num_steps, state_size]按num_steps维度进行拆分，然后每计算一步都存到list列表中，如下图 这种构建方式很耗时，在我们例子中没有体现出来，但是如果我们要学习的步数很大(num_steps，也可以说要学习的依赖关系很长），如果再使用深层的RNN，这种就不合适了 为了方便比较和dynamic_rnn的运行耗时，下面还是给出使用list 2、使用list的方式(static_rnn) 构建计算图 我这里tensorflow的版本是1.2.0，与1.0 些许不一样 和之前的例子差不多，这里不再累述12345678910111213141516171819202122232425262728293031323334353637383940414243444546'''使用list的方式'''def build_basic_rnn_graph_with_list( state_size = state_size, num_classes = num_classes, batch_size = batch_size, num_steps = num_steps, num_layers = 3, learning_rate = learning_rate): reset_graph() x = tf.placeholder(tf.int32, [batch_size, num_steps], name='x') y = tf.placeholder(tf.int32, [batch_size, num_steps], name='y') x_one_hot = tf.one_hot(x, num_classes) # (batch_size, num_steps, num_classes) '''这里按第二维拆开num_steps*(batch_size, num_classes)''' rnn_inputs = [tf.squeeze(i,squeeze_dims=[1]) for i in tf.split(x_one_hot, num_steps, 1)] cell = tf.nn.rnn_cell.BasicRNNCell(state_size) init_state = cell.zero_state(batch_size, tf.float32) '''使用static_rnn方式''' rnn_outputs, final_state = tf.contrib.rnn.static_rnn(cell=cell, inputs=rnn_inputs, initial_state=init_state) #rnn_outputs, final_state = tf.nn.rnn(cell, rnn_inputs, initial_state=init_state) # tensorflow 1.0的方式 with tf.variable_scope('softmax'): W = tf.get_variable('W', [state_size, num_classes]) b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0)) logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs] y_as_list = [tf.squeeze(i, squeeze_dims=[1]) for i in tf.split(y, num_steps, 1)] #loss_weights = [tf.ones([batch_size]) for i in range(num_steps)] losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_as_list, logits=logits) #losses = tf.nn.seq2seq.sequence_loss_by_example(logits, y_as_list, loss_weights) # tensorflow 1.0的方式 total_loss = tf.reduce_mean(losses) train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss) return dict( x = x, y = y, init_state = init_state, final_state = final_state, total_loss = total_loss, train_step = train_step ) 训练神经网络函数 和之前例子类似123456789101112131415161718192021222324252627'''训练rnn网络的函数'''def train_rnn(g, num_epochs, num_steps=num_steps, batch_size=batch_size, verbose=True, save=False): tf.set_random_seed(2345) with tf.Session() as sess: sess.run(tf.initialize_all_variables()) training_losses = [] for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps, batch_size)): training_loss = 0 steps = 0 training_state = None for X, Y in epoch: steps += 1 feed_dict = &#123;g['x']: X, g['y']: Y&#125; if training_state is not None: feed_dict[g['init_state']] = training_state training_loss_, training_state, _ = sess.run([g['total_loss'], g['final_state'], g['train_step']], feed_dict=feed_dict) training_loss += training_loss_ if verbose: print('epoch: &#123;0&#125;的平均损失值：&#123;1&#125;'.format(idx, training_loss/steps)) training_losses.append(training_loss/steps) if isinstance(save, str): g['saver'].save(sess, save) return training_losses 调用执行： 123456start_time = time.time()g = build_basic_rnn_graph_with_list()print(\"构建图耗时\", time.time()-start_time)start_time = time.time()train_rnn(g, 3)print(\"训练耗时：\", time.time()-start_time) 运行结果 构建计算图耗时: 113.43532419204712 3个epoch运行耗时：1234epoch: 0的平均损失值：3.6314958388777985epoch: 1的平均损失值：3.287133811534136epoch: 2的平均损失值：3.250853428895446训练耗时： 84.2816972732544 可以看出在构建图的时候非常耗时，这里仅仅一层的cell 3、dynamic_rnn的使用 之前在我们第一个例子中实际已经使用过了，这里使用MultiRNNCell实现多层cell，具体下面再讲 构建模型： tf.nn.embedding_lookup(params, ids)函数是在params中查找ids的表示， 和在matrix中用array索引类似, 这里是在二维embeddings中找二维的ids, ids每一行中的一个数对应embeddings中的一行，所以最后是[batch_size, num_steps, state_size]，关于具体的输出可以查看这里 这里我认为就是某个字母的表示,之前上面我们的statci_rnn就是one-hot来表示的 12345678910111213141516171819202122232425262728293031323334353637383940414243'''使用dynamic_rnn方式 - 之前我们自己实现的cell和static_rnn的例子都是将得到的tensor使用list存起来，这种方式构建计算图时很慢 - dynamic可以在运行时构建计算图'''def build_multilayer_lstm_graph_with_dynamic_rnn( state_size = state_size, num_classes = num_classes, batch_size = batch_size, num_steps = num_steps, num_layers = 3, learning_rate = learning_rate ): reset_graph() x = tf.placeholder(tf.int32, [batch_size, num_steps], name='x') y = tf.placeholder(tf.int32, [batch_size, num_steps], name='y') embeddings = tf.get_variable(name='embedding_matrix', shape=[num_classes, state_size]) '''这里的输入是三维的[batch_size, num_steps, state_size] - embedding_lookup(params, ids)函数是在params中查找ids的表示， 和在matrix中用array索引类似, 这里是在二维embeddings中找二维的ids, ids每一行中的一个数对应embeddings中的一行，所以最后是[batch_size, num_steps, state_size] ''' rnn_inputs = tf.nn.embedding_lookup(params=embeddings, ids=x) cell = tf.nn.rnn_cell.LSTMCell(num_units=state_size, state_is_tuple=True) cell = tf.nn.rnn_cell.MultiRNNCell(cells=[cell]*num_layers, state_is_tuple=True) init_state = cell.zero_state(batch_size, dtype=tf.float32) '''使用dynamic_rnn方式''' rnn_outputs, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=rnn_inputs, initial_state=init_state) with tf.variable_scope('softmax'): W = tf.get_variable('W', [state_size, num_classes]) b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0)) rnn_outputs = tf.reshape(rnn_outputs, [-1, state_size]) # 转成二维的矩阵 y_reshape = tf.reshape(y, [-1]) logits = tf.matmul(rnn_outputs, W) + b # 进行矩阵运算 total_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_reshape)) train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss) return dict(x = x, y = y, init_state = init_state, final_state = final_state, total_loss = total_loss, train_step = train_step) 调用执行即可 123456start_time = time.time()g = build_multilayer_lstm_graph_with_dynamic_rnn()print(\"构建图耗时\", time.time()-start_time)start_time = time.time()train_rnn(g, 3)print(\"训练耗时：\", time.time()-start_time) 运行结果（注意这是3层的LSTM）： 构建计算图耗时 7.616888523101807，相比第一种static_rnn很快 训练耗时(这是3层的LSTM，所以还是挺慢的)：1234epoch: 0的平均损失值：3.604653576324726epoch: 1的平均损失值：3.3202743626188957epoch: 2的平均损失值：3.3155322650383257训练耗时： 303.5468375682831 4、tf.scan实现的方式 如果你不了解tf.scan，建议看下官方API, 还是有点复杂的。 或者Youtube上有个介绍，点击这里查看 scan是个高阶函数，一般的计算方式是：给定一个序列$[x_0, x_1,…..,x_n]$和初试状态$y_{-1}$,根据$y_t = f(x_t, y_{t-1})$ 计算得到最终序列$[y_0, y_1,……,y_n]$ 构建计算图 tf.transpose(rnn_inputs, [1,0,2]) 是将rnn_inputs的第一个和第二个维度调换，即变成[num_steps,batch_size, state_size], 在dynamic_rnn函数有个time_major参数，就是指定num_steps是否在第一个维度上，默认是false的,即不在第一维 tf.scan会将elems按照第一维拆开，所以一次就是一个step的数据（和我们static_rnn的例子类似） 参数a的结构和initializer的结构一致，所以a[1]就是对应的state，cell需要传入x和state计算 每次迭代cell返回的是一个rnn_output, shape=(batch_size,state_size)和对应的state,num_steps之后的rnn_outputs的shape就是(num_steps, batch_size, state_size) ，state同理 每次输入的x都会得到的state--&gt;(final_states)，我们只要的最后的final_state 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455'''使用scan实现dynamic_rnn的效果'''def build_multilayer_lstm_graph_with_scan( state_size = state_size, num_classes = num_classes, batch_size = batch_size, num_steps = num_steps, num_layers = 3, learning_rate = learning_rate ): reset_graph() x = tf.placeholder(tf.int32, [batch_size, num_steps], name='x') y = tf.placeholder(tf.int32, [batch_size, num_steps], name='y') embeddings = tf.get_variable(name='embedding_matrix', shape=[num_classes, state_size]) '''这里的输入是三维的[batch_size, num_steps, state_size]''' rnn_inputs = tf.nn.embedding_lookup(params=embeddings, ids=x) '''构建多层的cell, 先构建一个cell, 然后使用MultiRNNCell函数构建即可''' cell = tf.nn.rnn_cell.LSTMCell(num_units=state_size, state_is_tuple=True) cell = tf.nn.rnn_cell.MultiRNNCell(cells=[cell]*num_layers, state_is_tuple=True) init_state = cell.zero_state(batch_size, dtype=tf.float32) '''使用tf.scan方式 - tf.transpose(rnn_inputs, [1,0,2]) 是将rnn_inputs的第一个和第二个维度调换，即[num_steps,batch_size, state_size], 在dynamic_rnn函数有个time_major参数，就是指定num_steps是否在第一个维度上，默认是false的,即不在第一维 - tf.scan会将elems按照第一维拆开，所以一次就是一个step的数据（和我们static_rnn的例子类似） - a的结构和initializer的结构一致，所以a[1]就是对应的state，cell需要传入x和state计算 - 每次迭代cell返回的是一个rnn_output(batch_size,state_size)和对应的state,num_steps之后的rnn_outputs的shape就是(num_steps, batch_size, state_size) - 每次输入的x都会得到的state(final_states)，我们只要的最后的final_state ''' def testfn(a, x): return cell(x, a[1]) rnn_outputs, final_states = tf.scan(fn=testfn, elems=tf.transpose(rnn_inputs, [1,0,2]), initializer=(tf.zeros([batch_size,state_size]),init_state) ) '''或者使用lambda的方式''' #rnn_outputs, final_states = tf.scan(lambda a,x: cell(x, a[1]), tf.transpose(rnn_inputs, [1,0,2]), #initializer=(tf.zeros([batch_size, state_size]),init_state)) final_state = tuple([tf.nn.rnn_cell.LSTMStateTuple( tf.squeeze(tf.slice(c, [num_steps-1,0,0], [1,batch_size,state_size])), tf.squeeze(tf.slice(h, [num_steps-1,0,0], [1,batch_size,state_size]))) for c, h in final_states]) with tf.variable_scope('softmax'): W = tf.get_variable('W', [state_size, num_classes]) b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0)) rnn_outputs = tf.reshape(rnn_outputs, [-1, state_size]) y_reshape = tf.reshape(y, [-1]) logits = tf.matmul(rnn_outputs, W) + b total_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_reshape)) train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss) return dict(x = x, y = y, init_state = init_state, final_state = final_state, total_loss = total_loss, train_step = train_step) 运行结果 构建计算图耗时: 8.685610055923462 （比dynamic_rnn稍微慢一点） 训练耗时（和dynamic_rnn耗时差不多） 使用scan的方式只比dynamic_rnn慢一点点，但是对我们来说更加灵活和清楚执行的过程。也方便我们修改代码（比如从state的t-2时刻跳过一个时刻直接到t） 1234epoch: 0的平均损失值：3.6226147892831384epoch: 1的平均损失值：3.3211338095281318epoch: 2的平均损失值：3.3158331972429123训练耗时： 303.2535448074341 三、关于多层RNN1、结构 LSTM中包含两个state,一个是c记忆单元（memory cell），另外一个是h隐藏状态(hidden state), 在Tensorflow中是以tuple元组的形式，所以才有上面构建dynamic_rnn时的参数state_is_tuple的参数，这种方式执行更快 多层的结构如下图 我们可以将其包装起来, 看起来像一个cell一样 2、代码 Tensorflow中的实现就是使用tf.nn.rnn_cell.MultiRNNCell 声明一个cell MultiRNNCell中传入[cell]*num_layers就可以了 注意如果是LSTM，定义参数state_is_tuple=True123cell = tf.nn.rnn_cell.LSTMCell(num_units=state_size, state_is_tuple=True)cell = tf.nn.rnn_cell.MultiRNNCell(cells=[cell]*num_layers, state_is_tuple=True)init_state = cell.zero_state(batch_size, dtype=tf.float32) 四、Dropout操作 应用在一层cell的输入和输出，不应用在循环的部分 1、一层的cell static_rnn中实现 声明placeholder：keep_prob = tf.placeholder(tf.float32, name=&#39;keep_prob&#39;) 输入：rnn_inputs = [tf.nn.dropout(rnn_input, keep_prob) for rnn_input in rnn_inputs] 输出：rnn_outputs = [tf.nn.dropout(rnn_output, keep_prob) for rnn_output in rnn_outputs] feed_dict中加入即可：feed_dict = {g[&#39;x&#39;]: X, g[&#39;y&#39;]: Y, g[&#39;keep_prob&#39;]: keep_prob} dynamic_rnn或者scan中实现 直接添加即可，其余类似：rnn_inputs = tf.nn.dropout(rnn_inputed, keep_prob) 2、多层cell 我们之前说使用MultiRNNCell将多层cell看作一个cell, 那么怎么实现对每层cell使用dropout呢 可以使用tf.nn.rnn_cell.DropoutWrapper来实现 方式一：cell = tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=input_keep_prob, output_keep_prob=output_drop_prob) 如果同时使用了input_keep_prob和output_keep_prob都是0.9, 那么层之间的drop_out=0.9*0.9=0.81 方式二: 对于basic cell只使用一个input_keep_prob或者output_keep_prob，对MultiRNNCell也使用一个input_keep_prob或者output_keep_prob 1234cell = tf.nn.rnn_cell.LSTMCell(num_units=state_size, state_is_tuple=True)cell = tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=keep_prob)cell = tf.nn.rnn_cell.MultiRNNCell(cells=[cell]*num_layers, state_is_tuple=True)cell = tf.nn.rnn_cell.DropoutWrapper(cell,output_keep_prob=keep_prob) 五、层标准化 (Layer Normalization)1、说明 Layer Normalization是受Batch Normalization的启发而来，针对于RNN，可以查看相关论文 Batch Normalization主要针对于传统的深度神经网络和CNN，关于Batch Normalization的操作和推导可以看我之前的博客 可以加快训练的速度，得到更好的结果等 2、代码 找到LSTMCell的源码拷贝一份修改即可 layer normalization函数 传入的tensor是二维的，对其进行batch normalization操作 tf.nn.moment是计算tensor的mean value和variance value 然后对其进行缩放(scale)和平移(shift)123456789101112131415'''layer normalization'''def ln(tensor, scope=None, epsilon=1e-5): assert(len(tensor.get_shape()) == 2) m, v = tf.nn.moments(tensor, [1], keep_dims=True) if not isinstance(scope, str): scope = '' with tf.variable_scope(scope+'layer_norm'): scale = tf.get_variable(name='scale', shape=[tensor.get_shape()[1]], initializer=tf.constant_initializer(1)) shift = tf.get_variable('shift', [tensor.get_shape()[1]], initializer=tf.constant_initializer(0)) LN_initial = (tensor - m) / tf.sqrt(v + epsilon) return LN_initial*scale + shift LSTMCell中的call方法i,j,f,o调用layer normalization操作 _linear函数中的bias设为False， 因为BN会加上shift123456789'''这里bias设置为false, 因为bn会加上shift'''lstm_matrix = _linear([inputs, m_prev], 4 * self._num_units, bias=False)i, j, f, o = array_ops.split( value=lstm_matrix, num_or_size_splits=4, axis=1)'''执行ln'''i = ln(i, scope = 'i/')j = ln(j, scope = 'j/')f = ln(f, scope = 'f/')o = ln(o, scope = 'o/') 构建计算图 可以选择RNN GRU LSTM Dropout Layer Normalization123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960'''最终的整合模型， - 普通RNN，GRU，LSTM - dropout - BN'''from LayerNormalizedLSTMCell import LayerNormalizedLSTMCell # 导入layer normalization的LSTMCell 文件def build_final_graph( cell_type = None, state_size = state_size, num_classes = num_classes, batch_size = batch_size, num_steps = num_steps, num_layers = 3, build_with_dropout = False, learning_rate = learning_rate): reset_graph() x = tf.placeholder(tf.int32, [batch_size, num_steps], name='x') y = tf.placeholder(tf.int32, [batch_size, num_steps], name='y') keep_prob = tf.placeholder(tf.float32, name='keep_prob') embeddings = tf.get_variable('embedding_matrix', [num_classes, state_size]) rnn_inputs = tf.nn.embedding_lookup(embeddings, x) if cell_type == 'GRU': cell = tf.nn.rnn_cell.GRUCell(state_size) elif cell_type == 'LSTM': cell = tf.nn.rnn_cell.LSTMCell(state_size, state_is_tuple=True) elif cell_type == 'LN_LSTM': cell = LayerNormalizedLSTMCell(state_size) # 自己修改的代码，导入对应的文件 else: cell = tf.nn.rnn_cell.BasicRNNCell(state_size) if build_with_dropout: cell = tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=keep_prob) init_state = cell.zero_state(batch_size, tf.float32) '''dynamic_rnn''' rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state) with tf.variable_scope('softmax'): W = tf.get_variable('W', [state_size, num_classes]) b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0)) rnn_outputs = tf.reshape(rnn_outputs, [-1, state_size]) y_reshaped = tf.reshape(y, [-1]) logits = tf.matmul(rnn_outputs, W) + b predictions = tf.nn.softmax(logits) total_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)) train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss) return dict( x = x, y = y, keep_prob = keep_prob, init_state = init_state, final_state = final_state, total_loss = total_loss, train_step = train_step, preds = predictions, saver = tf.train.Saver() ) 六、生成文本1、说明 训练完成之后将计算图保存到本地磁盘，下次直接读取就可以了 我们给出第一个字符，RNN接着一个个生成字符，每次都是根据前一个字符 所以num_steps=1, batch_size=1（可以想象生成prediction的shape是(1, num_classes)中选择一个概率,–&gt; num_steps=1 ） 2、代码 构建图（直接传入参数即可）：g = build_final_graph(cell_type=&#39;LN_LSTM&#39;, num_steps=1, batch_size=1) 生成文本 读取训练好的文件 得到给出的第一个字符对应的数字 循环遍历要生成多少个字符， 每次循环生成一个字符123456789101112131415161718192021222324252627'''生成文本'''def generate_characters(g, checkpoint, num_chars, prompt='A', pick_top_chars=None): with tf.Session() as sess: sess.run(tf.global_variables_initializer()) g['saver'].restore(sess, checkpoint) # 读取文件 state = None current_char = vocab_to_idx[prompt] # 得到给出的字母对应的数字 chars = [current_char] for i in range(num_chars): # 总共生成多少数字 if state is not None: # 第一次state为None,因为计算图中定义了刚开始为0 feed_dict=&#123;g['x']: [[current_char]], g['init_state']: state&#125; # 传入当前字符 else: feed_dict=&#123;g['x']: [[current_char]]&#125; preds, state = sess.run([g['preds'],g['final_state']], feed_dict) # 得到预测结果（概率）preds的shape就是（1，num_classes） if pick_top_chars is not None: # 如果设置了概率较大的前多少个 p = np.squeeze(preds) p[np.argsort(p)[:-pick_top_chars]] = 0 # 其余的置为0 p = p / np.sum(p) # 因为下面np.random.choice函数p的概率和要求是1，处理一下 current_char = np.random.choice(vocab_size, 1, p=p)[0] # 根据概率选择一个 else: current_char = np.random.choice(vocab_size, 1, p=np.squeeze(preds))[0] chars.append(current_char) chars = map(lambda x: idx_to_vocab[x], chars) result = \"\".join(chars) print(result) return result 结果 由于训练耗时很长，这里使用LSTM训练了30个epoch，结果如下 可以自己调整参数，可能会得到更好的结果123456789101112131415161718192021222324252627282930313233ANKO: HFOFMFRone s the statlighte thithe thit.BODEN --I I's a tomir.I'tshis and on ar tald the theand this he sile be cares hat s ond tho fo hour he singe sime shind and somante tat ond treang tatsing of the an the to to fook.. Ir ard the with ane she stale..ANTE --KINEShow the ard and a beat the weringe be thing or.Bo hith tho he melan to the mute steres.The singer stis ard stis.BACE CANKONS CORESard the sids ing tho the the sackes tom theINWe stoe shit a dome thorate seomser hith.Thatthow oundTANTONT. SEAT THONTITE SERTI 1 23SHe the mathe a tomonerind is ingit ofres treacentit. Sher stard on this the tor an the candin he whor he sath heres andstha dortour tit thas stand. I'd and or a #2017/06/25 运行结果更新 更换了一个大点的数据集，点击查看，使用了layer normalized的LSTM模型 参数设置： num_steps=80 batch_size=50 state_size=512 num_classes = vocab_size learning_rate = 5e-4 30个epochs 在实验室电脑跑了一晚上，结果是不是好一点了1234567891011121314151617181920212223242526272829303132333435AKTIN: Yousa hand it have to turn you, sir.I have. I've got to here hard on myplay as a space state, and why hehappened. What we alwaws whothis?JOCASTAND :PADM You, sir!A battle. An arm of the ship is still.THE WINDEN'S CORUSHan's laser guns at the forest fire. The crowd spots his blackfolkwark and sees the bedroom and twists and sees Leiawho is shaking. A huge creature has a long time,hold her hand and his timmed, that we see the saulyand. Thecrowd ruised by the staircase.EXT. MAZ' CASTLE RUINS - DAYRey and Wicket and CAMERA is heard. Here as so they helfthis tonight, he spins and sit in a startled bright.LUKE(into propecy)The defenstity! Thank you.LUKEI'm afraid to have a lossing live,or help. We're Reference https://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html https://karpathy.github.io/2015/05/21/rnn-effectiveness/ http://jmlr.org/proceedings/papers/v37/ioffe15.pdf tensorflow scan： https://www.tensorflow.org/api_docs/python/tf/scan https://www.youtube.com/watch?v=A6qJMB3stE4&amp;t=621s","comments":true,"tags":[{"name":"Python","slug":"Python","permalink":"http://lawlite.cn/tags/Python/"},{"name":"RNN","slug":"RNN","permalink":"http://lawlite.cn/tags/RNN/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://lawlite.cn/tags/DeepLearning/"},{"name":"LSTM","slug":"LSTM","permalink":"http://lawlite.cn/tags/LSTM/"}]},{"title":"RNN-循环神经网络-02Tensorflow中的实现","date":"2017-06-16T12:59:28.000Z","path":"2017/06/16/RNN-循环神经网络-02Tensorflow中的实现/","text":"关于基本的RNN和LSTM的概念和BPTT算法可以查看这里 参考文章： https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html https://r2rt.com/styles-of-truncated-backpropagation.html 一、源代码实现一个binary例子1、例子描述(1) 数据描述 输入数据X是二进制的一串序列, 在t时刻，有50%的概率是1，50%的概率是0，比如：X=[1,1,0,0,1,0.....] 输出数据Y： 在时刻t，50%的概率是1，50%的概率是0； 如果$X_{t-3}$是1，则$Y_{t}$ 100%是1（增加50%）； 如果$X_{t-8}$是1，则$Y_{t}$ 25%是1（减少25%）； 所以如果$X_{t-3}$和$X_{t-8}$都是1，则$Y_{t}$ 50%+50%-25%=75%的概率是1 所以，输出数据是有两个依赖关系的 (2) 损失函数 使用cross-entropy损失函数进行训练 这里例子很简单，根据数据生成的规则，我们可以简单的计算一下不同情况下的cross-entropy值 [1] 如果rnn没有学到两个依赖关系, 则最终预测正确的概率是62.5%，cross entropy值为0.66计算如下 ${X_{t-3}}=\\{ {\\matrix{{1} \\rightarrow X_{t-8}=\\{ {\\matrix{{ 1 \\rightarrow 0.5+0.5-0.25=0.75} \\cr{ 0 \\rightarrow 0.5+0.5=1 \\quad \\quad \\quad \\quad} \\cr}} \\cr{0} \\rightarrow X_{t-8} = \\{ {\\matrix{{1 \\rightarrow 0.5-0.25=0.25 } \\quad \\quad\\cr{0 \\rightarrow 0.5 \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad} \\cr}}\\cr}}$ 所以正确预测1的概率为：(0.75+1+0.25+0.5)/4=0.625 所以cross entropy值为：-[plog(p)+(1-p)log(1-p)]=0.66 [2] 如果rnn学到第一个依赖关系，50%的情况下预测准确度为87.5%，50%的情况下预测准确度为62.5%，cross entropy值为0.52 因为X是随机生成，0/1各占50%,想象生成了很多的数，根据大数定律，50%的情况是1，对应到 [1] 中的上面的情况就是:(0.75+1)/2=0.875的概率预测正确，其余的50%就和[1]中一样了（去除学到的一个依赖，其余就是没有学到依赖）62.5% 损失值：-0.5 * (0.875 * .log(0.875) + 0.125 * log(0.125))-0.5 * (0.625 * np.log(0.625) + 0.375 * log(0.375)))=0.52 [3] 如果rnn两个依赖都学到了，则25%的情况下100%预测正确，25%的情况下50%预测正确，50%的情况向75%预测正确，cross entropy值为0.45 1/4的情况就是$X_{t-3}=1 和 X_{t-8}=0$ 100%预测正确 1/4的情况就是$X_{t-3}=0 和 X_{t-8}=0$ 50%预测正确 1/2的情况75%预测正确（0.5+0.5-0.25） 损失值：-0.50 * (0.75 * np.log(0.75) + 0.25 * np.log(0.25)) - 0.25 * (2 * 0.50 * np.log (0.50)) - 0.25 * (0) = 0.45 2、网络结构 根据时刻t的输入向量$X_t$和时刻t-1的状态向量state $S_{t-1}$计算得出当前的状态向量$S_t$和输出的结果概率向量$P_t$ Label数据是Y 所以有：$${S_t} = {tanh(W(X_t \\bigoplus S_{t-1})) + b_s}$$ $${P_t = softmax(US_t + b_p)}$$ 这里$\\bigoplus$表示向量的拼接 $W \\in R^{d \\times (2+d)}, {b_s} \\in R^d , U \\in R^{2 \\times d}, b_p \\in R^2$ d是 state 向量的长度 W是二维的矩阵，因为是将$X_t 和 S_{t-1}$拼接起来和W运算的，2对应输入的X one-hot之后，所以是2 U是最后输出预测的权值 初始化state $S_{-1}$ 为0向量 需要注意的是 cell 并不一定是只有一个neuron unit，而是有n个hidden units 下图的state size=4 3、Tensorflow中RNN BPTT实现方式1) 截断反向传播（truncated backpropagation） 假设我们训练含有1000000个数据的序列，如果全部训练的话，整个的序列都feed进RNN中，容易造成梯度消失或爆炸的问题 所以解决的方法就是truncated backpropagation，我们将序列截断来进行训练(num_steps) 2) tensorflow中的BPTT算法实现 一般截断的反向传播是：在当前时间t,往前反向传播num_steps步即可 如下图，长度为6的序列，截断步数是3 但是Tensorflow中的实现并不是这样(如下图) 它是将长度为6的序列分为了两部分，每一部分长度为3 前一部分计算得到的final state用于下一部分计算的initial state 所以tensorflow风格的反向传播并没有有效的反向传播num_steps步(对比一般的方式，依赖关系变的弱一些) 所以比如想要学习有8依赖关系的序列（我们的例子中就是），一般要设置的大于8 另外，有人做实验比较了两种方式here，发现一般的实现方式中的n步和Tensorflow中截断设置为2n的结果相似 3) 关于这个例子，tensorflow风格的实现 如下图，num_steps=5, state_size=4，就是截断反向传播的步数truncated backprop steps是5步，state_size就是cell中的神经元的个数 如果需要截断的步数增多，可以适当增加state_size来记录更多的信息 好比传统的神经网络，就是增加隐藏层的神经元个数 途中的注释是下面的列子代码中定义变量的shape, 可以对照参考 4、自己实现例子中的RNN 全部代码：https://github.com/lawlite19/Blog-Back-Up/blob/master/code/rnn/rnn_implement.py 1) 实现过程 导入包： 1234import numpy as npimport tensorflow as tffrom tensorflow.python import debug as tf_debugimport matplotlib.pyplot as plt 超参数 这里num_steps=5就是只能记忆5步, 所以只能学习到一个依赖(因为至少8步才能学到第二个依赖)，我们看结果最后的cross entropy是否在0.52左右123456'''超参数'''num_steps = 5batch_size = 200num_classes = 2state_size = 4learning_rate = 0.1 生成数据 就是按照我们描述的规则 123456789101112131415161718'''生成数据就是按照文章中提到的规则，这里生成1000000个'''def gen_data(size=1000000): X = np.array(np.random.choice(2, size=(size,))) Y = [] '''根据规则生成Y''' for i in range(size): threshold = 0.5 if X[i-3] == 1: threshold += 0.5 if X[i-8] == 1: threshold -=0.25 if np.random.rand() &gt; threshold: Y.append(0) else: Y.append(1) return X, np.array(Y) 生成batch数据，因为我们使用sgd训练 12345678910111213141516171819'''生成batch数据'''def gen_batch(raw_data, batch_size, num_step): raw_x, raw_y = raw_data data_length = len(raw_x) batch_patition_length = data_length // batch_size # -&gt;5000 data_x = np.zeros([batch_size, batch_patition_length], dtype=np.int32) # -&gt;(200, 5000) data_y = np.zeros([batch_size, batch_patition_length], dtype=np.int32) # -&gt;(200, 5000) '''填到矩阵的对应位置''' for i in range(batch_size): data_x[i] = raw_x[batch_patition_length*i:batch_patition_length*(i+1)]# 每一行取batch_patition_length个数，即5000 data_y[i] = raw_y[batch_patition_length*i:batch_patition_length*(i+1)] epoch_size = batch_patition_length // num_steps # -&gt;5000/5=1000 就是每一轮的大小 for i in range(epoch_size): # 抽取 epoch_size 个数据 x = data_x[:, i * num_steps:(i + 1) * num_steps] # -&gt;(200, 5) y = data_y[:, i * num_steps:(i + 1) * num_steps] yield (x, y) # yield 是生成器，生成器函数在生成值后会自动挂起并暂停他们的执行和状态（最后就是for循环结束后的结果，共有1000个(x, y)）def gen_epochs(n, num_steps): for i in range(n): yield gen_batch(gen_data(), batch_size, num_steps) 定义RNN的输入 这里每个数需要one-hot处理 unstack方法就是将n维的数据拆成若开个n-1的数据，axis指定根据哪个维度拆的，比如(200,5,2)三维数据，按axis=1会有5个(200,2)的二维数据1234567'''定义placeholder'''x = tf.placeholder(tf.int32, [batch_size, num_steps], name=\"x\")y = tf.placeholder(tf.int32, [batch_size, num_steps], name='y')init_state = tf.zeros([batch_size, state_size])'''RNN输入'''x_one_hot = tf.one_hot(x, num_classes)rnn_inputs = tf.unstack(x_one_hot, axis=1) 定义RNN的cell（关键步骤） 这里关于name_scope和variable_scope的用法可以查看这里12345678910'''定义RNN cell'''with tf.variable_scope('rnn_cell'): W = tf.get_variable('W', [num_classes + state_size, state_size]) b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0)) def rnn_cell(rnn_input, state): with tf.variable_scope('rnn_cell', reuse=True): W = tf.get_variable('W', [num_classes+state_size, state_size]) b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0)) return tf.tanh(tf.matmul(tf.concat([rnn_input, state],1),W) + b) 将cell添加到计算图中 1234567'''将rnn cell添加到计算图中'''state = init_staternn_outputs = []for rnn_input in rnn_inputs: state = rnn_cell(rnn_input, state) # state会重复使用，循环 rnn_outputs.append(state)final_state = rnn_outputs[-1] # 得到最后的state 定义预测，损失函数，和优化方法 sparse_softmax_cross_entropy_with_logits会自动one-hot1234567891011'''预测，损失，优化'''with tf.variable_scope('softmax'): W = tf.get_variable('W', [state_size, num_classes]) b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]predictions = [tf.nn.softmax(logit) for logit in logits]y_as_list = tf.unstack(y, num=num_steps, axis=1)losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label,logits=logit) for logit, label in zip(logits, y_as_list)]total_loss = tf.reduce_mean(losses)train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss) 训练网络 123456789101112131415161718192021'''训练网络'''def train_rnn(num_epochs, num_steps, state_size=4, verbose=True): with tf.Session() as sess: sess.run(tf.global_variables_initializer()) #sess = tf_debug.LocalCLIDebugWrapperSession(sess) training_losses = [] for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)): training_loss = 0 training_state = np.zeros((batch_size, state_size)) # -&gt;(200, 4) if verbose: print('\\nepoch', idx) for step, (X, Y) in enumerate(epoch): tr_losses, training_loss_, training_state, _ = \\ sess.run([losses, total_loss, final_state, train_step], feed_dict=&#123;x:X, y:Y, init_state:training_state&#125;) training_loss += training_loss_ if step % 100 == 0 and step &gt; 0: if verbose: print('第 &#123;0&#125; 步的平均损失 &#123;1&#125;'.format(step, training_loss/100)) training_losses.append(training_loss/100) training_loss = 0 return training_losses 显示结果 1234training_losses = train_rnn(num_epochs=1, num_steps=num_steps, state_size=state_size)print(training_losses[0])plt.plot(training_losses)plt.show() 2) 实验结果 num_steps=5, state=4 可以看到初试的损失值大约0.66, 最后学到一个依赖关系，最终损失值0.52左右 num_step=10, state=16 学到了两个依赖，最终损失值接近0.45 5、使用Tensorflow的cell实现1) 使用static rnn方式 将我们之前自己实现的cell和添加到计算图中步骤改为如下即可 123cell = tf.contrib.rnn.BasicRNNCell(num_units=state_size)rnn_outputs, final_state = tf.contrib.rnn.static_rnn(cell=cell, inputs=rnn_inputs, initial_state=init_state) 2) 使用dynamic_rnn方式 这里仅仅替换cell就不行了，RNN输入 直接就是三维的形式12'''RNN输入'''rnn_inputs = tf.one_hot(x, num_classes) 使用dynamic_rnn 12cell = tf.contrib.rnn.BasicRNNCell(num_units=state_size)rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state) 预测，损失 由于rnn_inputs是三维的，所以先转成二维的，计算结束后再转换回三维[batch_size, num_steps, num_classes]12345678910 '''因为rnn_outputs是三维的，这里需要将其转成2维的， 矩阵运算后再转换回来[batch_size, num_steps, num_classes]'''logits = tf.reshape(tf.matmul(tf.reshape(rnn_outputs, [-1, state_size]), W) +b, \\ shape=[batch_size, num_steps, num_classes])predictions = tf.nn.softmax(logits)y_as_list = tf.unstack(y, num=num_steps, axis=1)losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)total_loss = tf.reduce_mean(losses)train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss) Reference https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html https://r2rt.com/styles-of-truncated-backpropagation.html https://web.stanford.edu/class/psych209a/ReadingsByDate/02_25/Williams%20Zipser95RecNets.pdf","comments":true,"tags":[{"name":"Python","slug":"Python","permalink":"http://lawlite.cn/tags/Python/"},{"name":"RNN","slug":"RNN","permalink":"http://lawlite.cn/tags/RNN/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://lawlite.cn/tags/DeepLearning/"}]},{"title":"RNN-循环神经网络和LSTM_01基础","date":"2017-06-14T15:42:32.000Z","path":"2017/06/14/RNN-循环神经网络和LSTM-01基础/","text":"一、介绍1、什么是RNN 传统的神经网络是层与层之间是全连接的，但是每层之间的神经元是没有连接的（其实是假设各个数据之间是独立的） 这种结构不善于处理序列化的问题。比如要预测句子中的下一个单词是什么，这往往与前面的单词有很大的关联，因为句子里面的单词并不是独立的。 RNN 的结构说明当前的的输出与前面的输出也有关，即隐层之间的节点不再是无连接的，而是有连接的 基本的结构如图，可以看到有个循环的结构，将其展开就是右边的结构 2、运算说明 如上图，输入单元(inputs units): $\\{ {x_0},{x_1}, \\cdots \\cdots ,{x_t},{x_{t + 1}}, \\cdots \\cdots \\}$, 输出单元(output units)为：$\\{ {o_0},{o_1}, \\cdots \\cdots ,{o_t},{o_{t + 1}}, \\cdots \\cdots \\}$, 隐藏单元(hidden units)输出集: $\\{ {s_0},{s_1}, \\cdots \\cdots ,{ost},{s_{t + 1}}, \\cdots \\cdots \\}$ 时间 t 隐层单元的输出为：${s_t} = f(U{x_t} + W{s_{t - 1}})$ f就是激励函数，一般是sigmoid,tanh, relu等 计算${s_{0}}$时，即第一个的隐藏层状态，需要用到${s_{-1}}$，但是其并不存在，在实现中一般置为0向量 （如果将上面的竖着立起来，其实很像传统的神经网络，哈哈） 时间 t 的输出为：${o_t}=Softmax(V{s_t})$ 可以认为隐藏层状态${s_t}$是网络的记忆单元. ${s_t}$包含了前面所有步的隐藏层状态。而输出层的输出${o_t}$只与当前步的${s_t}$有关。 （在实践中，为了降低网络的复杂度，往往${s_t}$只包含前面若干步而不是所有步的隐藏层状态） 在RNNs中，每输入一步，每一层都共享参数U,V,W，（因为是将循环的部分展开，天然应该相等） RNNs的关键之处在于隐藏层，隐藏层能够捕捉序列的信息。 3、应用方面 循环神经网络(Recurrent Neural Networks，RNNs)已经在众多自然语言处理(Natural Language Processing, NLP)中取得了巨大成功以及广泛应用。目前使用最广泛最成功的模型便是LSTMs(Long Short-Term Memory，长短时记忆模型)模型(1) 语言模型和文本生成 给定一个单词序列，根据前面的单词预测下面单词的可能性 也可以根据概率生成新的词 这里给出了3篇论文 Recurrent neural network based language model Extensions of Recurrent neural network based language model Generating Text with Recurrent Neural Networks(2) 机器翻译 和上面的语言模型很像，只不过是根据一段过生成另外的一段话 注意的是开始的输出是在全部输入结束后生成的 一些论文 A Recursive Recurrent Neural Network for Statistical Machine Translation Sequence to Sequence Learning with Neural Networks (3) 语音识别 论文 Towards End-to-End Speech Recognition with Recurrent Neural Networks(4) 图像描述生成 根据图像，生成一段描述图像的话 需要和CNN结合使用 二、结构1、One to One 即一个输入对应一个输出，就是上面的图2、Many to One 即多个输入对应一个输出，比如情感分析，一段话中很多次，判断这段话的情感 其中$x_{1},x_{2},\\ldots,x_{t}$表示句子中的t个词，o代表最终输出的情感标签 前向计算就是：$$f(x)=Vs_{t}=V(Ux_{t}+Ws_{t-1})=V(Ux_{t}+W(Ux_{t-1}+Ws_{t-2}))\\cdots$$3、One to Many 前向计算类似，不再给出4、Many to Many 前向计算类似，不再给出5、双向RNN（Bidirectional RNN） 比如翻译问题往往需要联系上下文内容才能正确的翻译，我们上面的结构线性传递允许“联系上文”，但是联系下文并没有，所以就有双向RNN 前向运算稍微复杂一点，以t时刻为例$o_{t} = W_t^{(os)}s_t + W_t^{(oh)}h_t \\\\\\quad = W_t^{(os)} (W_{t-1}^{(ss)} s_{t-1} + W_{t}^{(sx)} x_{t-1}) + W_t^{(oh)} (W_t^{(hh)} h_{t+1} + W_t^{(hx)}x_t)$ 6、深层的RNN 上面的结构都是只含有一层的state层，根据传统NN和CNN，深层次的结构有更加号的效果，结构如图 三、Back Propagation Through Time(BPTT)训练 关于传统神经网络BP算法可以查看这里神经网络部分的推导1、符号等说明 以下图为例 符号说明 $\\phi$………………………………………………隐藏层的激励函数 $\\varphi$………………………………………………输出层的变换函数 $L_{t} = L_{t}\\left( o_{t},y_{t} \\right)$……………………………模型的损失函数 标签数据$y_{t}$是一个 one-hot 向量 2、反向传播过程 接受完序列中所有样本后再统一计算损失，此时模型的总损失可以表示为（假设输入序列长度为n）：$$L = \\sum_{t = 1}^{n}L_{t}$$ $o_{t} = \\varphi(Vs_t) = \\varphi(V(Ux_t + Ws_{t-1}))$ 其中$s_{0} = \\mathbf{0 =}( 0,0,\\ldots,0 )^{T}$ 令：${o_{t}^* = Vs_{t}}, \\quad {s_{t}^{*} = Ux_{t} + Ws_{t - 1}}…………(1)$ (就是没有经过激励函数和变换函数前) 则：$o_{t} = \\varphi( o_{t}^*)$ $s_{t} = \\phi(s_{t}^{*})$ (1) 矩阵V的更新 对矩阵 V 的更新过程,根据(1)式可得， (和传统的神经网络一致，根据求导的链式法则): $${{{\\partial {L_t} \\over \\partial o_t^{\\ast}}} = {{\\partial L_t \\over \\partial o_t } \\ast {\\partial o_t \\over \\partial o_{t}^{\\ast} }} = {{\\partial L_t \\over \\partial o_t} \\ast \\varphi ^{'} (o_t^{\\ast})}}$$ $${{{\\partial L_t} \\over {\\partial V }}} = {{\\partial L_t \\over \\partial Vs_t} } \\ast {{\\partial Vs_t \\over \\partial V}} = {{\\partial L_t \\over \\partial o_t^\\ast}} \\times s_t^T = ({{\\partial L_t \\over \\partial o_t} \\ast \\varphi ^{'} (o_{t}^\\ast)}) \\times s_t^T$$ - 因为${L = \\sum_{t = 1}^{n}L_{t}}$，所以对矩阵V的更新对应的导数:$${{\\partial L \\over \\partial V} = {\\sum\\limits_{t=1}^n ({\\partial L_t \\over \\partial o_t} \\ast \\varphi ^{'} (o_t^\\ast)) \\times s_t^T}}$$ (2) 矩阵U和W的更新 RNN 的 BP 算法的主要难点在于它 State 之间的通信 可以采用循环的方法来计算各个梯度，t应从n开始降序循环至 1 计算时间通道上的局部梯度（同样根据链式法则）$$ {{\\partial L_t \\over \\partial s_t^{\\ast}}} = {{\\partial L_t \\over \\partial Vs_t}} \\times {{\\partial s_t^{T} V_t^{T} \\over \\partial s_t}} \\ast {{\\partial s_t \\over \\partial s_t^{\\ast}}} = V^T \\times ({{\\partial L_t \\over \\partial o_t}} * {\\varphi ^{‘} (o_t^{\\ast}))} $$ $$ {{\\partial L_t \\over \\partial s_{k-1}^\\ast}} ={{\\partial s_k^\\ast \\over \\partial s_{k-1}^\\ast}} \\times {{\\partial L_t \\over \\partial s_{k}^\\ast}} = W_T \\times ({{\\partial L_t \\over \\partial s_k^\\ast} * {\\phi ^{'} (s_{k-1}^\\ast)}}) , (k=1,……,t) ………(2)$$ 利用局部梯度计算U和W的梯度 这里累加是因为权值是共享的，所以往前推算一直用的是一样的权值$${\\partial L_t \\over \\partial U} + = {\\sum\\limits_{k=1}^t {\\partial L_t \\over \\partial s_k^\\ast} \\times {\\partial s_k^\\ast \\over \\partial U}} = {\\sum\\limits_{k=1}^t {\\partial L_t\\over \\partial s_k^\\ast}} \\times x_t^T $$$${\\partial L_t \\over \\partial W} + = {\\sum\\limits_{k=1}^t {\\partial L_t \\over \\partial s_k^\\ast} \\times {\\partial s_k^\\ast \\over \\partial W}} = {\\sum\\limits_{k=1}^t {\\partial L_t\\over \\partial s_k^\\ast}} \\times s_{t-1}^T ………………..(3)$$ 3、训练问题 从 公式(2)和(3) 中可以看出，时间维度上的权重W更新需要计算$\\phi^{‘} (s_k^{\\ast})$，即经过激励函数的导数 如果时间维度上很长，则这个梯度是累积的，所以造成梯度消失或爆炸 可以想象将结构图竖起来，就是一个深层的神经网络，所以容易出现梯度问题 关于梯度消失的问题可以查看我这里一遍博客 RNN 主要的作用就是能够记住之前的信息，但是梯度消失的问题又告诉我们不能记住太久之前的信息，改进的思路有两点 一是使用一些trick,比如合适的激励函数，初始化，BN等等 二是改进state的传递方式，比如就是下面提及的LSTM 关于为何 LSTMs 能够解决梯度消失，直观上来说就是上方时间通道是简单的线性组合 四、Long Short-Term Memory(LSTM，长短时记忆网络)1、介绍 LSTM 是一般 RNN 的升级，因为一些序列问题，我们可能需要忘记一些东西， LSTM 和普通 RNN 相比, 多出了三个控制器. (输入控制, 输出控制, 忘记控制) 在LSTM里，这个叫做cell（其实就是前面的state,只是这里更加复杂了）, 可以看作一个黑盒，这个cell结合前面cell的输出$h_{t-1}$和当前的输入$x_{t}$来决定是否记忆下来，该网络结构在对长序列依赖问题中非常有效 2、结构 一个经典的cell结构如下图 $\\phi_{1} $是sigmoid函数，$\\phi_{2}$ 是tanh函数 *表示 element wise 乘法(就是点乘)，使用X表示矩阵乘法 LSTMs 的 cell 的时间通道有两条。 上方的时间通道（$h^{\\left( {old} \\right)} \\rightarrow h^{\\left( {new} \\right)}$）仅包含了两个代数运算,这意味着它信息传递的方式会更为直接 $$h^{(new)} = h^{(old)}*r_1 + r_2$$ 位于下方的时间通道（$s^{\\left( {old} \\right)} \\rightarrow s^{\\left( {new} \\right)}$）则运用了大量的层结构,在 LSTMs 中，我们通常称这些层结构为门（Gates） 3、运算说明 Sigmoid 函数取值区间为 0-1，那么当 Sigmoid 对应的层结构输出 0 时，就对应着遗忘这个过程；当输出 1 时，自然就对应着接受这个过程。 事实上这也是 Sigmoid 层叫门的原因——它能决定“放哪些数据进来”和决定“不让哪些数据通过” 最左边的Sigmoid gate 叫做遗忘门, 控制着时间通道信息的遗忘程度 前向计算: $r_1 = \\phi_1(W_1 \\times x^*)$ 其中 $x^* \\buildrel \\Delta \\over =[x,s^{(old)}] $，表示当前输入样本和下方时间通道$s^{(old)}$连接(concat)起来 第二个 Sigmoid Gate 通常被称为输入门（Input Gate）, 控制着当前输入和下方通道信息对上方通道信息的影响 前向运算为：$g_{1} = \\phi_{1} ( W_{2} \\times x^{*} )$, 第三个 Tanh Gate 则允许网络结构驳回历史信息, 因为tanh的值域是(-1,1) 前向运算为：$g_{2} = \\phi_{2} ( W_{3} \\times x^{*} )$ $r_{2} = g_{1}*g_{2}$ 第四个 Sigmoid Gate 通常被称为输出门（Output Gate），它为输出和传向下一个 cell 的下方通道信息作出了贡献。 对应的前向传导算法为：$g_{3} = \\phi_{1}\\left( W_{4} \\times x^{*} \\right)$ 最终cell的输出为：$o = s^{\\left( \\text{new} \\right)} = \\phi_{2}\\left( h^{\\left( \\text{new} \\right)} \\right)*g_{3}$ 每个 Gate 对应的权值矩阵是不同的（$W_{1}\\sim W_{4}$），切勿以为它们会共享权值 Reference http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/ http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/ https://zhuanlan.zhihu.com/p/26891871 https://zhuanlan.zhihu.com/p/26892413","comments":true,"tags":[{"name":"RNN","slug":"RNN","permalink":"http://lawlite.cn/tags/RNN/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://lawlite.cn/tags/DeepLearning/"},{"name":"LSTM","slug":"LSTM","permalink":"http://lawlite.cn/tags/LSTM/"}]},{"title":"Seaborn绘图","date":"2017-06-14T13:25:43.000Z","path":"2017/06/14/Seaborn绘图/","text":"全部代码：https://github.com/lawlite19/Blog-Back-Up/blob/master/code/seaborn_study.py 一、介绍与安装1、介绍 官网：http://seaborn.pydata.org/index.html Github: https://github.com/mwaskom/seaborn Seaborn 其实是在matplotlib的基础上进行了更高级的 API 封装，从而使得作图更加容易 在大多数情况下使用seaborn就能做出很具有吸引力的图，而使用matplotlib就能制作具有更多特色的图。应该把Seaborn视为matplotlib的补充2、安装 直接 pip3 install seaborn即可 二、分布图1、distplot 导入包 1234567#-*- coding: utf-8 -*-import numpy as npimport pandas as pdimport matplotlib as mplimport matplotlib.pyplot as pltimport seaborn as sns#%matplotlib inline # 为了在jupyter notebook里作图，需要用到这个命令 加载 seaborn中的数据集：tips = sns.load_dataset(&#39;tips&#39;) 分布图 kde是高斯分布密度图，绘图在0-1之间 hist是否画直方图 rug在X轴上画一些分布线 fit可以制定某个分布进行拟合 label legend时的值 axlabel制定横轴的说明12345sns.distplot(tips['total_bill'], bins=None, hist=True, kde=False, rug=True, fit=None, hist_kws=None, kde_kws=None, rug_kws=None, fit_kws=None, color=None, vertical=False, norm_hist=False, axlabel=None, label=None, ax=None)sns.plt.show() 拟合分布 这里使用了gamma分布拟合123from scipy import statssns.distplot(tips.total_bill, fit=stats.gamma, kde=False)sns.plt.show() 2、kdeplot 高斯概率密度图 data2可以是二维的分布 shade是否填充 kernel核函数，还有很多核函数，比如cos, biw等 cumulative累积的作图，最后的值应该是接近1 gridsize多少个点估计 123456ax = sns.kdeplot(tips['total_bill'], data2=tips.tip, shade=False, vertical=False, kernel=\"gau\", bw=\"scott\", gridsize=100, cut=3, clip=None, legend=True, cumulative=False, shade_lowest=True, ax=None)sns.plt.show() 二、pairplot1、两两作图 iris 为例 data: DataFrame格式的数据 hue: label类别对应的column name vars: 指定feature的列名 kind: 作图的方式，可以是reg或scatter diag_kind: 对角线作图的方式，可以是hist或kde123456789iris = sns.load_dataset('iris')g = sns.pairplot(iris, hue='species', hue_order=None, palette=None, vars=list(iris.columns[0:-1]), x_vars=None, y_vars=None, kind=\"reg\", diag_kind=\"hist\", markers=['o','s','D'], size=1.5, aspect=1, dropna=True, plot_kws=None, diag_kws=None, grid_kws=None)sns.plt.show() 三、stripplot和swarmplot1、stripplot tips为例，查看每天的数据信息 x: X轴数据 y: Y轴数据 hue: 区分不同种类数据的column name data: DataFrame类型数据 jitter: 将数据分开点，防止重叠1234567tips = sns.load_dataset('tips')ax = sns.stripplot(x='day', y='total_bill', hue=None, data=tips, order=None, hue_order=None, jitter=True, split=False, orient=None, color=None, palette=None, size=5, edgecolor=\"gray\", linewidth=0, ax=None) 查看关于性别消费的信息 123456ax = sns.stripplot(x='sex', y='total_bill', hue='day', data=tips, order=None, hue_order=None, jitter=True, split=False, orient=None, color=None, palette=None, size=5, edgecolor=\"gray\", linewidth=0, ax=None) 2、swarmplot 与stripplot类似，只是数据点不会重叠 (适合小数据量) 123tips = sns.load_dataset('tips')ax = sns.swarmplot(x='sex', y='total_bill', hue='day', data=tips)sns.plt.show() 四、boxplot1、boxplot示意图 函数 x, y：指定X轴，Y轴的columns name值 hue: 指定要区分的类别12345678tips = sns.load_dataset('tips')ax = sns.boxplot(x='day', y='total_bill', hue=None, data=tips, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=.75, width=.8, fliersize=5, linewidth=None, whis=1.5, notch=False, ax=None)sns.plt.show() 可以和上面的stripplot一起用 12345678910111213tips = sns.load_dataset('tips')ax = sns.boxplot(x='day', y='total_bill', hue=None, data=tips, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=.75, width=.8, fliersize=5, linewidth=None, whis=1.5, notch=False, ax=None)sns.stripplot(x='day', y='total_bill', hue=None, data=tips, order=None, hue_order=None, jitter=True, split=False, orient=None, color=None, palette=None, size=5, edgecolor=\"gray\", linewidth=0, ax=None)sns.plt.show() 五、jointplot1、jointplot 联合作图 kind: 有scatter” | “reg” | “resid” | “kde” | “hex12345678910tips = sns.load_dataset('tips')from scipy import statsg = sns.jointplot(x='total_bill', y='tip', data=tips, kind=\"reg\", stat_func=stats.pearsonr, color=None, size=6, ratio=5, space=.2, dropna=True, xlim=None, ylim=None, joint_kws=None, marginal_kws=None, annot_kws=None)sns.plt.show() 可以在基础上再作图 plot_joint就是在联合分布上作图 plot_marginals就是在边缘分布上再作图1g = (sns.jointplot(x='total_bill', y='tip',data=tips).plot_joint(sns.kdeplot)) 六、violinplot1、小提琴图，和boxplot很像 对称的kde图 中间的白点是中位数，黑色粗线对应分位数 inner: 指定图里面用什么划分，有&quot;box&quot;, &quot;quartile&quot;, &quot;point&quot;, &quot;stick&quot;, None quartile为四分位数划分 stick很像rug，就是可以看出密度情况 scale: 缩放每个图对应的area, 取值有 &quot;area&quot;, &quot;count&quot;, &quot;width&quot; area指定每个有相同的area count会按数量缩放（数量少的就比较窄扁）123456789101112tips = sns.load_dataset('tips')ax = sns.violinplot(x='day', y='total_bill', hue='smoker', data=tips, order=None, hue_order=None, bw=\"scott\", cut=2, scale=\"area\", scale_hue=True, gridsize=100, width=.8, inner=\"quartile\", split=False, orient=None, linewidth=None, color=None, palette='muted', saturation=.75, ax=None) sns.plt.show() 七、pointplot, bar1、pointplot 点图 estimator：点的取值是，默认是np.mean123456789tips = sns.load_dataset('tips')sns.pointplot(x='time', y='total_bill', hue='smoker', data=tips, order=None, hue_order=None, estimator=np.mean, ci=95, n_boot=1000, units=None, markers=\"o\", linestyles=\"-\", dodge=False, join=True, scale=1, orient=None, color=None, palette=None, ax=None, errwidth=None, capsize=None)sns.plt.show() 2、barplot 条形图 y轴是mean value，和点图其实差不多12345678tips = sns.load_dataset('tips')sns.barplot(x='day', y='total_bill', hue='sex', data=tips, order=None, hue_order=None, estimator=np.mean, ci=95, n_boot=1000, units=None, orient=None, color=None, palette=None, saturation=.75, errcolor=\".26\", errwidth=None, capsize=None, ax=None)sns.plt.show() 3、countplot123tips = sns.load_dataset('tips')sns.countplot(x='day', hue='sex', data=tips)sns.plt.show() 八、factorplot1、可以通过这个函数绘制以上几种图 指定kind即可，有point, bar, count, box, violin, strip row和col指定绘制的行数和列数，给出一个种类类型的列名即可 1234567891011121314titanic = sns.load_dataset('titanic')sns.factorplot(x='age', y='embark_town', hue='sex', data=titanic, row='class', col='sex', col_wrap=None, estimator=np.mean, ci=95, n_boot=1000, units=None, order=None, hue_order=None, row_order=None, col_order=None, kind=\"box\", size=4, aspect=1, orient=None, color=None, palette=None, legend=True, legend_out=True, sharex=True, sharey=True, margin_titles=False, facet_kws=None)sns.plt.show() 九、heatmap1、heatmap1234flight = sns.load_dataset('flights')flights = flight.pivot('month','year','passengers')sns.heatmap(flights, annot=True, fmt='d')sns.plt.show() 十、时序绘图1、tsplot condition: 和hue差不多，指定类别 estimator: 默认为np.mean12345678gammas = sns.load_dataset('gammas')sns.tsplot(data=gammas, time='timepoint', unit='subject', condition='ROI', value='BOLD signal', err_style=\"ci_band\", ci=68, interpolate=True, color=None, estimator=np.mean, n_boot=5000, err_palette=None, err_kws=None, legend=True, ax=None)sns.plt.show() Reference Youtube: https://www.youtube.com/playlist?list=PLgJhDSE2ZLxYlhQx0UfVlnF1F7OWF-9rp Github: https://github.com/knathanieltucker/seaborn-weird-parts","comments":true,"tags":[{"name":"Python","slug":"Python","permalink":"http://lawlite.cn/tags/Python/"},{"name":"可视化","slug":"可视化","permalink":"http://lawlite.cn/tags/可视化/"}]},{"title":"PyTorch学习","date":"2017-05-10T11:30:05.000Z","path":"2017/05/10/PyTorch/","text":"一、PyTorch介绍1、说明 PyTorch 是 Torch 在 Python 上的衍生（Torch 是一个使用 Lua 语言的神经网络库） 和tensorflow比较 PyTorch建立的神经网络是动态的 Tensorflow是建立静态图 Tensorflow 的高度工业化, 它的底层代码是很难看懂的. PyTorch 好那么一点点, 如果你深入 API, 你至少能比看 Tensorflow 多看懂一点点 PyTorch 的底层在干嘛. 2、安装PyTorch 官网：http://pytorch.org/ 进入官网之后可以选择对应的安装选项 目前只支持Linux和MacOS版本（2017-05-06） 执行下面对应的安装命令即可 安装 PyTorch 会安装两个模块 一个是 torch, 一个 torchvision, torch 是主模块, 用来搭建神经网络的, torchvision 是辅模块,有数据库,还有一些已经训练好的神经网络等着你直接用, 比如 (VGG, AlexNet, ResNet). 上面在ubuntu14下自带的python2.7安装没有问题，在CentOS6.5下的python3.5中安装可能报错 安装python3.5时的配置： 123./configure --enable-shared \\ --prefix=/usr/local/python3.5 \\ LDFLAGS=\"-Wl,--rpath=/usr/local/lib\" 然后运行python可能报loading shared libraries: libpython3.5m.so.1.0: cannot open shared object file: No such file or directory的错误，拷贝一份libpython3.5m.so.1.0到/usr/lib64目录下即可 1cp /home/Python/Python-3.5.3/libpython3.5m.so.1.0 /usr/lib64 二、基础知识1、和Numpy相似之处(1) 数据转换 导入包：import torch 将numpy数据转为torch数据 12np_data = np.arange(6).reshape((2, 3))torch_data = torch.from_numpy(np_data) 将torch数据转为numpy数据 1tensor2array = torch_data.numpy() (2) Torch中的运算 API：http://pytorch.org/docs/torch.html#math-operations torch 中 tensor 的运算和 numpy array运算很相似，比如 np.abs() --&gt; torch.abs() np.sin() --&gt; torch.sin()等 矩阵相乘： data = [[1,2], [3,4]] tensor = torch.FloatTensor(data) # 转换成32位浮点 tensor torch.mm(tensor, tensor)2、变量Variable(1) 说明 Variable 就是一个存放会变化的值的位置 这里变化的值就是tensor数据(2) 使用 导入包 12import torchfrom torch.autograd import Variable # torch 中 Variable 模块 定义tensor: tensor = torch.FloatTensor([[1,2],[3,4]]) 将tensor放入Variable: variable = Variable(tensor, requires_grad=True) requires_grad 是参不参与误差反向传播, 要不要计算梯度 print(variable) 会输出，(多出Variable containing:，表明是Variable) 1234Variable containing: 1 2 3 4[torch.FloatTensor of size 2x2] (3) 计算梯度 v_out = torch.mean(variable*variable) # x^2 v_out.backward() # 模拟 v_out 的误差反向传递 print(variable.grad) # 显示 Variable 的梯度 输出结果如下 因为torch.mean(variable*variable)是1/4*x^2，导数就是1/2x120.5000 1.00001.5000 2.0000 (4) Variable里面的数据 直接print(variable)只会输出 Variable 形式的数据, 在很多时候是用不了的(比如想要用 plt 画图), 所以我们要转换一下, 将它变成 tensor 形式. 获取 tensor 数据：print(variable.data) # tensor 形式 然后也可以转而numpy数据：print(variable.data.numpy()) # numpy 形式3、Torch 中的激励函数 导入包：import torch.nn.functional as F # 激励函数都在这 平时要用到的就这几个. relu, sigmoid, tanh, softplus 激励函数 x是Variable数据，F.relu(x)也是返回Variable数据，然后.data获取 tensor 数据1234# 做一些假数据来观看图像x = torch.linspace(-5, 5, 200) # x data (tensor), shape=(100, 1)x = Variable(x)x_np = x.data.numpy() # 换成 numpy array, 出图时用 12345y_relu = F.relu(x).data.numpy()y_sigmoid = F.sigmoid(x).data.numpy()y_tanh = F.tanh(x).data.numpy()y_softplus = F.softplus(x).data.numpy()# y_softmax = F.softmax(x) softmax 比较特殊, 不能直接显示, 不过他是关于概率的, 用于分类 softplus的公式为：f(x)=ln(1+ex) 三、建立基础的神经网络1、回归问题(1) 准备工作 导入包 1234import torchfrom torch.autograd import Variableimport torch.nn.functional as F import matplotlib.pyplot as plt 制造假数据 torch.unsqueeze是转成2维的数据[[]],加上一个假的维度12x = torch.unsqueeze(torch.linspace(-1, 1, 100), dim=1) # x data (tensor), shape=(100, 1)y = x.pow(2) + 0.2*torch.rand(x.size()) # noisy y data (tensor), shape=(100, 1) 定义Variable: x, y = torch.autograd.Variable(x), Variable(y) (2) 建立神经网络 使用类的方式class 继承torch.nn.Module 这里只包含一个隐层，__init__只是定义了几个层 forward进行传播，也就是整个网络的搭建，因为是预测，最后一层不需要激励函数123456789101112class Net(torch.nn.Module): # 继承 torch 的 Module def __init__(self, n_feature, n_hidden, n_output): super(Net, self).__init__() # 继承 __init__ 功能 # 定义每层用什么样的形式 self.hidden = torch.nn.Linear(n_feature, n_hidden) # 隐藏层线性输出 self.predict = torch.nn.Linear(n_hidden, n_output) # 输出层线性输出 def forward(self, x): # 这同时也是 Module 中的 forward 功能 # 正向传播输入值, 神经网络分析出输出值 x = F.relu(self.hidden(x)) # 激励函数(隐藏层的线性值) x = self.predict(x) # 输出值 return x 使用：net = Net(n_feature=1, n_hidden=10, n_output=1) 输出：print(net)，结果为 1234Net ( (hidden): Linear (1 -&gt; 10) (predict): Linear (10 -&gt; 1)) (3) 训练网络 定义优化器：optimizer = torch.optim.SGD(net.parameters(), lr=0.5) # 传入 net 的所有参数, 学习率lr 定义损失函数：loss_func = torch.nn.MSELoss() # 预测值和真实值的误差计算公式 (均方差) 训练 12345678for t in range(100): prediction = net(x) # 喂给 net 训练数据 x, 输出预测值 loss = loss_func(prediction, y) # 计算两者的误差 optimizer.zero_grad() # 清空上一步的残余更新参数值 loss.backward() # 误差反向传播, 计算参数更新值 optimizer.step() # 将参数更新值施加到 net 的 parameters 上 2、分类问题(1) 准备工作 导入包 1234import torchfrom torch.autograd import Variableimport torch.nn.functional as F # 激励函数都在这import matplotlib.pyplot as plt 制造假数据 x0是一个类别的x1,x2 y0就是对应这个类别的 label，这里是0 然后将x0,x1，y0,y1合并在一起123456789# 假数据n_data = torch.ones(100, 2) # 数据的基本形态x0 = torch.normal(2*n_data, 1) # 类型0 x data (tensor), shape=(100, 2)y0 = torch.zeros(100) # 类型0 y data (tensor), shape=(100, 1)x1 = torch.normal(-2*n_data, 1) # 类型1 x data (tensor), shape=(100, 1)y1 = torch.ones(100) # 类型1 y data (tensor), shape=(100, 1)# 注意 x, y 数据的数据形式是一定要像下面一样 (torch.cat 是在合并数据)x = torch.cat((x0, x1), 0).type(torch.FloatTensor) # FloatTensor = 32-bit floatingy = torch.cat((y0, y1), ).type(torch.LongTensor) # LongTensor = 64-bit integer 定义Variable: x, y = Variable(x), Variable(y) (2) 建立网络 与上面回归的例子类似 使用relu激励函数 这里最后一层并没有使用激励函数或是softmax，因为下面使用了CrossEntropyLoss，这个里面默认会调用log_softmax函数(nll_loss(log_softmax(input), target, weight, size_average)) 当然这里也可以最后返回F.softmax(x), 那么下面的损失函数就是loss = F.nll_loss(out, y)1234567891011class Net(torch.nn.Module): # 继承 torch 的 Module def __init__(self, n_feature, n_hidden, n_output): super(Net, self).__init__() # 继承 __init__ 功能 self.hidden = torch.nn.Linear(n_feature, n_hidden) # 隐藏层线性输出 self.out = torch.nn.Linear(n_hidden, n_output) # 输出层线性输出 def forward(self, x): # 正向传播输入值, 神经网络分析出输出值 x = F.relu(self.hidden(x)) # 激励函数(隐藏层的线性值) x = self.out(x) # 输出值, 但是这个不是预测值, 预测值还需要再另外计算 return x 建立网络：net = Net(n_feature=2, n_hidden=10, n_output=2) # 几个类别就几个 output (3) 训练网络 优化器：optimizer = torch.optim.SGD(net.parameters(), lr=0.02) # 传入 net 的所有参数, 学习率 损失函数：loss_func = torch.nn.CrossEntropyLoss() 训练： 12345678for t in range(100): out = net(x) # 喂给 net 训练数据 x, 输出分析值 loss = loss_func(out, y) # 计算两者的误差 optimizer.zero_grad() # 清空上一步的残余更新参数值 loss.backward() # 误差反向传播, 计算参数更新值 optimizer.step() # 将参数更新值施加到 net 的 parameters 上 预测： 输出至最大的那个（概率最大的）坐标12# 过了一道 softmax 的激励函数后的最大概率才是预测值 prediction = torch.max(F.softmax(out), 1)[1] 3、快速搭建神经网络 使用torch.nn.Sequential 12345net2 = torch.nn.Sequential( torch.nn.Linear(1, 10), torch.nn.ReLU(), torch.nn.Linear(10, 1)) 输出：print(net2) 相比我们之前自己定义的类，激励函数也显示出来了12345Sequential ( (0): Linear (1 -&gt; 10) (1): ReLU () (2): Linear (10 -&gt; 1)) 4、保存和提取(1) 保存（两种方法） 保存整个网络 torch.save(net1, &#39;net.pkl&#39;) # 保存整个网络，net1 就是定义的网络 只保存网络中的参数 torch.save(net1.state_dict(), &#39;net_params.pkl&#39;) # 只保存网络中的参数 (速度快, 占内存少)(2) 提取（也是两种方法） 提取整个网络： net2 = torch.load(&#39;net.pkl&#39;) prediction = net2(x) 只提取网络参数 首先需要定义一样的神经网络 net3.load_state_dict(torch.load(&#39;net_params.pkl&#39;)) prediction = net3(x)5、批训练SGD 上面我们虽然是torch.optim.SGD进行优化，但是还是将所有数据放进去训练(1) DataLoader 是 torch 用来包装你的数据(tensor)的工具 导入包： import torch.utils.data as Data 将tensor数据转为torch能识别的Dataset 1torch_dataset = Data.TensorDataset(data_tensor=x, target_tensor=y) 把 dataset 放入 DataLoader BATCH_SIZE是我们定义的batch大小123456loader = Data.DataLoader( dataset=torch_dataset, # torch TensorDataset format batch_size=BATCH_SIZE, # mini batch size shuffle=True, # 要不要打乱数据 (打乱比较好) num_workers=2, # 多线程来读数据) 就可以得到batch数据了 12345678for epoch in range(3): # 训练所有!整套!数据 3 次 for step, (batch_x, batch_y) in enumerate(loader): # 每一步 loader 释放一小批数据用来学习 # 假设这里就是你训练的地方... # 打出来一些数据 print('Epoch: ', epoch, '| Step: ', step, '| batch x: ', batch_x.numpy(), '| batch y: ', batch_y.numpy()) 这里还是tensor数据，真正训练时还要放到Variable中 12b_x = Variable(batch_x) # 务必要用 Variable 包一下b_y = Variable(batch_y) 6、优化器 optimizer SGD 就是随机梯度下降 momentum 动量加速 在SGD函数里指定momentum的值即可 RMSprop 指定参数alpha Adam 参数betas=(0.9, 0.99)1234opt_SGD = torch.optim.SGD(net_SGD.parameters(), lr=LR)opt_Momentum = torch.optim.SGD(net_Momentum.parameters(), lr=LR, momentum=0.8)opt_RMSprop = torch.optim.RMSprop(net_RMSprop.parameters(), lr=LR, alpha=0.9)opt_Adam = torch.optim.Adam(net_Adam.parameters(), lr=LR, betas=(0.9, 0.99)) 四、高级神经网络1、卷积神经网络 CNN 使用mnist数据集 导入包 12345import torchfrom torch.autograd import Variableimport torch.utils.data as Dataimport torchvisionfrom matplotlib import pyplot as plt 下载数据集 123456789EPOCH = 10BATCH_SIZE = 50LR = 0.001train_data = torchvision.datasets.MNIST(root='./mnist', transform=torchvision.transforms.ToTensor(), download=False) # first set True, then set Falseprint(train_data.train_data.size())test_data = torchvision.datasets.MNIST(root='./mnist', train=False) 处理数据 使用 DataLoader 进行batch训练 将测试数据放到Variable里，并加上一个维度（在第二维位置dim=1），因为下面训练时是(batch_size, 1, 28, 28)12345train_loader = Data.DataLoader(dataset=train_data, batch_size=128, shuffle=True)# shape from (total_size, 28, 28) to (total_size, 1, 28, 28)test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1), volatile=True).type(torch.FloatTensor)/255.0test_y = test_data.test_labels 建立计算图模型 12345678910111213141516171819202122232425class CNN(torch.nn.Module): def __init__(self): super(CNN, self).__init__() self.conv1 = torch.nn.Sequential( # input shape (1, 28, 28) torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2), torch.nn.ReLU(), torch.nn.MaxPool2d(kernel_size=2) ) # output shape (16, 14, 14) self.conv2 = torch.nn.Sequential( torch.nn.Conv2d(16, 32, 5, 1, 2), torch.nn.ReLU(), torch.nn.MaxPool2d(2) ) # output shape (32, 7, 7) self.out = torch.nn.Linear(in_features=32*7*7, out_features=10) def forward(self, x): x = self.conv1(x) x = self.conv2(x) x = x.view(x.size(0), -1) # 展平多维的卷积图成 (batch_size, 32 * 7 * 7) output = self.out(x) return outputcnn = CNN() 定义优化器optimizer和损失 12optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)loss_func = torch.nn.CrossEntropyLoss() 进行batch训练 123456789101112131415for epoch in range(EPOCH): for i, (x, y) in enumerate(train_loader): batch_x = Variable(x) batch_y = Variable(y) output = cnn(batch_x) loss = loss_func(output, batch_y) optimizer.zero_grad() loss.backward() optimizer.step() if i % 50 == 0: # 用 test 数据来验证准确率 test_output = cnn(test_x) pred_y = torch.max(test_output, 1)[1].data.squeeze() accuracy = sum(pred_y == test_y) / float(test_y.size(0)) print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0], '| test accuracy: %.2f' % accuracy) Reference https://morvanzhou.github.io/tutorials/machine-learning/torch/","comments":true,"tags":[{"name":"Python","slug":"Python","permalink":"http://lawlite.cn/tags/Python/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://lawlite.cn/tags/PyTorch/"}]},{"title":"Hexo+yilia主题实现文章目录和添加视频","date":"2017-04-17T07:00:21.000Z","path":"2017/04/17/Hexo-yilia主题实现文章目录和添加视频/","text":"一、说明 文章目录功能可以点击这里查看 视频页面可以点击这里查看 粗略实现，有问题可以在下方评论区留言，或者留言板留言 二、文章目录功能1、添加CSS样式 打开themes\\yilia\\source下的main.234bc0.css文件，添加如下代码： css样式我也放到了github上：https://raw.githubusercontent.com/lawlite19/Blog-Back-Up/master/css/main.234bc0.css 使用的是别人的css，可能有冗余的部分 12345678910/* 新添加的 */#container .show-toc-btn,#container .toc-article&#123;display:block&#125;.toc-article&#123;z-index:100;background:#fff;border:1px solid #ccc;max-width:250px;min-width:150px;max-height:500px;overflow-y:auto;-webkit-box-shadow:5px 5px 2px #ccc;box-shadow:5px 5px 2px #ccc;font-size:12px;padding:10px;position:fixed;right:35px;top:129px&#125;.toc-article .toc-close&#123;font-weight:700;font-size:20px;cursor:pointer;float:right;color:#ccc&#125;.toc-article .toc-close:hover&#123;color:#000&#125;.toc-article .toc&#123;font-size:12px;padding:0;line-height:20px&#125;.toc-article .toc .toc-number&#123;color:#333&#125;.toc-article .toc .toc-text:hover&#123;text-decoration:underline;color:#2a6496&#125;.toc-article li&#123;list-style-type:none&#125;.toc-article .toc-level-1&#123;margin:4px 0&#125;.toc-article .toc-child&#123;&#125;@-moz-keyframes cd-bounce-1&#123;0%&#123;opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;60%&#123;opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)&#125;100%&#123;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;&#125;@-webkit-keyframes cd-bounce-1&#123;0%&#123;opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;60%&#123;opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)&#125;100%&#123;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;&#125;@-o-keyframes cd-bounce-1&#123;0%&#123;opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;60%&#123;opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)&#125;100%&#123;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;&#125;@keyframes cd-bounce-1&#123;0%&#123;opacity:0;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;60%&#123;opacity:1;-o-transform:scale(1.01);-webkit-transform:scale(1.01);-moz-transform:scale(1.01);-ms-transform:scale(1.01);transform:scale(1.01)&#125;100%&#123;-o-transform:scale(1);-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);transform:scale(1)&#125;&#125;.show-toc-btn&#123;display:none;z-index:10;width:30px;min-height:14px;overflow:hidden;padding:4px 6px 8px 5px;border:1px solid #ddd;border-right:none;position:fixed;right:40px;text-align:center;background-color:#f9f9f9&#125;.show-toc-btn .btn-bg&#123;margin-top:2px;display:block;width:16px;height:14px;background:url(http://7xtawy.com1.z0.glb.clouddn.com/show.png) no-repeat;-webkit-background-size:100%;-moz-background-size:100%;background-size:100%&#125;.show-toc-btn .btn-text&#123;color:#999;font-size:12px&#125;.show-toc-btn:hover&#123;cursor:pointer&#125;.show-toc-btn:hover .btn-bg&#123;background-position:0 -16px&#125;.show-toc-btn:hover .btn-text&#123;font-size:12px;color:#ea8010&#125;.toc-article li ol, .toc-article li ul &#123; margin-left: 30px;&#125;.toc-article ol, .toc-article ul &#123; margin: 10px 0;&#125; 2、修改article.ejs文件 使用的是Hexo的toc函数 打开themes\\yilia\\layout\\_partial文件夹下的article.ejs文件 在&lt;/header&gt; &lt;% } %&gt;下面加入如下内容（注意位置） 123456789101112131415161718192021222324252627&lt;!-- 目录内容 --&gt;&lt;% if (!index &amp;&amp; post.toc)&#123; %&gt; &lt;p class=\"show-toc-btn\" id=\"show-toc-btn\" onclick=\"showToc();\" style=\"display:none\"&gt; &lt;span class=\"btn-bg\"&gt;&lt;/span&gt; &lt;span class=\"btn-text\"&gt;文章导航&lt;/span&gt; &lt;/p&gt; &lt;div id=\"toc-article\" class=\"toc-article\"&gt; &lt;span id=\"toc-close\" class=\"toc-close\" title=\"隐藏导航\" onclick=\"showBtn();\"&gt;×&lt;/span&gt; &lt;strong class=\"toc-title\"&gt;文章目录&lt;/strong&gt; &lt;%- toc(post.content) %&gt; &lt;/div&gt; &lt;script type=\"text/javascript\"&gt; function showToc()&#123; var toc_article = document.getElementById(\"toc-article\"); var show_toc_btn = document.getElementById(\"show-toc-btn\"); toc_article.setAttribute(\"style\",\"display:block\"); show_toc_btn.setAttribute(\"style\",\"display:none\"); &#125;; function showBtn()&#123; var toc_article = document.getElementById(\"toc-article\"); var show_toc_btn = document.getElementById(\"show-toc-btn\"); toc_article.setAttribute(\"style\",\"display:none\"); show_toc_btn.setAttribute(\"style\",\"display:block\"); &#125;; &lt;/script&gt; &lt;% &#125; %&gt; &lt;!-- 目录内容结束 --&gt; 然后若想要文章显示目录，在每篇文章开头加入：toc: true 3、最终效果(1) 电脑端 (2) 手机端 三、添加视频 是在之前相册功能的基础之上，相册功能的实现点击这里查看 1、添加视频样式css 打开当前博客source\\photos文件夹下的ins.css文件 加入如下内容 123456789/* ====== video ===== */.video-container &#123;z-index: 1;position: relative;padding-bottom: 56.25%;margin: 0 auto;&#125;.video-container iframe, .video-container object, .video-container embed &#123;z-index: 1;position: absolute;top: 0;left: 7%;width: 85%;height: 85%;box-shadow: 0px 0px 20px 2px #888888;&#125; 2、添加视频 我这里添加的是优酷上面的视频 在当前博客source\\photos文件夹下建立videos.ejs文件 内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849---layout: postslug: \"photos\"title: \"相册\"noDate: \"true\"comments: \"true\"reward: \"true\"open_in_new: false---&lt;link rel=\"stylesheet\" href=\"./ins.css\"&gt;&lt;div class=\"photos-btn-wrap\"&gt; &lt;a class=\"photos-btn\" href=\"/photos\"&gt;Photos&lt;/a&gt; &lt;a class=\"photos-btn active\" href=\"/photos/videos.html\"&gt;Videos&lt;/a&gt;&lt;/div&gt;&lt;center&gt;&lt;h1&gt;指弹_女儿情&lt;/h1&gt;&lt;/center&gt;&lt;hr/&gt;&lt;center&gt;&lt;div class=\"video-container\"&gt;&lt;iframe height=\"80%\" width=\"80%\" src=\"http://player.youku.com/embed/XMjUzMzY4OTM3Ng==\" frameborder=0 allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/center&gt;&lt;hr/&gt;&lt;center&gt;&lt;h1&gt;指弹_友谊地久天长&lt;/h1&gt;&lt;/center&gt;&lt;hr/&gt;&lt;center&gt;&lt;div class=\"video-container\"&gt;&lt;iframe height=\"80%\" width=\"80%\" src=\"http://player.youku.com/embed/XMjQ5MDExOTY2MA==\" frameborder=0 allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/center&gt;&lt;hr/&gt;&lt;center&gt;&lt;h1&gt;指弹_Always with me&lt;/h1&gt;&lt;/center&gt;&lt;hr/&gt;&lt;center&gt;&lt;div class=\"video-container\"&gt;&lt;iframe height=\"80%\" width=\"80%\" src=\"http://player.youku.com/embed/XMjQ4MDQyNTQ0MA==\" frameborder=0 allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/center&gt; 3、最终效果(1) 电脑端 (2) 手机端","comments":true,"tags":[{"name":"Github","slug":"Github","permalink":"http://lawlite.cn/tags/Github/"},{"name":"Hexo","slug":"Hexo","permalink":"http://lawlite.cn/tags/Hexo/"}]},{"title":"Hexo+Github实现相册功能","date":"2017-04-13T12:27:03.000Z","path":"2017/04/13/Hexo-Github实现相册功能/","text":"最终效果请看这里：http://lawlite.me/photos/ 粗略实现，有问题可以在下方评论区评论，或者留言区留言 一、说明1、关于 我使用的主题是hexo-theme-yilia，其中实现相册功能的方案是同步instagram上面的图片，但是现在instagram被禁，不能使用了 下面是通过自己的方式实现了相册功能，其中的样式还是使用该主题提供的2、方案 在github上新建一个仓库，主要用于存储图片，可以通过url访问到，也方便管理 将要放到相册的图片处理成json格式的数据，然后进行访问，这里json的格式需要配合要使用的样式，所以需要处理成特定格式的json数据，下面会给出 图片裁剪，因为相册显示的样式最好是正方形的的图片，这里使用脚本处理一下 图片压缩，相册显示的图片是压缩后的图片，提高加载的速度，打开后的图片是原图。 二、实现1、github操作 建立一个用于存储相册的仓库，我这里建立了名为Blog-Back-Up的仓库 关于git的命令行操作和配置不再给出 2、博客操作 在博客的source文件夹下建立一个photos文件夹 将样式文件放到photos文件夹下，样式文件我都放到了github上：https://github.com/lawlite19/Blog-Back-Up/tree/master/blog_photos_copy 修改ins.js文件，主要是里面的render函数 其中的url对应到你的github放图片的地址1234567891011121314151617181920212223var render = function render(res) &#123; var ulTmpl = \"\"; for (var j = 0, len2 = res.list.length; j &lt; len2; j++) &#123; var data = res.list[j].arr; var liTmpl = \"\"; for (var i = 0, len = data.link.length; i &lt; len; i++) &#123; var minSrc = 'https://raw.githubusercontent.com/lawlite19/blog-back-up/master/min_photos/' + data.link[i]; var src = 'https://raw.githubusercontent.com/lawlite19/blog-back-up/master/photos/' + data.link[i]; var type = data.type[i]; var target = src + (type === 'video' ? '.mp4' : '.jpg'); src += ''; liTmpl += '&lt;figure class=\"thumb\" itemprop=\"associatedMedia\" itemscope=\"\" itemtype=\"http://schema.org/ImageObject\"&gt;\\ &lt;a href=\"' + src + '\" itemprop=\"contentUrl\" data-size=\"1080x1080\" data-type=\"' + type + '\" data-target=\"' + src + '\"&gt;\\ &lt;img class=\"reward-img\" data-type=\"' + type + '\" data-src=\"' + minSrc + '\" src=\"/assets/img/empty.png\" itemprop=\"thumbnail\" onload=\"lzld(this)\"&gt;\\ &lt;/a&gt;\\ &lt;figcaption style=\"display:none\" itemprop=\"caption description\"&gt;' + data.text[i] + '&lt;/figcaption&gt;\\ &lt;/figure&gt;'; &#125; ulTmpl = ulTmpl + '&lt;section class=\"archives album\"&gt;&lt;h1 class=\"year\"&gt;' + data.year + '年&lt;em&gt;' + data.month + '月&lt;/em&gt;&lt;/h1&gt;\\ &lt;ul class=\"img-box-ul\"&gt;' + liTmpl + '&lt;/ul&gt;\\ &lt;/section&gt;'; &#125; 3、图片处理 python脚本文件都放在了这里：https://github.com/lawlite19/Blog-Back-Up(1) 裁剪图片 去图片的中间部分，裁剪为正方形 对应的裁剪函数1234567891011121314151617181920def cut_by_ratio(self): \"\"\"按照图片长宽进行分割 ------------ 取中间的部分，裁剪成正方形 \"\"\" im = Image.open(self.infile) (x, y) = im.size if x &gt; y: region = (int(x/2-y/2), 0, int(x/2+y/2), y) #裁切图片 crop_img = im.crop(region) #保存裁切后的图片 crop_img.save(self.outfile) elif x &lt; y: region = (0, int(y/2-x/2), x, int(y/2+x/2)) #裁切图片 crop_img = im.crop(region) #保存裁切后的图片 crop_img.save(self.outfile) (2) 压缩图片 把图片进行压缩，方便相册的加载12345678910111213141516171819202122def compress(choose, des_dir, src_dir, file_list): \"\"\"压缩算法，img.thumbnail对图片进行压缩， 参数 ----------- choose: str 选择压缩的比例，有4个选项，越大压缩后的图片越小 \"\"\" if choose == '1': scale = SIZE_normal if choose == '2': scale = SIZE_small if choose == '3': scale = SIZE_more_small if choose == '4': scale = SIZE_more_small_small for infile in file_list: img = Image.open(src_dir+infile) # size_of_file = os.path.getsize(infile) w, h = img.size img.thumbnail((int(w/scale), int(h/scale))) img.save(des_dir + infile) 4、github提交 处理完成之后需要将处理后的图片提交到github上 这里同样使用脚本的方式，需要将git命令行配置到环境变量中12345678910def git_operation(): ''' git 命令行函数，将仓库提交 ---------- 需要安装git命令行工具，并且添加到环境变量中 ''' os.system('git add --all') os.system('git commit -m \"add photos\"') os.system('git push origin master') 5、json数据处理 下面就需要将图片信息处理成json数据格式了，这里为重点 最终需要的json格式的数据如下图： 这里我采用的方式是读取图片的名字作为其中的text的内容，图片的命名如下图 最前面是日期，然后用_进行分隔 后面是图片的描述信息，注意不要包含_和.符号 实现代码： 注意代码中../lawlite19.github.io/source/photos/data.json是对应到我的博客的路径，这里根据需要改成自己博客的路径 1234567891011121314151617181920212223242526272829303132333435363738394041def handle_photo(): '''根据图片的文件名处理成需要的json格式的数据 ----------- 最后将data.json文件存到博客的source/photos文件夹下 ''' src_dir, des_dir = \"photos/\", \"min_photos/\" file_list = list_img_file(src_dir) list_info = [] for i in range(len(file_list)): filename = file_list[i] date_str, info = filename.split(\"_\") info, _ = info.split(\".\") date = datetime.strptime(date_str, \"%Y-%m-%d\") year_month = date_str[0:7] if i == 0: # 处理第一个文件 new_dict = &#123;\"date\": year_month, \"arr\":&#123;'year': date.year, 'month': date.month, 'link': [filename], 'text': [info], 'type': ['image'] &#125; &#125; list_info.append(new_dict) elif year_month != list_info[-1]['date']: # 不是最后的一个日期，就新建一个dict new_dict = &#123;\"date\": year_month, \"arr\":&#123;'year': date.year, 'month': date.month, 'link': [filename], 'text': [info], 'type': ['image'] &#125; &#125; list_info.append(new_dict) else: # 同一个日期 list_info[-1]['arr']['link'].append(filename) list_info[-1]['arr']['text'].append(info) list_info[-1]['arr']['type'].append('image') list_info.reverse() # 翻转 final_dict = &#123;\"list\": list_info&#125; with open(\"../lawlite19.github.io/source/photos/data.json\",\"w\") as fp: json.dump(final_dict, fp) 每次图片有改动都需要执行此脚本文件三、其他 你可以根据需要进行修改python脚本代码，这里一些细节可能处理的不好 留言板：http://lawlite.me/%E7%95%99%E8%A8%80%E6%9D%BF/ 效果展示 相册 留言板","comments":true,"tags":[{"name":"Github","slug":"Github","permalink":"http://lawlite.cn/tags/Github/"},{"name":"Hexo","slug":"Hexo","permalink":"http://lawlite.cn/tags/Hexo/"}]},{"title":"Hexo+Github搭建自己的博客","date":"2017-04-10T14:49:15.000Z","path":"2017/04/10/Hexo-Github搭建自己的博客/","text":"最终效果可以查看：http://lawlite.me/ 后序继续完善，有问题可以联系我或是下面评论 一、说明 关于一些基本软件的安装和配置这里不再给出 安装NodeJS：http://nodejs.cn/download/ 需要配置环境变量 安装git工具：https://git-for-windows.github.io/ 注册github账号 配置SSH-key 创建名为userName.github.io的仓库,userName是你申请的用户名 二、安装Hexo和基本使用 安装Hexo: npm install -g hexo 初始化Hexo: hexo init 生成静态页面：hexo generate 或者 hexo g 启动服务器：hexo server 或者 hexo s 注意：服务器默认是4000端口，若是安装了福昕阅读器可能端口冲突 可以制定端口：hexo s -p5000 浏览器中访问：http://localhost:4000 三、更换主题Theme及基本配置1、更换主题 默认主题是landscape，在themes文件夹下，可以使用别人开发好的主题，这里有很多，我使用的是这一个: https://github.com/litten/hexo-theme-yilia 下载之后放到themes文件夹下即可：git clone git@github.com:litten/hexo-theme-yilia.git 2、主题基本配置 配置在_config.yml文件中，基本的配置尝试一下就知道了，不在给出(1) 图片的位置： 比如打赏的支付宝二维码图片，是在当前博客的source/assets/img/下 （不是当前主题） 配置：12345678# 打赏基础设定：0-关闭打赏； 1-文章对应的md文件里有reward:true属性，才有打赏； 2-所有文章均有打赏reward_type: 1# 打赏wordingreward_wording: '谢谢你请我吃糖果'# 支付宝二维码图片地址，跟你设置头像的方式一样。比如：/assets/img/alipay.jpgalipay: /assets/img/alipay.jpg# 微信二维码图片地址weixin: /assets/img/weixin.png (2) 百度、谷歌统计配置 申请账号：https://tongji.baidu.com/web/welcome/login 在代码获取的地方只要填入key即可 123# Miscellaneousbaidu_analytics: '454d1a5ba8ed29xxxxxxxx'google_analytics: 'UA-9700xxxxxxxx' 就可以统计网站访问情况了，如下图， 谷歌统计同理 (3) 文章评论设置 由于主题之实现了多说和disqus的第三方评论功能，这里不配置 因为多说6月份要关闭了，disqus需要翻墙访问才行，还有友言不支持https协议，因为github使用的是https协议 下面会给出使用网易云跟帖和来必力的第三方评论功能 四、博客的基本配置1、部署配置 配置到github对应的仓库中 使用hexo deploy或hexo d命令即可发布到github仓库中 浏览器输入网址https://userName.github.io即可访问（userName对应你的用户名） 1234deploy: type: git repo: git@github.com:lawlite19/lawlite19.github.io.git branch: master 2、主题配置 设置为你下载的主题：theme: yilia3、其他 加入如下配置，123456789101112131415161718jsonContent: meta: false pages: false posts: title: true date: true path: true text: true raw: false content: false slug: false updated: false comments: false link: false permalink: false excerpt: false categories: false tags: true 五、进阶功能配置1、网站访问量显示(1) 效果 (2) 实现 我使用了不蒜子第三方的统计插件，网址：http://ibruce.info/2015/04/04/busuanzi/ 在themes\\yilia\\layout\\_partial下的footer.ejs中加入如下代码即可 12345678&lt;script async src=\"//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js\"&gt;&lt;/script&gt;&lt;span id=\"busuanzi_container_site_pv\"&gt; 本站总访问量&lt;span id=\"busuanzi_value_site_pv\"&gt;&lt;/span&gt;次&lt;/span&gt;&lt;span id=\"busuanzi_container_site_uv\"&gt;总访客数&lt;span id=\"busuanzi_value_site_uv\"&gt;&lt;/span&gt;人次&lt;/span&gt; 2、实现单篇文章浏览统计和评论统计 评论数的统计是网易云跟帖中获取的，下面给出(1) 效果(2) 实现 修改themes\\yilia\\layout\\_partial文件夹下的article.ejs文件 在&lt;%- partial(&#39;post/title&#39;, {class_name: &#39;article-title&#39;}) %&gt;节点下加入： 注意这里网易云跟帖还没设置，而评论数中使用到了，这里运行会有问题，下面给出123456789101112131415&lt;!-- 显示阅读和评论数 --&gt;&lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.wangYi)&#123; %&gt;&lt;br/&gt;&lt;a class=\"cloud-tie-join-count\" href=\"javascript:void(0);\" style=\"color:gray;font-size:14px;\"&gt;&lt;span class=\"icon-sort\"&gt;&lt;/span&gt;&lt;span id=\"busuanzi_container_page_pv\" style=\"color:#ef7522;font-size:14px;\"&gt; 阅读数: &lt;span id=\"busuanzi_value_page_pv\"&gt;&lt;/span&gt;次 &amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;a class=\"cloud-tie-join-count\" href=\"javascript:void(0);\" style=\"color:#ef7522;font-size:14px;\"&gt; &lt;span class=\"icon-comment\"&gt;&lt;/span&gt; &lt;span class=\"join-text\" style=\"color:#ef7522;font-size:14px;\"&gt;评论数:&lt;/span&gt; &lt;span class=\"join-count\"&gt;0&lt;/span&gt;次&lt;/a&gt;&lt;% &#125; %&gt; 3、实现网易云跟帖评论(1) 效果 (2) 实现 注册账号：https://gentie.163.com/info.html 填写完成之后获取WEB代码 修改themes\\yilia\\layout\\_partial文件夹下的article.ejs文件 在最后加入 这里需要注意下，一个站点不同端标识文章的方式必须统一（同一站点可以采用以下方式标识文章：①URL；②Sourceid+productKey ；③URL+Sourceid+productKey，建议用②或者③），否则跟贴数据可能错乱。比如同一站点PC端采用URL，APP采用Sourceid+productKey，这种情况跟贴数据会错乱，必选采用统一方式标识。 这里使用方式② 123456789101112131415&lt;!-- 网易云跟帖 --&gt;&lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.wangYi)&#123; %&gt;&lt;section class=\"duoshuo\" id=\"comments\"&gt;&lt;div id=\"cloud-tie-wrapper\" class=\"cloud-tie-wrapper\"&gt;&lt;/div&gt;&lt;script&gt; var cloudTieConfig = &#123; url: \"\", sourceId: \"&lt;%= post.path%&gt;\", productKey: \"&lt;%= config.wangYi%&gt;\", target: \"cloud-tie-wrapper\" &#125;;&lt;/script&gt;&lt;script src=\"https://img1.cache.netease.com/f2e/tie/yun/sdk/loader.js\"&gt;&lt;/script&gt;&lt;/section&gt;&lt;% &#125; %&gt; 在博客的配置文件_config.yml最后加入获取代码中的productKey 1wangYi: 06ab5cdc0b4c45efb39xxxxxxxxxxxx 发布到github上可以查看效果 六、绑定到申请的域名 可以绑定到自己申请的域名上，不用使用userName.github.io访问了，直接使用自己的域名访问1、申请域名 我在万网购买的域名，地址：https://wanwang.aliyun.com/domain/com?spm=5176.8142029.388261.137.LoKzy7 我这里是.me结尾的域名，一年13大洋2、解析域名 添加如下的解析3、配置一下 在博客的source文件夹下建立一个CNAME的文件 内容写入你的域名信息，比如我这里是lawlite.me 发布到github即可4、细节说明 之前网易云跟帖，百度统计设置的域名这里对应该过来一下七、写作的一些说明 执行命令：hexo new &quot;xxxx&quot;创建Markdown文件，在博客的source\\_posts文件夹下 比如如下例子， comments设置为true允许评论，若设置为false则不能评论 reward设置为true允许打赏，若设置为false则不能打赏，（注意对应主题的配置文件reward_type: 设置的为1） 在文章中加入&lt;!-- more --&gt;将文章截断显示在主页","comments":true,"tags":[{"name":"Github","slug":"Github","permalink":"http://lawlite.cn/tags/Github/"},{"name":"Hexo","slug":"Hexo","permalink":"http://lawlite.cn/tags/Hexo/"}]},{"title":"致火影","date":"2017-03-24T13:57:12.000Z","path":"2017/03/24/致火影/","text":"致火影 ——只要有树叶飞舞的地方，火就会燃烧。 昨天就知道火影动漫也完结了，但是没有马上去看，想抽个正式点的时间。 漫画是700集完结，当时动漫到700的时候就有个打算想写点东西记录一下，但是没有动手。今天准备看时还在思考，看完一些回忆涌上，果断提笔。 初三的暑假，当时是在补课，一位小伙伴有火影的光盘，当时就借来看看。记得每天最多能看几十集，当时光盘里面应该是有300集左右。 暑假结束，步入高一，当时并不知道有漫画（毕竟高一才有的QQ），还在军训，班级里面有同学买的关于火影的海报，那时漫画里讲到鼬双重间谍的身份，以及多么爱他的弟弟佐助。后来有了个诺亚舟学习机（当然现在还在），有时周末就去网吧下载火影动漫看。现在来说有的一集看了不止10遍，当然我周围的小伙伴也有一块看的。 高一结束分班，我后面一排的一位小伙伴也看火影，每次周日下午回校，他都和我讨论，当时讨论的还有死神（死神、柯南都有看，但火影是我唯一看的完整的动漫（不算死亡笔记这种比较短的动漫））。 大三的时候火影漫画700完结（700之后的5话是番外），当时写了一段话，但没有发出来。当动漫700之后几集的片尾曲唱到：さようなら（再见）的时候，些许感慨，之后看的时候的片头曲和片尾曲很少跳过。 还记得岸本齐史（AB大叔）有说过，刚开始画火影的时候他还没有结婚，就像鸣人一样希望得到别人的注意，后来结婚，漫画里的鸣人也渐渐的有了朋友。 最后定格在鸣人雏田结婚。 16岁到24岁，谢谢鸣人，谢谢火影! ——思念你的人所在的地方就是你的归宿！ 2017年3月24日","comments":true,"tags":[{"name":"随笔","slug":"随笔","permalink":"http://lawlite.cn/tags/随笔/"}]},{"title":"Keras学习","date":"2017-02-14T12:25:43.000Z","path":"2017/02/14/Keras学习/","text":"一、Keras概述1、介绍 Keras 是一个兼容 Theano 和 Tensorflow 的神经网络高级包 用他来组件一个神经网络更加快速, 几条语句就搞定 Keras 可以再在 Windows 和 MacOS 或者 Linux 上运行 网站：https://keras.io/ 2、安装Keras 需要事先安装好numpy和scipy 直接pip安装：pip install keras Keras有两个backend,就是是基于什么进行运算的，一个是Tensorflow，一个是Theano 通过修改配置文件永久修改 默认配置是Tensorflow，这里改为Theano Windows在用户的文件夹下有个配置文件：C:\\Users\\bob\\.keras文件夹下的keras.json文件 修改即可123456&#123; &quot;image_dim_ordering&quot;: &quot;tf&quot;, &quot;epsilon&quot;: 1e-07, &quot;floatx&quot;: &quot;float32&quot;, &quot;backend&quot;: &quot;theano&quot;&#125; 修改当前脚本的环境变量 123import os os.environ[&apos;KERAS_BACKEND&apos;]=&apos;tensorflow&apos; # 或者theanoimport keras 二、搭建神经网络1、一个神经网络例子 导入包 12345import kerasimport numpy as npfrom keras.models import Sequential # Sequential顺序建立from keras.layers import Dense # 全连接层import matplotlib.pyplot as plt 制造数据 12345678&apos;&apos;&apos;制造数据，并且显示&apos;&apos;&apos;X = np.linspace(-1,1,200)np.random.shuffle(X)Y = 0.5 * X + 2 + np.random.normal(0,0.05,(200,))plt.scatter(X,Y)plt.show()X_train,Y_train = X[:160],Y[:160]X_test,Y_test = X[160:],Y[160:] 建立模型 123&apos;&apos;&apos;建立模型&apos;&apos;&apos; model = Sequential() # 通过Sequential建立model model.add(Dense(output_dim=1, input_dim=1)) # model.add添加神经层，指定输入和输出维度 激活模型 12&apos;&apos;&apos;激活模型&apos;&apos;&apos; model.compile(optimizer=&apos;sgd&apos;, loss=&apos;mse&apos;) 训练模型 1234for i in range(500): cost = model.train_on_batch(X_train,Y_train) # 使用批训练 if i % 50 == 0: print(cost) 测试集的cost误差 12cost = model.evaluate(X_test, Y_test, batch_size=40)print(cost) 学到的权重和偏置 123&apos;&apos;&apos;输出学到的权重和偏置&apos;&apos;&apos; W,b = model.layers[0].get_weights() print(W,b) 预测 1Y_pred = model.predict(X_test) 2、手写数字识别例子–mnist 导入包： 1234567import kerasfrom keras.datasets import mnistfrom keras.utils import np_utilsimport numpy as npfrom keras.models import Sequential # Sequential顺序建立from keras.layers import Dense,Activation # 全连接层from keras.optimizers import RMSprop 加载并预处理数据 123456&apos;&apos;&apos;加载和预处理数据&apos;&apos;&apos;(X_train,y_train),(X_test,y_test) = mnist.load_data() # 下载数据集，windows在当前用户的对应目录下：C:\\Users\\bob\\.keras\\datasetsX_train = X_train.reshape(X_train.shape[0],-1)/255 # X_train是(60000, 28, 28)，reshape一下变成(60000,784),然后在标准化X_test = X_test.reshape(X_test.shape[0],-1)/255y_train = np_utils.to_categorical(y_train,nb_classes=10) # y_train对应的数字1，2，3....转换为0/1映射y_test = np_utils.to_categorical(y_test,nb_classes=10) 建立模型 1234567&apos;&apos;&apos;建立模型&apos;&apos;&apos;model = Sequential(layers=[ Dense(output_dim=32,input_dim=784), # 第一层，输入为784维，输出为32维 Activation(&apos;relu&apos;), # 激励函数为relu Dense(10), # 第二层，这里不需要指定输入层维度，全连接会使用上一层的输出，这里即32 Activation(&apos;softmax&apos;), # 激励函数，也是最后的预测函数使用softmax ]) 激活模型 123456&apos;&apos;&apos;定义optimizer&apos;&apos;&apos;rmsprop = RMSprop()&apos;&apos;&apos;激活模型&apos;&apos;&apos;model.compile(optimizer=rmsprop, loss=&apos;categorical_crossentropy&apos;, # 分类中使用交叉熵损失函数 metrics=[&apos;accuracy&apos;]) # 计算准确度 训练模型 1model.fit(X_train,y_train,nb_epoch=2,batch_size=100) # nb_epoch整个训练集训练次数 测试集上预测信息 1234&apos;&apos;&apos;测试集测试训练出的模型&apos;&apos;&apos;loss,accuracy = model.evaluate(X_test,y_test)print(&apos;loss:&apos;,loss)print(&apos;accuracy&apos;,accuracy) 3、卷积神经网络CNN–mnist 导入包 1234567import kerasfrom keras.datasets import mnistfrom keras.utils import np_utilsimport numpy as npfrom keras.models import Sequential # Sequential顺序建立from keras.layers import Dense,Activation,Convolution2D,MaxPooling2D,Flattenfrom keras.optimizers import RMSprop,Adam 建立模型 123456789101112131415161718192021222324252627282930313233model = Sequential()## 第一层卷积model.add(Convolution2D(nb_filter=32, # 32个filter，即从32个特征提取 nb_row=5, # patch大小 nb_col=5, border_mode=&apos;same&apos;, dim_ordering=&apos;th&apos;, # theano使用th,TensorFlow使用tf input_shape=(1,28,28,) # 输入的大小，1表示输入的channel通道，由于是黑白图所以是1,若是rgb是3个通道 ))## 第一层激活层model.add(Activation(&apos;relu&apos;))## 第一层池化层model.add(MaxPooling2D( pool_size=(2,2), # 2x2的大小 strides=(2,2), # 步长为2，纵向和横向 border_mode=&apos;same&apos;))### 第二层卷积层model.add(Convolution2D(nb_filter=64, # 不需要指定输入的大小了 nb_row=5, nb_col=5, border_mode=&apos;same&apos; ))### 第二层激活层model.add(Activation(&apos;relu&apos;))### 第二层池化层model.add(MaxPooling2D(border_mode=&apos;same&apos;))#### 全连接层model.add(Flatten()) # 展开model.add(Dense(output_dim=1024)) # 输出维度为1024model.add(Activation(&apos;relu&apos;))model.add(Dense(output_dim=10)) # 最终输出为10类model.add(Activation(&apos;softmax&apos;)) 激活模型 1234adam = Adam()model.compile(optimizer=adam, # 使用adam的optimizer loss=&apos;categorical_crossentropy&apos;, metrics=[&apos;accuracy&apos;]) 训练模型 1model.fit(X_train, y_train) 测试集计算结果 1234&apos;&apos;&apos;测试集模型&apos;&apos;&apos;loss,accuracy = model.evaluate(X_test,y_test)print(&quot;loss&quot;,loss)print(&apos;accuracy&apos;,accuracy)","comments":true,"tags":[{"name":"Python","slug":"Python","permalink":"http://lawlite.cn/tags/Python/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://lawlite.cn/tags/DeepLearning/"}]},{"title":"Theano学习","date":"2017-02-10T13:25:43.000Z","path":"2017/02/10/Theano学习/","text":"一、Theano概述1、介绍 Theano 是神经网络python机器学习的模块，和 Tensowflow 类似 可以在MacOS、Linux、Windows上运行 theano 可以使用 GPU 进行运算 网址：http://deeplearning.net/software/theano/ 2、安装 Windows上直接：pip install theano 可能提示个警告：WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string. 二、Theano基础1、基本用法 导入包 123import numpy as npimport theano.tensor as Tfrom theano import function 常量和方程定义 1234x = T.dscalar(&apos;x&apos;) # 建立 x 的容器y = T.dscalar(&apos;y&apos;) # 建立 y 的容器z = x + y # 建立方程f = function([x, y],z) # 使用function定义方程，将输入值 x, y 放在 [] 里, 输出值 z 放在后面 pretty print打印原始方程 导入包：from theano import pp 打印即可：print(pp(z)) 矩阵相乘1234567x = T.dmatrix(&apos;x&apos;) # float64的矩阵,fmatrix对应float32y = T.dmatrix(&apos;y&apos;)z = T.dot(x,y) # 相乘f = function([x,y],z) # 定义functionprint(f(np.arange(12).reshape(3,4), np.ones((4,3))))print(pp(z)) 输出：1234[[ 6. 6. 6.] [ 22. 22. 22.] [ 38. 38. 38.]](x \\dot y) 2、function用法 theano 当中的 function 就和 python 中的 function类似，但是在theano中由于涉及到GPU加速以及CPU的并行的运算，所以他的function会有不同。 多输入和多输出 12345678a,b = T.dmatrices(&apos;a&apos;,&apos;b&apos;) # 定义两个容器diff = a - babs_diff = abs(diff) # 绝对值diff_square = diff ** 2 f = function([a,b],[diff,abs_diff,diff_square]) # function同样前面指定输入，后面是输出x1,x2,x3 = f(np.ones((2,2)), np.arange(4).reshape(2,2))print(x1,x2,x3) 指定function默认值和名字name 123456789x,y,z = T.dscalars(&apos;x&apos;,&apos;y&apos;,&apos;z&apos;) # 定义三个scalar容器w = (x + y) * zf = function([x, theano.In(y,value=1), # 输入y,默认值为1 theano.In(z,value=2,name=&apos;weights&apos;)], # 输入z,默认值为2，同时指定名字为weights，后面可以通过名字复制 w)print(f(2)) # 使用默认值print(f(2,2,3)) # 指定值print(f(2,2,weights=3)) # 通过name赋值 3、Shared变量 Shared 变量，意思是这些变量可以在运算过程中，不停地进行交换和更新值。 在定义 weights 和 bias 的情况下，会需要用到这样的变量 定义shared变量1234567891011state = theano.shared(np.array(0,dtype=np.float64), name=&apos;state&apos;) # state初值为0，为float64increase = T.scalar(&apos;increase&apos;,dtype=state.dtype) # 定义一个容器，这里注意dtype为state.dtype,若是np.float64会报错accmulator = theano.function([increase], # 输入 state, # 输出 updates=[(state,state+increase)]) # 指定每次更新为累加print(state.get_value())# get_value()获取值accmulator(1)print(state.get_value())state.set_value(-1) # set_value()设置值accmulator(1)print(state.get_value()) 输出：1230.01.00.0 临时使用shared变量123456789state = theano.shared(np.array(0,dtype=np.float64), name=&apos;state&apos;) # state初值为0，为float64increase = T.scalar(&apos;increase&apos;,dtype=state.dtype) # 定义一个容器，这里注意dtype为state.dtype,若是np.float64会报错tmp_func = state *2 +increasea = T.scalar(dtype=state.dtype) # 定义标量a，后面用来带起stateskip_shared = theano.function([increase,a], tmp_func, givens=[(state,a)]) # 指定givens参数用a代替stateprint(skip_shared(2,3))print(state.get_value()) # 输出state还是0 4、Theano中的激励函数 sigmoid: theano.tensor.nnet.nnet.sigmoid(x) 还有relu,tanh,softmax,softplus等 在隐含层中常用relu,tanh,softplus等非线性激励函数 在输出层常用sigmoid，softmax求概率 三、搭建神经网络1、定义Layer类或者函数 以后想这样直接使用： 12l1 = Layer(inputs,1,10,T.nnet.relu)l2 = Layer(l1.outputs,10,1,None) 实现代码： 12345678910111213import theanoimport theano.tensor as Timport numpy as npclass Layer(object): def __init__(self,inputs,in_size,out_size,activation_function=None): self.W = theano.shared(np.random.normal(0,1,(in_size,out_size))) # 使用高斯函数初始化，大小为in_size*out_size self.b = theano.shared(np.zeros(out_size) + 0.1) # 指定偏置，大小为out_size，注意+0.1在shared内，否则使用会报错 self.Wx_plus_b = T.dot(inputs,self.W) + self.b self.activation_function = activation_function if activation_function is None: self.outpus = self.Wx_plus_b else: self.outputs = self.activation_function(self.Wx_plus_b) 指定构造函数的参数：inputs,in_size,out_size,activation_function 2、一个神经网络例子 制造数据 123456&apos;&apos;&apos;制造假数据，并显示&apos;&apos;&apos;x_data = np.linspace(-1,1,300)[:,np.newaxis] # [:,np.newaxis]是将(300,)转为(300,1),增加一个维度，将列表转化为矩阵noise = np.random.normal(0,0.05,x_data.shape)y_data = np.square(x_data) -0.5 + noiseplt.scatter(x_data,y_data)plt.show() 定义输入，相当于TensorFlow中的placeholder，后面传入真实数据 12x = T.dmatrix(&apos;x&apos;)y = T.dmatrix(&apos;y&apos;) 定义网络，使用上面定义的Layer 12l1 = Layer(x, 1, 10,T.nnet.relu)l2 = Layer(l1.outputs,10,1,None) 定义cost,并且计算其梯度 12cost = T.mean(T.square(l2.outputs-y))g_w1,g_b1,g_w2,g_b2 = T.grad(cost, [l1.W,l1.b,l2.W,l2.b]) 使用theano中的function进行梯度下降 123456789learning_rate = 0.05&apos;&apos;&apos;调用function，使用梯度下降求解&apos;&apos;&apos;train = theano.function(inputs=[x,y], outputs=cost, updates=[(l1.W, l1.W - learning_rate * g_w1), (l1.b, l1.b - learning_rate * g_b1), (l2.W, l2.W - learning_rate * g_w2), (l2.b, l2.b - learning_rate * g_b2)] ) 传入之前制造的数据训练 1234for i in range(1000): err = train(x_data,y_data) # 训练，传入真实数据 if i%50 == 0: print(err) 预测 12&apos;&apos;&apos;预测，输入为x，输出为layer2的输出&apos;&apos;&apos;prediction = theano.function([x],l2.outputs) 计算准确度函数 1234def compute_accuracy(y_target,y_predict): correct_prediction = np.equal(y_target,y_predict) accuracy = np.sum(correct_prediction)/len(correct_prediction) return accuracy 3、保存和提取模型 导入包：import pickle 保存模型–即学到的参数权重和偏置 12345678&apos;&apos;&apos;保存神经网络--保存学到的参数&apos;&apos;&apos;with open(&apos;model.pickle&apos;, mode=&apos;wb&apos;) as file: #model = [l1.W.get_value(),l1.b.get_value(), # l2.W.get_value(),l2.b.get_value()] model = &#123;&apos;layer1_w&apos;:l1.W.get_value(),&apos;layer1_b&apos;:l1.b.get_value(), &apos;layer2_w&apos;:l2.W.get_value(),&apos;layer2_b&apos;:l2.b.get_value()&#125; # 保存为字典形式，通过get_value()获取值 pickle.dump(model, file) print(model[&apos;layer1_w&apos;]) 提取模型 1234with open(&apos;model.pickle&apos;,&apos;rb&apos;) as file: model = pickle.load(file) l1.W.set_value(model[&apos;layer1.w&apos;]) # 通过set_value()将值设置进去 ...","comments":true,"tags":[{"name":"Python","slug":"Python","permalink":"http://lawlite.cn/tags/Python/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://lawlite.cn/tags/DeepLearning/"}]},{"title":"论文记录-Batch-Normalization","date":"2017-01-09T13:37:38.000Z","path":"2017/01/09/论文记录-Batch-Normalization/","text":"参考论文：http://jmlr.org/proceedings/papers/v37/ioffe15.pdf 一、论文概述 2015年Google提出的Batch Normalization 训练深层的神经网络很复杂，因为训练时每一层输入的分布在变化，导致训练过程中的饱和，称这种现象为：internal covariate shift 需要降低学习率Learning Rate和注意参数的初始化 论文中提出的方法是对于每一个小的训练batch都进行标准化（正态化） 允许使用较大的学习率 不必太关心初始化的问题 同时一些例子中不需要使用Dropout方法避免过拟合 此方法在ImageNet classification比赛中获得4.82% top-5的测试错误率 二、BN思路1、问题 如果输入数据是白化的（whitened），网络会更快的收敛 白化目的是降低数据的冗余性和特征的相关性，例如通过线性变换使数据为0均值和单位方差 并非直接标准化每一层那么简单，如果不考虑归一化的影响，可能会降低梯度下降的影响 标准化与某个样本和所有样本都有关系 解决上面的问题，我们希望对于任何参数值，都要满足想要的分布；$$\\widehat x Norm(x,\\chi )$$ 对于反向传播，需要计算:${\\partial Norm(x,\\chi )} \\over {\\partial x}$和${\\partial Norm({x},\\chi )} \\over {\\partial \\chi }$ 这样做的计算代价是非常大的，因为需要计算x的协方差矩阵 然后白化操作：$${x - E[x]} \\over {\\sqrt {Cov[x]} }$$ 上面两种都不行或是不好，进而得到了BN的方法 既然白化每一层的输入代价非常大，我们可以进行简化 2、简化1 标准化特征的每一个维度而不是去标准化所有的特征，这样就不用求协方差矩阵了 例如d维的输入：$$x = ({x^{(1)}},{x^{(2)}}, \\cdots ,{x^{(d)}})$$ 标准化操作：$${\\widehat x^k} = {x^{(k) - E[x^{(k)}]} \\over {\\sqrt {Var[x^{(k)}]} }}$$ 需要注意的是标准化操作可能会降低数据的表达能力,例如我们之前提到的Sigmoid函数，标准化之后均值为0，方差为1，数据就会落在近似线性的函数区域内，这样激活函数的意义就不明显 所以对于每个标准化之后的$\\widehat x^{(k)}$，对应一对参数：${\\gamma ^{(k)}},{\\beta ^{(k)}}$ ，然后令：${y^{(k)}} = {\\gamma ^{(k)}}{\\widehat x^{(k)}} + {\\beta ^{(k)}}$ 从式子来看就是对标准化的数据进行缩放和平移，不至于使数据落在线性区域内，增加数据的表达能力（式子中如果：${\\gamma ^{(k)}} = \\sqrt {Var[x^{(k)}]}, {\\beta ^{(k)}} = E[x^{(k)}]$ ，就会使恢复到原来的值了） 但是这里还是使用的全部的数据集，但是如果使用随机梯度下降，可以选取一个batch进行训练 3、简化2 第二种简化就是使用mini-batch进行随机梯度下降 注意这里使用mini-batch也是标准化每一个维度上的特征，而不是所有的特征一起，因为若果mini-batch中的数据量小于特征的维度时，会产生奇异协方差矩阵， 对应的行列式的值为0，非满秩 假设mini-batch 大小为m的B $B = \\{ {x_{1 \\ldots m}}\\}$对应的变换操作为：$$B{N_{\\gamma ,\\beta }}:{x_{1 \\ldots m}} \\to {y_{1 \\ldots m}}$$ 作者给出的批标准化的算法如下： 算法中的ε是一个很小的常量，为了保证数值的稳定性（就是防止除数为0） 4、反向传播求梯度： 因为：$$y^{(k)} = \\gamma ^{(k)}\\widehat x^{(k)} + \\beta ^{(k)}$$ 所以：$${\\partial l \\over \\partial \\widehat x_i} = {\\partial l \\over \\partial y_i}\\gamma $$ 因为：$$\\widehat x_i = {x_i - \\mu _B \\over {\\sqrt {\\sigma _B^2 + \\varepsilon } }}$$ 所以：$${\\partial l \\over \\partial \\sigma _B^2} = \\sum\\limits_{i=1}^m {\\partial l \\over \\partial \\widehat x_i} (x_i- \\mu_B) {-1 \\over 2}(\\sigma_B^2 + \\varepsilon)^{-{3\\over2}}$$$${\\partial l \\over \\partial u_B} = \\sum\\limits_{i = 1}^m {\\partial l \\over \\partial \\widehat x_i} { - 1 \\over \\sqrt {\\sigma _B^2 + \\varepsilon }}$$ 因为：${\\mu _B} = {1 \\over m}\\sum\\limits_{i = 1}^m $和$\\sigma _B^2 = {1 \\over m}\\sum\\limits_{i = 1}^m {({x_i}} - {\\mu _B}{)^2}$ 所以：$${\\partial l \\over \\partial x_i} = {\\partial l \\over \\partial \\widehat x_i}{1 \\over \\sqrt {\\sigma _B^2 + \\varepsilon } } + {\\partial l \\over \\partial \\sigma _B^2}{2(x_i - \\mu _B) \\over m} + {\\partial l \\over \\partial u_B}{1 \\over m}$$ 所以：$${\\partial l \\over \\partial \\gamma } = \\sum\\limits_{i = 1}^m {\\partial l \\over \\partial y_i} {\\widehat x_i}$$$${\\partial l \\over \\partial \\beta } = \\sum\\limits_{i = 1}^m {\\partial l \\over \\partial y_i} $$ 对于BN变换是可微分的，随着网络的训练，网络层可以持续学到输入的分布。 三、BN网络的训练和推断（预测）1、预测的问题 按照BN方法，输入数据x会经过变化得到BN（x），然后可以通过随机梯度下降进行训练，标准化是在mini-batch上所以是非常高效的。 但是对于推断我们希望输出只取决于输入，而对于输入只有一个实例数据，无法得到mini-batch的其他实例，就无法求对应的均值和方差了。 2、解决方法 可以通过从所有训练实例中获得的统计量来代替mini-batch中m个训练实例获得统计量均值和方差 比如我们机器学习算法，在训练集上进行了标准化，在测试集上的标准化操作时利用的训练集上的数据(Standarscaler中的mean和variance) 我们对每个mini-batch做标准化，可以对记住每个mini-batch的B，然后得到全局统计量 $$E[x] \\leftarrow E_B[{\\mu _B}]$$ $$Var[x] \\leftarrow {m \\over {m - 1}}E_B[\\sigma _B^2]$$（这里方差采用的是无偏方差估计，所以是m-1） 所以推断采用BN的方式为：$$\\eqalign{&amp; y = \\gamma {x - E(x) \\over \\sqrt {Var[x] + \\varepsilon }} + \\beta \\cr&amp; \\quad= {\\gamma \\over \\sqrt {Var[x] + \\varepsilon }}x + (\\beta - {\\gamma E[x] \\over \\sqrt {Var[x] + \\varepsilon }})} $$3、完整算法 作者给出的完整算法： 四、实验 最后给出的实验可以看出使用BN的方式训练精准度很高而且很稳定。","comments":true,"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://lawlite.cn/tags/DeepLearning/"},{"name":"Paper阅读记录","slug":"Paper阅读记录","permalink":"http://lawlite.cn/tags/Paper阅读记录/"}]},{"title":"论文记录-Relu激励函数权重初始化","date":"2017-01-09T07:20:00.000Z","path":"2017/01/09/论文记录-Relu激励函数权重初始化/","text":"参考论文：点击这里查看 上一篇博客谈到了关于Sigmoid，tanh激励函数的权重初始化方法，以及深度神经网络为什么难训练 这篇博客主要推导关于Relu类激励函数的权重初始化方法 一、ReLu/PReLu激励函数 目前ReLu激活函数使用比较多，而上一篇论文博客中没有讨论，如果还是使用同样初始化权重的方法（Xavier初始化）会有问题 PReLu函数定义如下： 等价于：$$f(y_i) = \\max (0,y_i) + a_i\\min (0,y_i)$$ ReLu（左）和PReLu（右）激活函数图像 二、前向传播推导1、符号说明$\\varepsilon$……………………………………目标函数$\\mu$……………………………………动量$\\alpha$……………………………………学习率$f()$…………………………………激励函数$l$……………………………………当前层layer$L$……………………………………神经网络总层数$b$…………………………..…………偏置向量 2、推导过程 可以得到：$$y_l = W_l x_l + b_l……………………………………..(1)$$$$x_l= f(y_{l - 1})$$ 根据式(1)得：$$Var[y_l] = n_lVar[w_lx_l]………………………………….(2)$$ 因为初始化权重w均值为0，所以 期望：$$E(w_l) = 0$$ 方差：$$Var[w_l] = E(w_l^2) - E^2(w_l) = E(w_l^2)$$ 根据 公式(2) 继续推导： $Var[y_l] = n_l Var[w_l x_l]\\\\\\quad \\quad\\quad = n_l[E(w_l^2 x_l^2) - E^2(w_l x_l)]\\\\\\quad \\quad\\quad = n_lE(w_l^2)E(x_l^2)\\\\\\quad \\quad\\quad = n_lVar[w_l]E(x_l^2)……………………………………..(3)$ 对于x来说：$Var[x_l] \\ne E[x_l^2]$，除非x的均值也是0, 对于ReLu函数来说：$x_l = \\max (0,y_{l - 1})$，所以不可能均值为0 w满足对称区间的分布，并且偏置${b_{l - 1}} = 0$，所以${y_{l - 1}}$也满足对称区间的分布，所以： $E(x_l^2) = E[max(0, y_{l-1})^2]\\\\\\quad \\quad\\quad= {1\\over 2} [E(y_{l-1}^2)]\\\\\\quad \\quad\\quad= {1 \\over 2} [E(y_{l-1}^2) - E^2(y_{l-1})]……………………………………(4)$ 将上式(4)代入(3)中得：$$Var[y_l] = {1 \\over 2}{n_l}Var[w_l]Var[y_{l - 1}]……………………………………….(5)$$ 所以对于L层:$$Var[y_L] = Var[y_1]\\prod\\limits_{l = 2}^L {1 \\over 2}n_lVar[w_l] …………………………………..(6)$$ 从上式可以看出，因为累乘的存在，若是$${1 \\over 2}n_lVar[w_l] &lt; 1$$，每次累乘都会使方差缩小，若是大于1，每次会使方差当大。 所以我们希望：$${1 \\over 2}n_lVar[w_l] = 1$$ 所以初始化方法为：是w满足均值为0，标准差为$\\sqrt {2 \\over n_l}$的高斯分布，同时偏置初始化为0 三、反向传播推导 $\\Delta x_l = \\widehat W_l\\Delta y_l…………………………………………….(7)$ 假设$\\widehat W_l$和$\\Delta y_l$相互独立 当$\\widehat W_l$初始化为对称区间的分布时，可以得到：$\\Delta x_l$的均值为0 △x,△y都表示梯度，即：$$\\Delta x = {\\partial \\varepsilon \\over \\partial x}$$，$$\\Delta y = {\\partial \\varepsilon \\over \\partial y}$$ 根据反向传播：$$\\Delta {y_l} = f^{‘}(y_l)\\Delta x_{l + 1}$$ 对于ReLu函数，f的导数为0或1，且概率是相等的，假设$f^{‘}(y_l)$和$\\Delta x_{l + 1}$是相互独立的， 所以：$$E[\\Delta y_l] = E[\\Delta x_{l + 1}]/2 = 0$$ 所以：$$E[(\\Delta y_l)^2] = Var[\\Delta y_l] = {1 \\over 2}Var[\\Delta x_{l + 1}]……………………………………………(8)$$ 根据(7)可以得到： $Var[\\Delta x_l] = \\widehat n_l Var[w_l] Var[\\Delta y_l] \\\\\\quad\\quad\\quad\\quad= {1\\over2} {\\widehat n_l Var[w_l]Var[\\Delta x_{l+1}]}$ 将L层展开得：$$Var[\\Delta x_2] = Var[\\Delta x_{L + 1}]\\prod\\limits_{l = 2}^L {1 \\over 2}\\widehat n_lVar[w_l]…………………………………………………..(9)$$ 同样令：$${1 \\over 2}\\widehat n_lVar[w_l] = 1$$ 注意这里：$\\widehat n_l = k_l^2d_l$，而$n_l = k_l^2c_l = k_l^2d_{l - 1}$ 所以$w_l$应满足均值为0，标准差为$\\sqrt {2 \\over \\widehat n_l}$的的分布 四、正向和反向传播讨论、实验和PReLu函数1、正向和方向传播 对于正向和反向两种初始化权重的方式都是可以的，论文中的模型都能够收敛 比如利用反向传播得到的初始化得到：$$\\prod\\limits_{l = 2}^L {1 \\over 2}\\widehat n_lVar[{w_l}] = 1$$ 对应到正向传播中得到： $\\prod\\limits_{l=2}^L{1\\over2} {n_lVar[w_l]} = \\prod\\limits_{l=2}^L {n_l \\over \\widehat n_l}\\\\\\quad\\quad\\quad\\quad\\quad\\quad= {k_2^2 c_2 \\over k_2^2 d_2} \\cdot {k_3^2 d_2 \\over k_3^2d_3} \\cdot {k_L^2d_L \\over K_L^2 d_L} \\\\\\quad\\quad\\quad\\quad\\quad\\quad= {c_2 \\over d_L}$ 所以也不是逐渐缩小的 实验给出了与第一篇论文的比较，如下图所示，当神经网络有30层时，Xavier初始化权重的方法（第一篇论文中的方法）已经不能收敛。 2、PRelu对应方差 对于PReLu激励函数可以得到：$${1 \\over 2}(1 + a^2)n_lVar[w_l] = 1$$ 当a=0时就是对应的ReLu激励函数 当a=1是就是对应线性函数","comments":true,"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://lawlite.cn/tags/DeepLearning/"},{"name":"Paper阅读记录","slug":"Paper阅读记录","permalink":"http://lawlite.cn/tags/Paper阅读记录/"}]},{"title":"Python机器学习","date":"2017-01-08T15:01:58.000Z","path":"2017/01/08/Python机器学习/","text":"机器学习算法Python实现说明 github地址：https://github.com/lawlite19/MachineLearning_Python 因为里面的公式加载出现问题，这里只给出了目录，可以去github中查看目录 机器学习算法Python实现 一、线性回归 1、代价函数 2、梯度下降算法 3、均值归一化 4、最终运行结果 5、使用scikit-learn库中的线性模型实现 二、逻辑回归 1、代价函数 2、梯度 3、正则化 4、S型函数（即） 5、映射为多项式 6、使用的优化方法 7、运行结果 8、使用scikit-learn库中的逻辑回归模型实现 逻辑回归_手写数字识别_OneVsAll 1、随机显示100个数字 2、OneVsAll 3、手写数字识别 4、预测 5、运行结果 6、使用scikit-learn库中的逻辑回归模型实现 三、BP神经网络 1、神经网络model 2、代价函数 3、正则化 4、反向传播BP 5、BP可以求梯度的原因 6、梯度检查 7、权重的随机初始化 8、预测 9、输出结果 四、SVM支持向量机 1、代价函数 2、Large Margin 3、SVM Kernel（核函数） 4、使用中的模型代码 5、运行结果 五、K-Means聚类算法 1、聚类过程 2、目标函数 3、聚类中心的选择 4、聚类个数K的选择 5、应用——图片压缩 6、使用scikit-learn库中的线性模型实现聚类 7、运行结果 六、PCA主成分分析（降维） 1、用处 2、2D–&gt;1D，nD–&gt;kD 3、主成分分析PCA与线性回归的区别 4、PCA降维过程 5、数据恢复 6、主成分个数的选择（即要降的维度） 7、使用建议 8、运行结果 9、使用scikit-learn库中的PCA实现降维 七、异常检测 Anomaly Detection 1、高斯分布（正态分布） 2、异常检测算法 3、评价的好坏，以及的选取 4、选择使用什么样的feature（单元高斯分布） 5、多元高斯分布 6、单元和多元高斯分布特点 7、程序运行结果","comments":true,"tags":[{"name":"Python","slug":"Python","permalink":"http://lawlite.cn/tags/Python/"},{"name":"机器学习","slug":"机器学习","permalink":"http://lawlite.cn/tags/机器学习/"}]},{"title":"论文记录-UnderstandingTheDifficultyOfTrainingDeepFeedforwardNeuralNetworks","date":"2016-12-20T11:03:24.000Z","path":"2016/12/20/论文记录-UnderstandingTheDifficultyOfTrainingDeepFeedforwardNeuralNetworks/","text":"1、说明 2010年的一篇论文，说明深度神经网络为什么难以训练，当时只讨论了Sigmoid，tanh和Softsign激活函数 提出了一种初始化权重weights的方法，能够解决训练中梯度消失的问题 但是使用现在的ReLu激活函数，同样使用此初始化方法就会出现问题。 2、Sigmoid激励函数实验 说明 论文首先通过实验观察激活函数的影响，指出Sigmoid函数是不适合作为深度神经网络激活函数的 因为它的均值总是大于0的，如下图，导致后面的隐藏层hidden layer趋于饱和，并且发现饱和的神经元可以自发移出饱和趋于，但是非常慢。接着发现一个新的非线性的激活函数是非常有益的。 最后观察每一层激活值和梯度的变化，给出了一种新的初始化权重的方法。 实验部分 初始化偏置biases为0，权重w服从均匀分布，即：$${{W_{ij}} \\sim U[ - {1 \\over {\\sqrt n }},{1 \\over {\\sqrt n }}]}$$ 其中n为前一层的神经元个数。然后构建了一个含有4个隐含层的神经网络，激活函数使用的是Sigmoid 观察每一层的激活值的均值和标准差随着训练次数的变化，layer1表示第一个隐含层的输出，以此类推。如图所示：实线表示均值mean value，垂直的条表示标准差。 实验的直观理解 最后我们使用 ${Softmax(b+Wh)}$ 作为输出预测的，刚开始训练的时候不能够很好的预测y的值，因此误差梯度会迫使Wh趋于0，所以会是h的值趋于0，h就是上一层的输出，所以激活值很快为0。 但是对于tanh函数是关于原点对称的，图像如下，值趋于0是好的，因为梯度能够反向传播回去，但是对于sigmoid函数来说就趋于饱和的位置了，梯度很难反向传回去，也就学习不到东西了。 3、梯度计算和公式推导1) 代价函数 代价函数使用的是交叉熵代价函数，相比对于二次代价函数会更好 二次代价函数较为平坦，所以使用梯度下降会比较慢。2) 公式推导 符号说明${z^i}$………………………………第i层的激活值向量${s^i}$………………………………第i+1层的输入$X$………………………………输入${n_i}$………………………………第i层神经元个数$W$………………………………权重 可以得到：$${s^i = {z^i}{W^i} + {b^i}}$$$${z^{i + 1} = f({s^i})}$$ 所以分别对上面两式求偏导可以得到：$${{\\partial Cost \\over \\partial s_k^i}=f^{'}W_{k,\\bullet}^{i+1}}{ \\partial Cost \\over \\partial s^{i+1}}…………………………….(1)$$ $${{\\partial Cost \\over \\partial w_{l,k}^i} = z_l^i}{\\partial Cost \\over \\partial s_k^i}........................................(2)$$ 推导如下 ![BP推导][5] - 上面公式推导说明 - 其中 $${{\\partial Cost \\over \\partial s^{i-1}}={\\delta ^{i-1}}}$$ 这里W从1开始，上面给出的最终公式是从0开始。 对权重的偏导（梯度）再乘以输入 ${z^i}$ 即可。 因为我们使用均匀分布进行初始化，所以方差是一样的，对于tanh函数的导数，$${[\\tanh (x)]^{‘}} = 1 - {[\\tanh (x)]^2}$$ 所以：$${f^,}(s_k^i) \\approx 1$$ 实际这里作者假设了这个区间内激活函数是线性的，第二篇论文中也有提到。（下面会给出） 根据方差的公式： $$Var(x) = E({x^2}) - {E^2}(x)$$ 可以得到: $${Var[z^i] = Var[x] \\prod\\limits_{j=0}^{i-1}n_j Var[W^j]}…………………………(3)$$ 推导如下： ${Var(s) = Var(\\sum\\limits_i^n w_i x_i)}=\\sum\\limits_i^n Var(w_ix_i)$ ${Var(wx) = E(w^2x^2) - E^2(wx)} \\\\\\quad\\quad\\quad\\quad=E(w^2)E(x^2) - E^2(w)E^2(x) \\\\\\quad\\quad\\quad\\quad=[E(w^2)-E^2(w)][E(x^2)-E^2(x)] + E^2(w)[E(x^2)-E^2(x)] + E^2(x)[E(w^2)-E^2(w)] \\\\\\quad\\quad\\quad\\quad=Var(w)Var(x)+E^2Var(x)+E^2Var(w)$ 因为输入的均值为0，所以$${E(w) = E(x) = 0}$$ 所以：$${Var(wx) = Var(w)Var(x)}$$ 又因为${f^{‘}(s_k^i) \\approx 1}$成立，然后代入上面的式子即可 根据公式（1），所以对${S^i}$偏导数的方差为：$${Var[{\\partial Cost \\over \\partial s^i}]} = {Var[{\\partial Cost \\over \\partial s^n}]}{\\prod\\limits_{j=i}^n}{n_{j+1}Var[W^j]}$$ 根据公式（2），代入到对权重w偏导（即为梯度）的方差为: $${Var[{\\partial Cost \\over \\partial w^i}]} = {\\prod \\limits_{j=0}^{i-1} n_j Var[W^j]}{\\prod \\limits_{j=i}^{n-1} n_{j+1}Var[W^j] \\ast Var[x] Var[{\\partial Cost \\over \\partial s^n}]}$$ 对于正向传播，希望：$$\\forall (i,j),Var[{z^i}] = Var[{z^j}]$$ 从反向传播的角度同样可以有：$${\\forall (i,j), Var[{\\partial Cost \\over \\partial s^i}]} = Var[{\\partial Cost \\over \\partial s^j}]$$ 就可以转化为：$$\\left\\{ {\\matrix{{n_iVar[w^i]}=1 \\cr{n_{i+1}Var[w^i]}=1 \\cr} }…………………………(4) \\right.$$ 比如第一种(公式（3）)： $${Var[z^i] = Var[x] \\prod\\limits_{j=0}^{i-1}n_j Var[W^j]}$$ $$Var(z^i) = Var(x)$$ 所以${n_i}Var[{w^i}] = 1$ ，第二种情况同理 所以将 （4） 中的两式相加可得：$${Var[{W^i}]}={2 \\over {n_i + n_{i+1}}}$$ 如果所有层的神经元个数一样时：$$\\left\\{ {\\matrix{{Var[{\\partial Cost \\over \\partial s^i}] = [nVar[W]]^{d-i}Var[x]} \\cr{Var[{\\partial Cost \\over \\partial w^i}] = [nVar[w]]^{d}Var[x]Var[{\\partial Cost \\over \\partial w^n}]} \\cr}} \\right.$$ 可以看到，所有层的梯度的方差都是一样的。但是对于很深层的神经网络还是有可能导致梯度消失。 4、初始化权重方法 最后提出了一个归一化的初始化方法，因为W服从均匀分布，根据均匀分布的方差公式可以得到：$${[c-(-c)]^2 \\over 12} = {c^2 \\over 3}$$ 所以得到：$${2 \\over {n_i + n_{i+1}} =}{ c^2 \\over 3}$$ 求出: $$c={\\sqrt 6 \\over \\sqrt {n_i + n_{i+1}}}$$ 所以最终给出初始化权重的方法为：$${W \\sim U[-{{\\sqrt 6}\\over {\\sqrt n_i+n_{i+1}}},{\\sqrt 6 \\over \\sqrt {n_i + n_{i+1}}}]}$$ 5、总结 论文讨论了Sigmoid，tanh激励函数权重初始化的问题，并给出了初始化的方法，- 但是针对ReLu这种激励函数是不适用的，第二篇会提到。 并且推导过程中假设了激励函数在初始化对应区间上是线性的，即假设导数恒为1我感觉也是存在问题的。 作者给出的实验部分网络的深度还是很有限的，随着网络的不断加深，对应的初始化权重的分布范围还是会不断减小的。可以通过控制学习率参数等方式来进行对应处理。 Reference http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf","comments":false,"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://lawlite.cn/tags/DeepLearning/"},{"name":"Paper阅读记录","slug":"Paper阅读记录","permalink":"http://lawlite.cn/tags/Paper阅读记录/"}]},{"title":"Tensorflow学习","date":"2016-12-08T08:07:33.000Z","path":"2016/12/08/Tensorflow学习/","text":"github地址：https://github.com/lawlite19/MachineLearning_TensorFlow 一、TensorFlow介绍 1、什么是TensorFlow 官网：https://www.tensorflow.org/ TensorFlow是Google开发的一款神经网络的Python外部的结构包, 也是一个采用数据流图来进行数值计算的开源软件库. 先绘制计算结构图, 也可以称是一系列可人机交互的计算操作, 然后把编辑好的Python文件 转换成 更高效的C++, 并在后端进行计算. 2、TensorFlow强大之处 擅长的任务就是训练深度神经网络 快速的入门神经网络,大大降低了深度学习（也就是深度神经网络）的开发成本和开发难度 TensorFlow 的开源性, 让所有人都能使用并且维护 3、安装TensorFlow 暂不支持Windows下安装TensorFlow,可以在虚拟机里使用或者安装Docker安装 这里在CentOS6.5下进行安装 安装Python2.7，默认CentOS中安装的是Python2.6 先安装zlib的依赖，下面安装easy_install时会用到 12yum install zlibyum install zlib-devel 在安装openssl的依赖，下面安装pip时会用到 12yum install opensslyum install openssl-devel 下载安装包，我传到github上的安装包，https协议后面加上--no-check-certificate，： 1wget https://raw.githubusercontent.com/lawlite19/LinuxSoftware/master/python/Python-2.7.12.tgz --no-check-certificate 解压缩：tar -zxvf xxx 进入，配置：./configure --prefix=/usr/local/python2.7 编译并安装：make &amp;&amp; make install 创建链接来使系统默认python变为python2.7,ln -fs /usr/local/python2.7/bin/python2.7 /usr/bin/python 修改一下yum，因为yum的执行文件还是需要原来的python2.6,vim /usr/bin/yum1#!/usr/bin/python 修改为系统原有的python版本地址 1#!/usr/bin/python2.6 安装easy_install 下载：wget https://raw.githubusercontent.com/lawlite19/LinuxSoftware/blob/master/python/setuptools-26.1.1.tar.gz --no-check-certificate 解压缩：tar -zxvf xxx python setup.py build #注意这里python是新的python2.7 python setup.py install 到/usr/local/python2.7/bin目录下查看就会看到easy_install了 创建一个软连接：ln -s /usr/local/python2.7/bin/easy_install /usr/local/bin/easy_install 就可以使用easy_install 包名 进行安装 安装pip 下载: 解压缩：tar -zxvf xxx 安装：python setup.py install 到/usr/local/python2.7/bin目录下查看就会看到pip了 同样创建软连接：ln -s /usr/local/python2.7/bin/pip /usr/local/bin/pip 就可以使用pip install 包名进行安装包了 安装wingIDE 默认安装到/usr/local/lib下，进入，执行./wing命令即可执行 创建软连接：ln -s /usr/local/lib/wingide5.1/wing /usr/local/bin/wing 破解： [另]安装VMwareTools，可以在windows和Linux之间复制粘贴 启动CentOS 选择VMware中的虚拟机–&gt;安装VMware Tools 会自动弹出VMware Tools的文件夹 拷贝一份到root目录下 cp VMwareTools-9.9.3-2759765.tar.gz /root 解压缩 tar -zxvf VMwareTools-9.9.3-2759765.tar.gz 进入目录执行，vmware-install.pl，一路回车下去即可 重启CentOS即可 安装numpy 直接安装没有出错 安装scipy 安装依赖：yum install bzip2-devel pcre-devel ncurses-devel readline-devel tk-devel gcc-c++ lapack-devel 安装即可：pip install scipy 安装matplotlib 安装依赖：yum install libpng-devel 安装即可：pip install matplotlib 运行可能有以下的错误：1ImportError: No module named _tkinter 安装：tcl8.5.9-src.tar.gz 进入安装即可,./confgiure make make install安装：tk8.5.9-src.tar.gz 进入安装即可。 [注意]要重新安装一下Pyhton2.7才能链接到tkinter 安装scikit-learn 直接安装没有出错，但是缺少包bz2 将系统中python2.6的bz2复制到python2.7对应文件夹下1cp /usr/lib/python2.6/lib-dynload/bz2.so /usr/local/python2.7/lib/python2.7/lib-dynload 安装TensorFlow 官网点击 选择对应的版本 1234567891011121314151617181920212223242526272829303132 # Ubuntu/Linux 64-bit, CPU only, Python 2.7$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp27-none-linux_x86_64.whl# Ubuntu/Linux 64-bit, GPU enabled, Python 2.7# Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see &quot;Installing from sources&quot; below.$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc0-cp27-none-linux_x86_64.whl# Mac OS X, CPU only, Python 2.7:$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0rc0-py2-none-any.whl# Mac OS X, GPU enabled, Python 2.7:$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-0.12.0rc0-py2-none-any.whl# Ubuntu/Linux 64-bit, CPU only, Python 3.4$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp34-cp34m-linux_x86_64.whl# Ubuntu/Linux 64-bit, GPU enabled, Python 3.4# Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see &quot;Installing from sources&quot; below.$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc0-cp34-cp34m-linux_x86_64.whl# Ubuntu/Linux 64-bit, CPU only, Python 3.5$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp35-cp35m-linux_x86_64.whl# Ubuntu/Linux 64-bit, GPU enabled, Python 3.5# Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see &quot;Installing from sources&quot; below.$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc0-cp35-cp35m-linux_x86_64.whl# Mac OS X, CPU only, Python 3.4 or 3.5:$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0rc0-py3-none-any.whl# Mac OS X, GPU enabled, Python 3.4 or 3.5:$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-0.12.0rc0-py3-none-any.whl 对应python版本 12345 # Python 2$ sudo pip install --upgrade $TF_BINARY_URL# Python 3$ sudo pip3 install --upgrade $TF_BINARY_URL 可能缺少依赖glibc,看对应提示的版本， 还有可能报错1ImportError: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.19&apos; not found (required by /usr/local/python2.7/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so) 安装对应版本的glibc 查看现有版本的glibc, strings /lib64/libc.so.6 |grep GLIBC 下载对应版本：wget http://ftp.gnu.org/gnu/glibc/glibc-2.17.tar.gz 解压缩：tar -zxvf glibc-2.17 进入文件夹创建build文件夹cd glibc-2.17 &amp;&amp; mkdir build 配置： 123456../configure \\ --prefix=/usr \\ --disable-profile \\ --enable-add-ons \\ --enable-kernel=2.6.25 \\ --libexecdir=/usr/lib/glibc 编译安装：make &amp;&amp; make install 可以再用命令：strings /lib64/libc.so.6 |grep GLIBC查看 添加GLIBCXX_3.4.19的支持 下载：wget https://raw.githubusercontent.com/lawlite19/LinuxSoftware/master/python2.7_tensorflow/libstdc++.so.6.0.20 复制到/usr/lib64文件夹下：cp libstdc++.so.6.0.20 /usr/lib64/ 添加执行权限：chmod +x /usr/lib64/libstdc++.so.6.0.20 删除原来的：rm -rf /usr/lib64/libstdc++.so.6 创建软连接：ln -s /usr/lib64/libstdc++.so.6.0.20 /usr/lib64/libstdc++.so.6 可以查看是否有个版本：strings /usr/lib64/libstdc++.so.6 | grep GLIBCXX 运行还可能报错编码的问题，这里安装0.10.0版本:pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl 安装pandas pip install pandas没有问题 二、TensorFlow基础架构1、处理结构 Tensorflow 首先要定义神经网络的结构,然后再把数据放入结构当中去运算和 training TensorFlow是采用数据流图（data flow graphs）来计算 首先我们得创建一个数据流流图 然后再将我们的数据（数据以张量(tensor)的形式存在）放在数据流图中计算 张量（tensor): 张量有多种. 零阶张量为 纯量或标量 (scalar) 也就是一个数值. 比如 1 一阶张量为 向量 (vector), 比如 一维的 [1, 2, 3] 二阶张量为 矩阵 (matrix), 比如 二维的 [[1, 2, 3],[4, 5, 6],[7, 8, 9]] 以此类推, 还有 三阶 三维的 … 2、一个例子 求y=1*x+3中的权重1和偏置3 定义这个函数 12x_data = np.random.rand(100).astype(np.float32)y_data = x_data*1.0+3.0 创建TensorFlow结构 1234567Weights = tf.Variable(tf.random_uniform([1], -1.0, 1.0)) # 创建变量Weight是，范围是 -1.0~1.0biases = tf.Variable(tf.zeros([1])) # 创建偏置，初始值为0y = Weights*x_data+biases # 定义方程loss = tf.reduce_mean(tf.square(y-y_data)) # 定义损失，为真实值减去我们每一步计算的值optimizer = tf.train.GradientDescentOptimizer(0.5) # 0.5 是学习率train = optimizer.minimize(loss) # 使用梯度下降优化init = tf.initialize_all_variables() # 初始化所有变量 定义Session 12sess = tf.Session()sess.run(init) 输出结果 1234for i in range(201): sess.run(train) if i%20 == 0: print i,sess.run(Weights),sess.run(biases) 结果为： 1234567891011 0 [ 1.60895896] [ 3.67376709]20 [ 1.04673827] [ 2.97489643]40 [ 1.011392] [ 2.99388123]60 [ 1.00277638] [ 2.99850869]80 [ 1.00067675] [ 2.99963641]100 [ 1.00016499] [ 2.99991131]120 [ 1.00004005] [ 2.99997854]140 [ 1.00000978] [ 2.99999475]160 [ 1.0000025] [ 2.99999857]180 [ 1.00000119] [ 2.99999928]200 [ 1.00000119] [ 2.99999928] 3、Session会话控制 运行 session.run() 可以获得你要得知的运算结果, 或者是你所要运算的部分 定义常量矩阵：tf.constant([[3,3]]) 矩阵乘法 ：tf.matmul(matrix1,matrix2) 运行Session的两种方法： 手动关闭 123sess = tf.Session()print sess.run(product)sess.close() 使用with，执行完会自动关闭 12with tf.Session() as sess:print sess.run(product) 4、Variable变量 定义变量：tf.Variable() 初始化所有变量：init = tf.initialize_all_variables() 需要再在 sess 里, sess.run(init) , 激活变量 输出时，一定要把 sess 的指针指向变量再进行 print 才能得到想要的结果 5、Placeholder传入值 首先定义Placeholder，然后在Session.run()的时候输入值 placeholder 与 feed_dict={} 是绑定在一起出现的1234567input1 = tf.placeholder(tf.float32) #在 Tensorflow 中需要定义 placeholder 的 type ，一般为 float32 形式input2 = tf.placeholder(tf.float32)output = tf.mul(input1,input2) # 乘法运算with tf.Session() as sess: print sess.run(output,feed_dict=&#123;input1:7.,input2:2.&#125;) # placeholder 与 feed_dict=&#123;&#125; 是绑定在一起出现的 三、定义一个神经网络1、添加层函数add_layer()12345678910&apos;&apos;&apos;参数：输入数据，前一层size，当前层size，激活函数&apos;&apos;&apos;def add_layer(inputs,in_size,out_size,activation_function=None): Weights = tf.Variable(tf.random_normal([in_size,out_size])) #随机初始化权重 biases = tf.Variable(tf.zeros([1,out_size]) + 0.1) # 初始化偏置，+0.1 Ws_plus_b = tf.matmul(inputs,Weights) + biases # 未使用激活函数的值 if activation_function is None: outputs = Ws_plus_b else: outputs = activation_function(Ws_plus_b) # 使用激活函数激活 return outputs 2、构建神经网络 定义二次函数 123x_data = np.linspace(-1,1,300,dtype=np.float32)[:,np.newaxis]noise = np.random.normal(0,0.05,x_data.shape).astype(np.float32)y_data = np.square(x_data)-0.5+noise 定义Placeholder,用于后期输入数据 12xs = tf.placeholder(tf.float32,[None,1]) # None代表无论输入有多少都可以,只有一个特征，所以这里是1ys = tf.placeholder(tf.float32,[None,1]) 定义神经层layer 1layer1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu) # 第一层，输入层为1，隐含层为10个神经元，Tensorflow 自带的激励函数tf.nn.relu 定义输出层 1prediction = add_layer(layer1, 10, 1) # 利用上一层作为输入 计算loss损失 1loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices=[1])) # 对二者差的平方求和再取平均 梯度下降最小化损失 1train = tf.train.GradientDescentOptimizer(0.1).minimize(loss) 初始化所有变量 1init = tf.initialize_all_variables() 定义Session 12sess = tf.Session()sess.run(init) 输出 1234for i in range(1000): sess.run(train,feed_dict=&#123;xs:x_data,ys:y_data&#125;) if i%50==0: print sess.run(loss,feed_dict=&#123;xs:x_data,ys:y_data&#125;) 结果：12345678910111213141516171819200.454020.01453640.007213180.00642150.006144930.005993070.005875780.005770390.005671720.005580080.005495460.005415950.005340590.005261390.005188730.005114030.005040630.00496130.00488740.004819 3、可视化结果 显示数据12345fig = plt.figure()ax = fig.add_subplot(111)ax.scatter(x_data,y_data)plt.ion() # 绘画之后不暂停plt.show() 动态绘画123456789101112131415 try: ax.lines.remove(lines[0]) # 每次绘画需要移除上次绘画的结果，放在try catch里因为第一次执行没有，所以直接pass except Exception: pass prediction_value = sess.run(prediction, feed_dict=&#123;xs: x_data&#125;) # plot the prediction lines = ax.plot(x_data, prediction_value, &apos;r-&apos;, lw=3) # 绘画 plt.pause(0.1) # 停0.1s``` ![enter description here][3]## 四、TensorFlow可视化### 1、TensorFlow的可视化工具`tensorboard`，可视化神经网路额结构- 输入`input` with tf.name_scope(‘input’): xs = tf.placeholder(tf.float32,[None,1],name=’x_in’) # ys = tf.placeholder(tf.float32,[None,1],name=’y_in’)123![enter description here][4]- `layer`层 def add_layer(inputs,in_size,out_size,activation_function=None): with tf.name_scope(‘layer’): with tf.name_scope(‘Weights’): Weights = tf.Variable(tf.random_normal([in_size,out_size]),name=’W’) with tf.name_scope(‘biases’): biases = tf.Variable(tf.zeros([1,out_size]) + 0.1,name=’b’) with tf.name_scope(‘Ws_plus_b’): Ws_plus_b = tf.matmul(inputs,Weights) + biases if activation_function is None: outputs = Ws_plus_b else: outputs = activation_function(Ws_plus_b) return outputs123![enter description here][5]- `loss`和`train` with tf.name_scope(‘loss’): loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices=1)) with tf.name_scope(‘train’): train = tf.train.GradientDescentOptimizer(0.1).minimize(loss)123![enter description here][6]- 写入文件中 writer = tf.train.SummaryWriter(“logs/“, sess.graph)12345678- 浏览器中查看（chrome浏览器） - 在终端输入：`tensorboard --logdir=&apos;logs/&apos;`，它会给出访问地址 - 浏览器中查看即可。 - `tensorboard`命令在安装**python**目录的**bin**目录下，可以创建一个软连接### 2、可视化训练过程- 可视化Weights权重和biases偏置 - 每一层起个名字 layer_name = ‘layer%s’%n_layer 1- tf.histogram_summary(name,value) def add_layer(inputs,in_size,out_size,n_layer,activation_function=None): layer_name = ‘layer%s’%n_layer with tf.name_scope(layer_name): with tf.name_scope(‘Weights’): Weights = tf.Variable(tf.random_normal([in_size,out_size]),name=’W’) tf.histogram_summary(layer_name+’/weights’, Weights) with tf.name_scope(‘biases’): biases = tf.Variable(tf.zeros([1,out_size]) + 0.1,name=’b’) tf.histogram_summary(layer_name+’/biases’,biases) with tf.name_scope(‘Ws_plus_b’): Ws_plus_b = tf.matmul(inputs,Weights) + biases if activation_function is None: outputs = Ws_plus_b else: outputs = activation_function(Ws_plus_b) tf.histogram_summary(layer_name+&apos;/outputs&apos;,outputs) return outputs 1- merge所有的summary merged =tf.merge_all_summaries() 1- 写入文件中 writer = tf.train.SummaryWriter(“logs/“, sess.graph) 1- 训练1000次，每50步显示一次： for i in range(1000): sess.run(train,feed_dict={xs:x_data,ys:y_data}) if i%50==0: summary = sess.run(merged, feed_dict={xs: x_data, ys:y_data}) writer.add_summary(summary, i) 12345678910111213141516 - 同样适用`tensorboard`查看 ![enter description here][7] - 可视化损失函数（代价函数） - 添加：`tf.scalar_summary(&apos;loss&apos;,loss)` ![enter description here][8]## 五、手写数字识别_1### 1、说明- [全部代码](https://github.com/lawlite19/MachineLearning_TensorFlow/blob/master/Mnist_01/mnist.py)：`https://github.com/lawlite19/MachineLearning_TensorFlow/blob/master/Mnist_02/mnist.py`- 自己的数据集，没有使用tensorflow中mnist数据集，- 之前在机器学习中用Python实现过，地址：`https://github.com/lawlite19/MachineLearning_Python`,这里使用`tensorflow`实现- 神经网络只有两层### 2、代码实现- 添加一层 ‘’’添加一层神经网络’’’def add_layer(inputs,in_size,out_size,activation_function=None): Weights = tf.Variable(tf.random_normal([in_size,out_size])) # 权重，in*out biases = tf.Variable(tf.zeros([1,out_size]) + 0.1) Ws_plus_b = tf.matmul(inputs,Weights) + biases # 计算权重和偏置之后的值 if activation_function is None: outputs = Ws_plus_b else: outputs = activation_function(Ws_plus_b) # 调用激励函数运算 return outputs1- 运行函数 ‘’’运行函数’’’def NeuralNetwork(): data_digits = spio.loadmat(‘data_digits.mat’) X = data_digits[‘X’] y = data_digits[‘y’] m,n = X.shape class_y = np.zeros((m,10)) # y是0,1,2,3…9,需要映射0/1形式 for i in range(10): class_y[:,i] = np.float32(y==i).reshape(1,-1) xs = tf.placeholder(tf.float32, shape=[None,400]) # 像素是20x20=400，所以有400个feature ys = tf.placeholder(tf.float32, shape=[None,10]) # 输出有10个 prediction = add_layer(xs, 400, 10, activation_function=tf.nn.softmax) # 两层神经网络，400x10 #prediction = add_layer(layer1, 25, 10, activation_function=tf.nn.softmax) #loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices=[1])) loss = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction),reduction_indices=[1])) # 定义损失函数（代价函数）， train = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(loss) # 使用梯度下降最小化损失 init = tf.initialize_all_variables() # 初始化所有变量 sess = tf.Session() # 创建Session sess.run(init) for i in range(4000): # 迭代训练4000次 sess.run(train, feed_dict={xs:X,ys:class_y}) # 训练train，填入数据 if i%50==0: # 每50次输出当前的准确度 print(compute_accuracy(xs,ys,X,class_y,sess,prediction)) 12- 计算准确度 ‘’’计算预测准确度’’’def compute_accuracy(xs,ys,X,y,sess,prediction): y_pre = sess.run(prediction,feed_dict={xs:X}) correct_prediction = tf.equal(tf.argmax(y_pre,1),tf.argmax(y,1)) #tf.argmax 给出某个tensor对象在某一维上的其数据最大值所在的索引值,即为对应的数字，tf.equal 来检测我们的预测是否真实标签匹配 accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) # 平均值即为准确度 result = sess.run(accuracy,feed_dict={xs:X,ys:y}) return result1234567891011- 输出每一次预测的结果准确度 ![enter description here][9]## 六、手写数字识别_2### 1、说明- [全部代码](https://github.com/lawlite19/MachineLearning_TensorFlow/blob/master/Mnist_02/mnist.py)：`https://github.com/lawlite19/MachineLearning_TensorFlow/blob/master/Mnist_02/mnist.py`- 采用TensorFlow中的mnist数据集（可以取网站下载它的数据集，http://yann.lecun.com/exdb/mnist/）- 实现代码与上面类似，它有专门的测试集### 2、代码- 随机梯度下降`SGD`,每次选出`100`个数据进行训练 for i in range(2000): batch_xs, batch_ys = minist.train.next_batch(100) sess.run(train_step,feed_dict={xs:batch_xs,ys:batch_ys}) if i%50==0: print(compute_accuracy(xs,ys,minist.test.images, minist.test.labels,sess,prediction)) 1234567891011121314- 输出每一次预测的结果准确度 ![enter description here][10]## 七、手写数字识别_3_CNN卷积神经网络### 1、说明- 关于**卷积神经网络CNN**可以查看[我的博客](http://blog.csdn.net/u013082989/article/details/53673602)：http://blog.csdn.net/u013082989/article/details/53673602 - 或者[github](https://github.com/lawlite19/DeepLearning_Python)：https://github.com/lawlite19/DeepLearning_Python- [全部代码](https://github.com/lawlite19/MachineLearning_TensorFlow/blob/master/Mnist_03_CNN/mnist_cnn.py)：`https://github.com/lawlite19/MachineLearning_TensorFlow/blob/master/Mnist_03_CNN/mnist_cnn.py`- 采用TensorFlow中的mnist数据集（可以取网站下载它的数据集，http://yann.lecun.com/exdb/mnist/）### 2、代码实现- 权重和偏置初始化函数 - 权重使用的`truncated_normal`进行初始化,`stddev`标准差定义为0.1 - 偏置初始化为常量0.1 ‘’’权重初始化函数’’’def weight_variable(shape): inital = tf.truncated_normal(shape, stddev=0.1) # 使用truncated_normal进行初始化 return tf.Variable(inital) ‘’’偏置初始化函数’’’def bias_variable(shape): inital = tf.constant(0.1,shape=shape) # 偏置定义为常量 return tf.Variable(inital)1234- 卷积函数 - `strides[0]`和`strides[3]`的两个1是默认值，中间两个1代表padding时在x方向运动1步，y方向运动1步 - `padding=&apos;SAME&apos;`代表经过卷积之后的输出图像和原图像大小一样 ‘’’卷积函数’’’def conv2d(x,W):#x是图片的所有参数，W是此卷积层的权重 return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=’SAME’)#strides[0]和strides3的两个1是默认值，中间两个1代表padding时在x方向运动1步，y方向运动1步12345- 池化函数 - `ksize`指定池化核函数的大小 - 根据池化核函数的大小定义`strides`的大小 ‘’’池化函数’’’def max_pool_2x2(x): return tf.nn.max_pool(x,ksize=[1,2,2,1], strides=[1,2,2,1], padding=’SAME’)#池化的核函数大小为2x2，因此ksize=[1,2,2,1]，步长为2，因此strides=[1,2,2,1]1234- 加载`mnist`数据和定义`placeholder` - 输入数据`x_image`最后一个`1`代表`channel`的数量,若是`RGB`3个颜色通道就定义为3 - `keep_prob` 用于**dropout**防止过拟合 mnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True) # 下载数据 xs = tf.placeholder(tf.float32,[None,784]) # 输入图片的大小，28x28=784 ys = tf.placeholder(tf.float32,[None,10]) # 输出0-9共10个数字 keep_prob = tf.placeholder(tf.float32) # 用于接收dropout操作的值，dropout为了防止过拟合 x_image = tf.reshape(xs,[-1,28,28,1]) #-1代表先不考虑输入的图片例子多少这个维度，后面的1是channel的数量，因为我们输入的图片是黑白的，因此channel是1，例如如果是RGB图像，那么channel就是3 123- 第一层卷积和池化 - 使用**ReLu**激活函数 &apos;&apos;&apos;第一层卷积，池化&apos;&apos;&apos; W_conv1 = weight_variable([5,5,1,32]) # 卷积核定义为5x5,1是输入的通道数目，32是输出的通道数目 b_conv1 = bias_variable([32]) # 每个输出通道对应一个偏置 h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1) # 卷积运算，并使用ReLu激活函数激活 h_pool1 = max_pool_2x2(h_conv1) # pooling操作 123- 第二层卷积和池化 &apos;&apos;&apos;第二层卷积，池化&apos;&apos;&apos; W_conv2 = weight_variable([5,5,32,64]) # 卷积核还是5x5,32个输入通道，64个输出通道 b_conv2 = bias_variable([64]) # 与输出通道一致 h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2)+b_conv2) h_pool2 = max_pool_2x2(h_conv2) 123- 全连接第一层 &apos;&apos;&apos;全连接层&apos;&apos;&apos; h_pool2_flat = tf.reshape(h_pool2, [-1,7*7*64]) # 将最后操作的数据展开 W_fc1 = weight_variable([7*7*64,1024]) # 下面就是定义一般神经网络的操作了，继续扩大为1024 b_fc1 = bias_variable([1024]) # 对应的偏置 h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1) # 运算、激活（这里不是卷积运算了，就是对应相乘） 123- `dropout`防止过拟合 &apos;&apos;&apos;dropout&apos;&apos;&apos; h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob) # dropout操作 1234- 最后一层全连接预测,使用梯度下降优化**交叉熵损失函数** - 使用**softmax**分类器分类 &apos;&apos;&apos;最后一层全连接&apos;&apos;&apos; W_fc2 = weight_variable([1024,10]) # 最后一层权重初始化 b_fc2 = bias_variable([10]) # 对应偏置 prediction = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2) # 使用softmax分类器 cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction),reduction_indices=[1])) # 交叉熵损失函数来定义cost function train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy) # 调用梯度下降 123- 定义Session，使用`SGD`训练 &apos;&apos;&apos;下面就是tf的一般操作，定义Session，初始化所有变量，placeholder传入值训练&apos;&apos;&apos; sess = tf.Session() sess.run(tf.initialize_all_variables()) for i in range(1000): batch_xs, batch_ys = mnist.train.next_batch(100) # 使用SGD，每次选取100个数据训练 sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5}) # dropout值定义为0.5 if i % 50 == 0: print compute_accuracy(xs,ys,mnist.test.images, mnist.test.labels,keep_prob,sess,prediction) # 每50次输出一下准确度 12- 计算准确度函数 - 和上面的两个计算准确度的函数一致，就是多了个**dropout**的参数`keep_prob` ‘’’计算准确度函数’’’def compute_accuracy(xs,ys,X,y,keep_prob,sess,prediction): y_pre = sess.run(prediction,feed_dict={xs:X,keep_prob:1.0}) # 预测，这里的keep_prob是dropout时用的，防止过拟合 correct_prediction = tf.equal(tf.argmax(y_pre,1),tf.argmax(y,1)) #tf.argmax 给出某个tensor对象在某一维上的其数据最大值所在的索引值,即为对应的数字，tf.equal 来检测我们的预测是否真实标签匹配 accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) # 平均值即为准确度 result = sess.run(accuracy,feed_dict={xs:X,ys:y,keep_prob:1.0}) return result12345678910111213### 3、运行结果- 测试集上准确度 ![enter description here][11] - 使用`top`命令查看占用的CPU和内存，还是很消耗CPU和内存的，所以上面只输出了四次我就终止了![enter description here][12] - 由于我在虚拟机里运行的`TensorFlow`程序，分配了`5G`的内存，若是内存不够会报一个错误。-------------------------------------------------------------## 八、保存和提取神经网络### 1、保存- 定义要保存的数据 W = tf.Variable(initial_value=[[1,2,3],[3,4,5]], name=’weights’, dtype=tf.float32) # 注意需要指定name和dtypeb = tf.Variable(initial_value=[1,2,3], name=’biases’, dtype=tf.float32)init = tf.initialize_all_variables()1- 保存 saver = tf.train.Saver()with tf.Session() as sess: sess.run(init) save_path = saver.save(sess, ‘my_network/save_net.ckpt’) # 保存目录，注意要在当前项目下建立my_network的目录 print (‘保存到 :’,save_path)12### 2、提取- 定义数据 W = tf.Variable(np.arange(6).reshape((2,3)), name=’weights’, dtype=tf.float32) # 注意与之前保存的一致b = tf.Variable(np.arange((3)), name=’biases’, dtype=tf.float32)1- `restore`提取 saver = tf.train.Saver()with tf.Session() as sess: saver.restore(sess,’my_network/save_net.ckpt’) print(‘weights:’,sess.run(W)) # 输出一下结果 print(‘biases:’,sess.run(b))12345678910111213141516171819202122-------------------------------------------------- 以下来自`tensorflow-turorial`，使用`python3.5`## 九、线性模型Linear Model- [全部代码][13]- 使用`MNIST`数据集### 1、加载MNIST数据集，并输出信息``` stylus&apos;&apos;&apos;Load MNIST data and print some information&apos;&apos;&apos;data = input_data.read_data_sets(&quot;MNIST_data&quot;, one_hot = True)print(&quot;Size of:&quot;)print(&quot;\\t training-set:\\t\\t&#123;&#125;&quot;.format(len(data.train.labels)))print(&quot;\\t test-set:\\t\\t\\t&#123;&#125;&quot;.format(len(data.test.labels)))print(&quot;\\t validation-set:\\t&#123;&#125;&quot;.format(len(data.validation.labels)))print(data.test.labels[0:5])data.test.cls = np.array([label.argmax() for label in data.test.labels]) # get the actual valueprint(data.test.cls[0:5]) 2、绘制9张图像 实现函数 1234567891011121314151617181920'''define a funciton to plot 9 images'''def plot_images(images, cls_true, cls_pred = None): ''' @parameter images: the images info @parameter cls_true: the true value of image @parameter cls_pred: the prediction value, default is None ''' assert len(images) == len(cls_true) == 9 # only show 9 images fig, axes = plt.subplots(nrows=3, ncols=3) for i, ax in enumerate(axes.flat): ax.imshow(images[i].reshape(img_shape), cmap=\"binary\") # binary means black_white image # show the true and pred values if cls_pred is None: xlabel = \"True: &#123;0&#125;\".format(cls_true[i]) else: xlabel = \"True: &#123;0&#125;,Pred: &#123;1&#125;\".format(cls_true[i],cls_pred[i]) ax.set_xlabel(xlabel) ax.set_xticks([]) # remove the ticks ax.set_yticks([]) plt.show() 选择测试集中的9张图显示 1234567891011121314'''show 9 images'''images = data.test.images[0:9]cls_true = data.test.cls[0:9]plot_images(images, cls_true)``` ![enter description here][14]### 3、定义要训练的模型- 定义`placeholder```` stylus'''define the placeholder'''X = tf.placeholder(tf.float32, [None, img_size_flat]) # None means the arbitrary number of labels, the features size is img_size_flat y_true = tf.placeholder(tf.float32, [None, num_classes]) # output size is num_classesy_true_cls = tf.placeholder(tf.int64, [None]) 定义weights和biases 123'''define weights and biases'''weights = tf.Variable(tf.zeros([img_size_flat, num_classes])) # img_size_flat*num_classesbiases = tf.Variable(tf.zeros([num_classes])) 定义模型 123456789'''define the model'''logits = tf.matmul(X,weights) + biases y_pred = tf.nn.softmax(logits)y_pred_cls = tf.argmax(y_pred, dimension=1)cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)cost = tf.reduce_mean(cross_entropy)'''define the optimizer'''optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost) 定义求准确度 123'''define the accuracy'''correct_prediction = tf.equal(y_pred_cls, y_true_cls)accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) 定义session 1234'''run the datagraph and use batch gradient descent'''session = tf.Session()session.run(tf.global_variables_initializer())batch_size = 100 4、定义函数optimize进行bgd训练123456789'''define a function to run the optimizer'''def optimize(num_iterations): ''' @parameter num_iterations: the traning times ''' for i in range(num_iterations): x_batch, y_true_batch = data.train.next_batch(batch_size) feed_dict_train = &#123;X: x_batch,y_true: y_true_batch&#125; session.run(optimizer, feed_dict=feed_dict_train) 5、定义输出准确度的函数 代码 1234567feed_dict_test = &#123;X: data.test.images, y_true: data.test.labels, y_true_cls: data.test.cls&#125; '''define a function to print the accuracy''' def print_accuracy(): acc = session.run(accuracy, feed_dict=feed_dict_test) print(\"Accuracy on test-set:&#123;0:.1%&#125;\".format(acc)) 输出：Accuracy on test-set:89.4% 6、定义绘制错误预测的图片函数 代码 12345678'''define a function to plot the error prediciton''' def plot_example_errors(): correct, cls_pred = session.run([correct_prediction, y_pred_cls], feed_dict=feed_dict_test) incorrect = (correct == False) images = data.test.images[incorrect] # get the prediction error images cls_pred = cls_pred[incorrect] # get prediction value cls_true = data.test.cls[incorrect] # get true value plot_images(images[0:9], cls_true[0:9], cls_pred[0:9]) 输出： 7、定义可视化权重的函数 代码 123456789101112131415'''define a fucntion to plot weights'''def plot_weights(): w = session.run(weights) w_min = np.min(w) w_max = np.max(w) fig, axes = plt.subplots(3, 4) fig.subplots_adjust(0.3, 0.3) for i, ax in enumerate(axes.flat): if i&lt;10: image = w[:,i].reshape(img_shape) ax.set_xlabel(\"Weights: &#123;0&#125;\".format(i)) ax.imshow(image, vmin=w_min,vmax=w_max,cmap=\"seismic\") ax.set_xticks([]) ax.set_yticks([]) plt.show() 输出： 8、定义输出confusion_matrix的函数 代码： 12345678910111213141516'''define a function to printand plot the confusion matrix using scikit-learn.''' def print_confusion_martix(): cls_true = data.test.cls # test set actual value cls_pred = session.run(y_pred_cls, feed_dict=feed_dict_test) # test set predict value cm = confusion_matrix(y_true=cls_true,y_pred=cls_pred) # use sklearn confusion_matrix print(cm) plt.imshow(cm, interpolation='nearest',cmap=plt.cm.Blues) # Plot the confusion matrix as an image. plt.tight_layout() plt.colorbar() tick_marks = np.arange(num_classes) tick_marks = np.arange(num_classes) plt.xticks(tick_marks, range(num_classes)) plt.yticks(tick_marks, range(num_classes)) plt.xlabel('Predicted') plt.ylabel('True') plt.show() 输出： 十：CNN 全部代码 使用MNIST数据集 加载数据，绘制9张图等函数与上面一致，readme中不再写出 1、定义CNN所需要的变量123456'''define cnn description'''filter_size1 = 5 # the first conv filter size is 5x5 num_filters1 = 32 # there are 32 filtersfilter_size2 = 5 # the second conv filter sizenum_filters2 = 64 # there are 64 filtersfc_size = 1024 # fully-connected layer 2、初始化weights和biases的函数123456789101112'''define a function to intialize weights'''def initialize_weights(shape): ''' @param shape：the shape of weights ''' return tf.Variable(tf.truncated_normal(shape=shape, stddev=0.1))'''define a function to intialize biases'''def initialize_biases(length): ''' @param length: the length of biases, which is a vector ''' return tf.Variable(tf.constant(0.1,shape=[length])) 3、定义卷积操作和池化（如果使用的话）的函数12345678910111213141516171819202122232425'''define a function to do conv and pooling if used'''def conv_layer(input, num_input_channels, filter_size, num_output_filters, use_pooling=True): ''' @param input: the input of previous layer's output @param num_input_channels: input channels @param filter_size: the weights filter size @param num_output_filters: the output number channels @param use_pooling: if use pooling operation ''' shape = [filter_size, filter_size, num_input_channels, num_output_filters] weights = initialize_weights(shape=shape) biases = initialize_biases(length=num_output_filters) # one for each filter layer = tf.nn.conv2d(input=input, filter=weights, strides=[1,1,1,1], padding='SAME') layer += biases if use_pooling: layer = tf.nn.max_pool(value=layer, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\") # the kernel function size is 2x2,so the ksize=[1,2,2,1] layer = tf.nn.relu(layer) return layer, weights 4、定义将卷积层展开的函数123456789'''define a function to flat conv layer'''def flatten_layer(layer): ''' @param layer: the conv layer ''' layer_shape = layer.get_shape() # get the shape of the layer(layer_shape == [num_images, img_height, img_width, num_channels]) num_features = layer_shape[1:4].num_elements() # [1:4] means the last three demension, namely the flatten size layer_flat = tf.reshape(layer, [-1, num_features]) # reshape to flat,-1 means don't care about the number of images return layer_flat, num_features 5、定义全连接层的函数1234567891011121314'''define a function to do fully-connected'''def fc_layer(input, num_inputs, num_outputs, use_relu=True): ''' @param input: the input @param num_inputs: the input size @param num_outputs: the output size @param use_relu: if use relu activation function ''' weights = initialize_weights(shape=[num_inputs, num_outputs]) biases = initialize_biases(num_outputs) layer = tf.matmul(input, weights) + biases if use_relu: layer = tf.nn.relu(layer) return layer 6、定义模型 定义placeholder 123456'''define the placeholder'''X = tf.placeholder(tf.float32, shape=[None, img_flat_size], name=\"X\")X_image = tf.reshape(X, shape=[-1, img_size, img_size, num_channels]) # reshape to the image shapey_true = tf.placeholder(tf.float32, [None, num_classes], name=\"y_true\")y_true_cls = tf.argmax(y_true, axis=1)keep_prob = tf.placeholder(tf.float32) # drop out placeholder 定义卷积、dropout、和全连接 123456789101112131415161718192021222324'''define the cnn model'''layer_conv1, weights_conv1 = conv_layer(input=X_image, num_input_channels=num_channels, filter_size=filter_size1, num_output_filters=num_filters1, use_pooling=True)print(\"conv1:\",layer_conv1)layer_conv2, weights_conv2 = conv_layer(input=layer_conv1, num_input_channels=num_filters1, filter_size=filter_size2, num_output_filters=num_filters2, use_pooling=True)print(\"conv2:\",layer_conv2)layer_flat, num_features = flatten_layer(layer_conv2) # the num_feature is 7x7x36=1764print(\"flatten layer:\", layer_flat) layer_fc1 = fc_layer(layer_flat, num_features, fc_size, use_relu=True)print(\"fully-connected layer1:\", layer_fc1)layer_drop_out = tf.nn.dropout(layer_fc1, keep_prob) # dropout operationlayer_fc2 = fc_layer(layer_drop_out, fc_size, num_classes,use_relu=False)print(\"fully-connected layer2:\", layer_fc2)y_pred = tf.nn.softmax(layer_fc2)y_pred_cls = tf.argmax(y_pred, axis=1)cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=layer_fc2)cost = tf.reduce_mean(cross_entropy)optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost) # use AdamOptimizer优化 定义求准确度 123'''define accuracy'''correct_prediction = tf.equal(y_true_cls, y_pred_cls)accuracy = tf.reduce_mean(tf.cast(correct_prediction,dtype=tf.float32)) 7、定义训练的函数optimize，使用bgd 代码： 1234567891011121314151617181920'''define a function to run train the model with bgd'''total_iterations = 0 # record the total iterationsdef optimize(num_iterations): ''' @param num_iterations: the total interations of train batch_size operation ''' global total_iterations start_time = time.time() for i in range(total_iterations,total_iterations + num_iterations): x_batch, y_batch = data.train.next_batch(batch_size) feed_dict = &#123;X: x_batch, y_true: y_batch, keep_prob: 0.5&#125; session.run(optimizer, feed_dict=feed_dict) if i % 10 == 0: acc = session.run(accuracy, feed_dict=feed_dict) msg = \"Optimization Iteration: &#123;0:&gt;6&#125;, Training Accuracy: &#123;1:&gt;6.1%&#125;\" # &#123;:&gt;6&#125;means the fixed width,&#123;1:&gt;6.1%&#125;means the fixed width is 6 and keep 1 decimal place print(msg.format(i + 1, acc)) total_iterations += num_iterations end_time = time.time() time_dif = end_time-start_time print(\"time usage:\"+str(timedelta(seconds=int(round(time_dif))))) 输出： 123456789101112131415161718192021222324252627282930313233343536Optimization Iteration: 651, Training Accuracy: 99.0%Optimization Iteration: 661, Training Accuracy: 99.0%Optimization Iteration: 671, Training Accuracy: 99.0%Optimization Iteration: 681, Training Accuracy: 99.0%Optimization Iteration: 691, Training Accuracy: 99.0%Optimization Iteration: 701, Training Accuracy: 99.0%Optimization Iteration: 711, Training Accuracy: 99.0%Optimization Iteration: 721, Training Accuracy: 99.0%Optimization Iteration: 731, Training Accuracy: 99.0%Optimization Iteration: 741, Training Accuracy: 100.0%Optimization Iteration: 751, Training Accuracy: 99.0%Optimization Iteration: 761, Training Accuracy: 99.0%Optimization Iteration: 771, Training Accuracy: 97.0%Optimization Iteration: 781, Training Accuracy: 96.0%Optimization Iteration: 791, Training Accuracy: 98.0%Optimization Iteration: 801, Training Accuracy: 100.0%Optimization Iteration: 811, Training Accuracy: 100.0%Optimization Iteration: 821, Training Accuracy: 97.0%Optimization Iteration: 831, Training Accuracy: 98.0%Optimization Iteration: 841, Training Accuracy: 99.0%Optimization Iteration: 851, Training Accuracy: 99.0%Optimization Iteration: 861, Training Accuracy: 99.0%Optimization Iteration: 871, Training Accuracy: 96.0%Optimization Iteration: 881, Training Accuracy: 99.0%Optimization Iteration: 891, Training Accuracy: 99.0%Optimization Iteration: 901, Training Accuracy: 98.0%Optimization Iteration: 911, Training Accuracy: 99.0%Optimization Iteration: 921, Training Accuracy: 99.0%Optimization Iteration: 931, Training Accuracy: 99.0%Optimization Iteration: 941, Training Accuracy: 98.0%Optimization Iteration: 951, Training Accuracy: 100.0%Optimization Iteration: 961, Training Accuracy: 99.0%Optimization Iteration: 971, Training Accuracy: 98.0%Optimization Iteration: 981, Training Accuracy: 99.0%Optimization Iteration: 991, Training Accuracy: 100.0%time usage:0:07:07 8、定义批量预测的函数，方便输出训练错的图像123456789101112131415161718192021222324252627batch_size_test = 256def print_test_accuracy(print_error=False,print_confusion_matrix=False): ''' @param print_error: whether plot the error images @param print_confusion_matrix: whether plot the confusion_matrix ''' num_test = len(data.test.images) cls_pred = np.zeros(shape=num_test, dtype=np.int) # declare the cls_pred i = 0 #predict the test set using batch_size while i &lt; num_test: j = min(i + batch_size_test, num_test) images = data.test.images[i:j,:] labels = data.test.labels[i:j,:] feed_dict = &#123;X:images,y_true:labels,keep_prob:0.5&#125; cls_pred[i:j] = session.run(y_pred_cls,feed_dict=feed_dict) i = j cls_true = data.test.cls correct = (cls_true == cls_pred) correct_sum = correct.sum() # correct predictions acc = float(correct_sum)/num_test msg = \"Accuracy on Test-Set: &#123;0:.1%&#125; (&#123;1&#125; / &#123;2&#125;)\" print(msg.format(acc, correct_sum, num_test)) if print_error: plot_error_pred(cls_pred,correct) if print_confusion_matrix: plot_confusin_martrix(cls_pred) 9、定义可视化卷积核权重的函数 代码： 12345678910111213141516171819'''define a function to plot conv weights'''def plot_conv_weights(weights,input_channel=0): ''' @param weights: the conv filter weights, for example: the weights_conv1 and weights_conv2, which are 4 dimension [filter_size, filter_size, num_input_channels, num_output_filters] @param input_channel: the input_channels ''' w = session.run(weights) w_min = np.min(w) w_max = np.max(w) num_filters = w.shape[3] # get the number of filters num_grids = math.ceil(math.sqrt(num_filters)) fig, axes = plt.subplots(num_grids, num_grids) for i, ax in enumerate(axes.flat): if i &lt; num_filters: img = w[:,:,input_channel,i] # the ith weight ax.imshow(img,vmin=w_min,vmax=w_max,interpolation=\"nearest\",cmap='seismic') ax.set_xticks([]) ax.set_yticks([]) plt.show() 输出： 第一层： 第二层：10、定义可视化卷积层输出的函数 代码： 123456789101112131415161718'''define a function to plot conv output layer'''def plot_conv_layer(layer, image): ''' @param layer: the conv layer, which is also a image after conv @param image: the image info ''' feed_dict = &#123;X:[image]&#125; values = session.run(layer, feed_dict=feed_dict) num_filters = values.shape[3] # get the number of filters num_grids = math.ceil(math.sqrt(num_filters)) fig, axes = plt.subplots(num_grids,num_grids) for i, ax in enumerate(axes.flat): if i &lt; num_filters: img = values[0,:,:,i] ax.imshow(img, interpolation=\"nearest\",cmap=\"binary\") ax.set_xticks([]) ax.set_yticks([]) plt.show() 输出： 第一层： 第二层： 十一：使用prettytensor实现CNNModel 全部代码 使用MNIST数据集 加载数据，绘制9张图等函数与九一致，readme中不再写出1、定义模型 定义placeholder,与之前的一致 12345'''declare the placeholder'''X = tf.placeholder(tf.float32, [None, img_flat_size], name=\"X\")X_img = tf.reshape(X, shape=[-1,img_size,img_size, num_channels])y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name=\"y_true\")y_true_cls = tf.argmax(y_true,1) 使用prettytensor实现CNN模型 1234567891011'''define the cnn model with prettytensor'''x_pretty = pt.wrap(X_img)with pt.defaults_scope(): # or pt.defaults_scope(activation_fn=tf.nn.relu) if just use one activation function y_pred, loss = x_pretty.\\ conv2d(kernel=5, depth=16, activation_fn=tf.nn.relu, name=\"conv_layer1\").\\ max_pool(kernel=2, stride=2).\\ conv2d(kernel=5, depth=36, activation_fn=tf.nn.relu, name=\"conv_layer2\").\\ max_pool(kernel=2, stride=2).\\ flatten().\\ fully_connected(size=128, activation_fn=tf.nn.relu, name=\"fc_layer1\").\\ softmax_classifier(num_classes=num_classes, labels=y_true) 获取卷积核的权重(后续可视化) 1234567'''define a function to get weights'''def get_weights_variable(layer_name): with tf.variable_scope(layer_name, reuse=True): variable = tf.get_variable(\"weights\") return variableconv1_weights = get_weights_variable(\"conv_layer1\")conv2_weights = get_weights_variable(\"conv_layer2\") 定义optimizer训练，和之前的一样了 1234567'''define optimizer to train'''optimizer = tf.train.AdamOptimizer().minimize(loss)y_pred_cls = tf.argmax(y_pred,1)correct_prediction = tf.equal(y_pred_cls, y_true_cls)accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))session = tf.Session()session.run(tf.global_variables_initializer()) 十二：CNN,保存和加载模型，使用Early Stopping 全部代码 使用MNIST数据集 加载数据，绘制9张图等函数与九一致，readme中不再写出 CNN模型的定义和十一中的一致，readme中不再写出1、保存模型 创建saver,和保存的目录 123456'''define a Saver to save the network'''saver = tf.train.Saver()save_dir = \"checkpoints/\"if not os.path.exists(save_dir): os.makedirs(save_dir)save_path = os.path.join(save_dir, 'best_validation') 保存session,对应到下面2中的Early Stopping，将最好的模型保存 1saver.save(sess=session, save_path=save_path) 2、Early Stopping123456789101112131415161718192021222324252627282930313233343536'''declear the train info'''train_batch_size = 64best_validation_accuracy = 0.0last_improvement = 0require_improvement_iterations = 1000total_iterations = 0'''define a function to optimize the optimizer'''def optimize(num_iterations): global total_iterations global best_validation_accuracy global last_improvement start_time = time.time() for i in range(num_iterations): total_iterations += 1 X_batch, y_true_batch = data.train.next_batch(train_batch_size) feed_dict_train = &#123;X: X_batch, y_true: y_true_batch&#125; session.run(optimizer, feed_dict=feed_dict_train) if (total_iterations%100 == 0) or (i == num_iterations-1): acc_train = session.run(accuracy, feed_dict=feed_dict_train) acc_validation, _ = validation_accuracy() if acc_validation &gt; best_validation_accuracy: best_validation_accuracy = acc_validation last_improvement = total_iterations saver.save(sess=session, save_path=save_path) improved_str = \"*\" else: improved_str = \"\" msg = \"Iter: &#123;0:&gt;6&#125;, Train_batch accuracy:&#123;1:&gt;6.1%&#125;, validation acc:&#123;2:&gt;6.1%&#125; &#123;3&#125;\" print(msg.format(i+1, acc_train, acc_validation, improved_str)) if total_iterations-last_improvement &gt; require_improvement_iterations: print('No improvement found in a while, stop running') break end_time = time.time() time_diff = end_time-start_time print(\"Time usage:\" + str(timedelta(seconds=int(round(time_diff))))) 调用optimize(10000)输出信息 12345678910111213141516171819Iter: 5100, Train_batch accuracy:100.0%, validation acc: 98.8% *Iter: 5200, Train_batch accuracy:100.0%, validation acc: 98.3% Iter: 5300, Train_batch accuracy:100.0%, validation acc: 98.7% Iter: 5400, Train_batch accuracy: 98.4%, validation acc: 98.6% Iter: 5500, Train_batch accuracy: 98.4%, validation acc: 98.6% Iter: 5600, Train_batch accuracy:100.0%, validation acc: 98.7% Iter: 5700, Train_batch accuracy: 96.9%, validation acc: 98.9% *Iter: 5800, Train_batch accuracy:100.0%, validation acc: 98.6% Iter: 5900, Train_batch accuracy:100.0%, validation acc: 98.6% Iter: 6000, Train_batch accuracy: 98.4%, validation acc: 98.7% Iter: 6100, Train_batch accuracy:100.0%, validation acc: 98.7% Iter: 6200, Train_batch accuracy:100.0%, validation acc: 98.7% Iter: 6300, Train_batch accuracy: 98.4%, validation acc: 98.8% Iter: 6400, Train_batch accuracy: 98.4%, validation acc: 98.8% Iter: 6500, Train_batch accuracy:100.0%, validation acc: 98.7% Iter: 6600, Train_batch accuracy:100.0%, validation acc: 98.7% Iter: 6700, Train_batch accuracy:100.0%, validation acc: 98.8% No improvement found in a while, stop runningTime usage:0:18:43 可以看到最后10次输出（每100次输出一次）在验证集上准确度都没有提高，停止执行 3、 小批量预测并计算准确率 因为需要预测测试集和验证集，这里参数指定需要的images 1234567891011121314'''define a function to predict using batch'''batch_size_predict = 256def predict_cls(images, labels, cls_true): num_images = len(images) cls_pred = np.zeros(shape=num_images, dtype=np.int) i = 0 while i &lt; num_images: j = min(i+batch_size_predict, num_images) feed_dict = &#123;X: images[i:j,:], y_true: labels[i:j,:]&#125; cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict) i = j correct = (cls_true==cls_pred) return correct, cls_pred 测试集和验证集直接调用即可 12345def predict_cls_test(): return predict_cls(data.test.images, data.test.labels, data.test.cls)def predict_cls_validation(): return predict_cls(data.validation.images, data.validation.labels, data.validation.cls) 计算验证集准确率（上面optimize函数中需要用到） 123456789'''calculate the acc'''def cls_accuracy(correct): correct_sum = correct.sum() acc = float(correct_sum)/len(correct) return acc, correct_sum'''define a function to calculate the validation acc'''def validation_accuracy(): correct, _ = predict_cls_validation() return cls_accuracy(correct) 计算测试集准确率，并且输出错误的预测和confusion matrix 123456789101112131415161718'''define a function to calculate test acc'''def print_test_accuracy(show_example_errors=False, show_confusion_matrix=False): correct, cls_pred = predict_cls_test() acc, num_correct = cls_accuracy(correct) num_images = len(correct) msg = \"Accuracy on Test-Set: &#123;0:.1%&#125; (&#123;1&#125; / &#123;2&#125;)\" print(msg.format(acc, num_correct, num_images)) # Plot some examples of mis-classifications, if desired. if show_example_errors: print(\"Example errors:\") plot_example_errors(cls_pred=cls_pred, correct=correct) # Plot the confusion matrix, if desired. if show_confusion_matrix: print(\"Confusion Matrix:\") plot_confusion_matrix(cls_pred=cls_pred) 十二：模型融合 全部代码 使用MNIST数据集 一些方法和之前的一致，不在给出 其中训练了多个CNN 模型，然后取预测的平均值作为最后的预测结果1、将测试集和验证集合并后，并重新划分 主要是希望训练时数据集有些变换，否则都是一样的数据去训练了，最后再融合意义不大12345678910111213141516171819'''将training set和validation set合并，并重新划分'''combine_images = np.concatenate([data.train.images, data.validation.images], axis=0)combine_labels = np.concatenate([data.train.labels, data.validation.labels], axis=0)print(\"合并后图片：\", combine_images.shape)print(\"合并后label：\", combine_labels.shape)combined_size = combine_labels.shape[0]train_size = int(0.8*combined_size)validation_size = combined_size - train_size'''函数：将合并后的重新随机划分'''def random_training_set(): idx = np.random.permutation(combined_size) # 将0-combined_size数字随机排列 idx_train = idx[0:train_size] idx_validation = idx[train_size:] x_train = combine_images[idx_train, :] y_train = combine_labels[idx_train, :] x_validation = combine_images[idx_validation, :] y_validation = combine_images[idx_validation, :] return x_train, y_train, x_validation, y_validation 2、融合模型 加载训练好的模型，并输出每个模型在测试集的预测结果等 1234567891011121314151617def ensemble_predictions(): pred_labels = [] test_accuracies = [] validation_accuracies = [] for i in range(num_networks): saver.restore(sess=session, save_path=get_save_path(i)) test_acc = test_accuracy() test_accuracies.append(test_acc) validation_acc = validation_accuracy() validation_accuracies.append(validation_acc) msg = \"网络：&#123;0&#125;，验证集：&#123;1:.4f&#125;，测试集&#123;2:.4f&#125;\" print(msg.format(i, validation_acc, test_acc)) pred = predict_labels(data.test.images) pred_labels.append(pred) return np.array(pred_labels),\\ np.array(test_accuracies),\\ np.array(validation_accuracies) 调用pred_labels, test_accuracies, val_accuracies = ensemble_predictions() 取均值：ensemble_pred_labels = np.mean(pred_labels, axis=0) 融合后的真实结果：ensemble_cls_pred = np.argmax(ensemble_pred_labels, axis=1) 其他一些信息： 12345678910111213141516ensemble_correct = (ensemble_cls_pred == data.test.cls)ensemble_incorrect = np.logical_not(ensemble_correct)print(test_accuracies)best_net = np.argmax(test_accuracies)print(best_net)print(test_accuracies[best_net])best_net_pred_labels = pred_labels[best_net, :, :]best_net_cls_pred = np.argmax(best_net_pred_labels, axis=1)best_net_correct = (best_net_cls_pred == data.test.cls)best_net_incorrect = np.logical_not(best_net_correct)print(\"融合后预测对的：\", np.sum(ensemble_correct))print(\"单个最好模型预测对的\", np.sum(best_net_correct))ensemble_better = np.logical_and(best_net_incorrect, ensemble_correct) # 融合之后好于单个的个数print(ensemble_better.sum())best_net_better = np.logical_and(best_net_correct, ensemble_incorrect) # 单个好于融合之后的个数print(best_net_better.sum()) 十二：Cifar-10数据集，使用variable_scope重复使用变量 全部代码 使用CIFAR-10数据集 创建了两个网络，一个用于训练，一个用于测试，测试使用的是训练好的权重参数，所以用到参数重用 网络结构 1、数据集 导入包： 这是别人实现好的下载和处理cifar-10数据集的diamante12import cifar10from cifar10 import img_size, num_channels, num_classes 输出一些数据集信息 123456789101112'''下载cifar10数据集, 大概163M'''cifar10.maybe_download_and_extract()'''加载数据集'''images_train, cls_train, labels_train = cifar10.load_training_data()images_test, cls_test, labels_test = cifar10.load_test_data()'''打印一些信息'''class_names = cifar10.load_class_names()print(class_names)print(\"Size of:\")print(\"training set:\\t\\t&#123;&#125;\".format(len(images_train)))print(\"test set:\\t\\t\\t&#123;&#125;\".format(len(images_test))) 显示9张图片函数 相比之前的，加入了smooth 123456789101112131415161718192021'''显示9张图片函数'''def plot_images(images, cls_true, cls_pred=None, smooth=True): # smooth是否平滑显示 assert len(images) == len(cls_true) == 9 fig, axes = plt.subplots(3,3) for i, ax in enumerate(axes.flat): if smooth: interpolation = 'spline16' else: interpolation = 'nearest' ax.imshow(images[i, :, :, :], interpolation=interpolation) cls_true_name = class_names[cls_true[i]] if cls_pred is None: xlabel = \"True:&#123;0&#125;\".format(cls_true_name) else: cls_pred_name = class_names[cls_pred[i]] xlabel = \"True:&#123;0&#125;, Pred:&#123;1&#125;\".format(cls_true_name, cls_pred_name) ax.set_xlabel(xlabel) ax.set_xticks([]) ax.set_yticks([]) plt.show() 2、定义placeholder123X = tf.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name=\"X\")y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name=\"y\")y_true_cls = tf.argmax(y_true, axis=1) 3、图片处理 单张图片处理 原图是32*32像素的，裁剪成24*24像素的 如果是训练集进行一些裁剪，翻转，饱和度等处理 如果是测试集，只进行简单的裁剪处理 这也是为什么使用variable_scope定义两个网络123456789101112131415'''单个图片预处理, 测试集只需要裁剪就行了'''def pre_process_image(image, training): if training: image = tf.random_crop(image, size=[img_size_cropped, img_size_cropped, num_channels]) # 裁剪 image = tf.image.random_flip_left_right(image) # 左右翻转 image = tf.image.random_hue(image, max_delta=0.05) # 色调调整 image = tf.image.random_brightness(image, max_delta=0.2) # 曝光 image = tf.image.random_saturation(image, lower=0.0, upper=2.0) # 饱和度 '''上面的调整可能pixel值超过[0, 1], 所以约束一下''' image = tf.minimum(image, 1.0) image = tf.maximum(image, 0.0) else: image = tf.image.resize_image_with_crop_or_pad(image, target_height=img_size_cropped, target_width=img_size_cropped) return image 多张图片处理 因为训练和测试是都是使用batch的方式 调用上面处理单张图片的函数 tf.map_fn(fn, elems)函数，前面一般是lambda函数，后面是所有的数据1234'''调用上面的函数，处理多个图片images'''def pre_process(images, training): images = tf.map_fn(lambda image: pre_process_image(image, training), images) # tf.map_fn()使用lambda函数 return images 4、定义tensorflow计算图 定义主网络图 使用prettytensor 分为training和test两个阶段 123456789101112131415161718'''定义主网络函数'''def main_network(images, training): x_pretty = pt.wrap(images) if training: phase = pt.Phase.train else: phase = pt.Phase.infer with pt.defaults_scope(activation_fn=tf.nn.relu, phase=phase): y_pred, loss = x_pretty.\\ conv2d(kernel=5, depth=64, name=\"layer_conv1\", batch_normalize=True).\\ max_pool(kernel=2, stride=2).\\ conv2d(kernel=5, depth=64, name=\"layer_conv2\").\\ max_pool(kernel=2, stride=2).\\ flatten().\\ fully_connected(size=256, name=\"layer_fc1\").\\ fully_connected(size=128, name=\"layer_fc2\").\\ softmax_classifier(num_classes, labels=y_true) return y_pred, loss 创建所有网络，包含预处理图片和主网络 需要使用variable_scope, 测试阶段需要reuse训练阶段的参数12345678'''创建所有网络, 包含预处理和主网络，'''def create_network(training): # 使用variable_scope可以重复使用定义的变量，训练时创建新的，测试时重复使用 with tf.variable_scope(\"network\", reuse=not training): images = X images = pre_process(images=images, training=training) y_pred, loss = main_network(images=images, training=training) return y_pred, loss 创建训练阶段网络 定义一个global_step记录训练的次数，下面会将其保存到checkpoint,trainable为False就不会训练改变123456'''训练阶段网络创建'''global_step = tf.Variable(initial_value=0, name=\"global_step\", trainable=False) # trainable 在训练阶段不会改变_, loss = create_network(training=True)optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss, global_step) 定义测试阶段网络 同时定义准确率 12345'''测试阶段网络创建'''y_pred, _ = create_network(training=False)y_pred_cls = tf.argmax(y_pred, dimension=1)correct_prediction = tf.equal(y_pred_cls, y_true_cls)accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) 5、获取权重和每层的输出值信息 获取权重变量 123456def get_weights_variable(layer_name): with tf.variable_scope(\"network/\" + layer_name, reuse=True): variable = tf.get_variable(\"weights\") return variable weights_conv1 = get_weights_variable(\"layer_conv1\")weights_conv2 = get_weights_variable(\"layer_conv2\") 获取每层的输出变量 123456def get_layer_output(layer_name): tensor_name = \"network/\" + layer_name + \"/Relu:0\" tensor = tf.get_default_graph().get_tensor_by_name(tensor_name) return tensoroutput_conv1 = get_layer_output(\"layer_conv1\")output_conv2 = get_layer_output(\"layer_conv2\") 6、保存和加载计算图参数 因为第一次不会加载，所以放到try中判断 12345678910111213141516'''执行tensorflow graph'''session = tf.Session()save_dir = \"checkpoints/\"if not os.path.exists(save_dir): os.makedirs(save_dir)save_path = os.path.join(save_dir, 'cifat10_cnn')'''尝试存储最新的checkpoint, 可能会失败，比如第一次运行checkpoint不存在等'''try: print(\"开始存储最新的存储...\") last_chk_path = tf.train.latest_checkpoint(save_dir) saver.restore(session, save_path=last_chk_path) print(\"存储点来自：\", last_chk_path)except: print(\"存储错误, 初始化变量\") session.run(tf.global_variables_initializer()) 7、训练 获取batch 12345678'''SGD'''train_batch_size = 64def random_batch(): num_images = len(images_train) idx = np.random.choice(num_images, size=train_batch_size, replace=False) x_batch = images_train[idx, :, :, :] y_batch = labels_train[idx, :] return x_batch, y_batch 训练网络 每1000次保存一下checkpoint 因为上面会restored已经保存训练的网络，同时也保存了训练的次数，所以可以接着训练1234567891011121314151617def optimize(num_iterations): start_time = time.time() for i in range(num_iterations): x_batch, y_batch = random_batch() feed_dict_train = &#123;X: x_batch, y_true: y_batch&#125; i_global, _ = session.run([global_step, optimizer], feed_dict=feed_dict_train) if (i_global%100==0) or (i == num_iterations-1): batch_acc = session.run(accuracy, feed_dict=feed_dict_train) msg = \"global step: &#123;0:&gt;6&#125;, training batch accuracy: &#123;1:&gt;6.1%&#125;\" print(msg.format(i_global, batch_acc)) if(i_global%1000==0) or (i==num_iterations-1): saver.save(session, save_path=save_path, global_step=global_step) print(\"保存checkpoint\") end_time = time.time() time_diff = end_time-start_time print(\"耗时：\", str(timedelta(seconds=int(round(time_diff))))) 十三、Inception model (GoogleNet) 全部代码 使用训练好的inception model,因为模型很复杂，一般的电脑运行不起来的。 网络结构 1、下载和加载inception model 因为是预训练好的模型，所以无需我们定义结构了 导入包 这里 inception是别人实现好的下载的代码12345import numpy as npimport tensorflow as tffrom matplotlib import pyplot as pltimport inception # 第三方类加载inception modelimport os 下载和加载模型 123'''下载和加载inception model'''inception.maybe_download()model = inception.Inception() 预测和显示图片函数 123456'''预测和显示图片'''def classify(image_path): plt.imshow(plt.imread(image_path)) plt.show() pred = model.classify(image_path=image_path) model.print_scores(pred=pred, k=10, only_first_name=True) 显示调整后的图片 因为 inception model要求输入图片为 299*299 像素的，所以它会resize成这个大小然后作为输入 123456'''显示处理后图片的样式'''def plot_resized_image(image_path): resized_image = model.get_resized_image(image_path) plt.imshow(resized_image, interpolation='nearest') plt.show()plot_resized_image(image_path) 十四、迁移学习 Transfer Learning 全部代码 网络结构还是使用上一节的inception model, 去掉最后的全连接层，然后重新构建全连接层进行训练 因为inception model 是训练好的，前面的卷积层用于捕捉特征, 而后面的全连接层可用于分类，所以我们训练全连接层即可 因为要计算每张图片的transfer values,所以使用一个cache缓存transfer-values，第一次计算完成后，后面重新运行直接读取存储的结果，这样比较节省时间 transfer values是inception model在Softmax层前一层的值 cifar-10数据集, 我放在实验室电脑上运行了几个小时才得到transfer values，还是比较慢的 总之最后相当于训练下面的神经网络，对应的 transfer-values作为输入 1、准备工作 导入包 1234567891011import numpy as npimport tensorflow as tfimport prettytensor as ptfrom matplotlib import pyplot as pltimport timefrom datetime import timedeltaimport osimport inception # 第三方下载inception model的代码from inception import transfer_values_cache # cacheimport cifar10 # 也是第三方的库，下载cifar-10数据集from cifar10 import num_classes 下载cifar-10数据集 1234567'''下载cifar-10数据集'''cifar10.maybe_download_and_extract()class_names = cifar10.load_class_names()print(\"所有类别是：\",class_names)'''训练和测试集'''images_train, cls_train, labels_train = cifar10.load_training_data()images_test, cls_test, labels_test = cifar10.load_test_data() 下载和加载inception model 123'''下载inception model'''inception.maybe_download()model = inception.Inception() 计算cifar-10训练集和测试集在inception model上的transfer values 因为计算非常耗时，这里第一次运行存储到本地，以后再运行直接读取即可 transfer values的shape是(dataset size, 2048)，因为是softmax层的前一层12345678910111213141516'''训练和测试的cache的路径'''file_path_cache_train = os.path.join(cifar10.data_path, 'inception_cifar10_train.pkl')file_path_cache_test = os.path.join(cifar10.data_path, 'inception_cifar10_test.pkl')print('处理训练集上的transfer-values.......... ')image_scaled = images_train * 255.0 # cifar-10的pixel是0-1的, shape=(50000, 32, 32, 3)transfer_values_train = transfer_values_cache(cache_path=file_path_cache_train, images=image_scaled, model=model) # shape=(50000, 2048)print('处理测试集上的transfer-values.......... ')images_scaled = images_test * 255.0transfer_values_test = transfer_values_cache(cache_path=file_path_cache_test, model=model, images=images_scaled)print(\"transfer_values_train: \",transfer_values_train.shape)print(\"transfer_values_test: \",transfer_values_test.shape) 可视化一张图片对应的transfer values 1234567891011'''显示transfer values'''def plot_transfer_values(i): print(\"输入图片：\") plt.imshow(images_test[i], interpolation='nearest') plt.show() print('transfer values --&gt; 此图片在inception model上') img = transfer_values_test[i] img = img.reshape((32, 64)) plt.imshow(img, interpolation='nearest', cmap='Reds') plt.show()plot_transfer_values(16) 2、分析transfer values(1) 使用PCA主成分分析 将数据降到2维，可视化，因为transfer values是已经捕捉到的特征，所以可视化应该是可以隐约看到不同类别的数据是有区别的 取3000个数据观察（因为PCA也是比较耗时的） 12345678'''使用PCA分析transfer values'''from sklearn.decomposition import PCApca = PCA(n_components=2)transfer_values = transfer_values_train[0:3000] # 取3000个，大的话计算量太大cls = cls_train[0:3000]print(transfer_values.shape)transfer_values_reduced = pca.fit_transform(transfer_values)print(transfer_values_reduced.shape) 可视化降维后的数据 12345678910## 显示降维后的transfer valuesdef plot_scatter(values, cls): from matplotlib import cm as cm cmap = cm.rainbow(np.linspace(0.0, 1.0, num_classes)) colors = cmap[cls] x = values[:, 0] y = values[:, 1] plt.scatter(x, y, color=colors) plt.show()plot_scatter(transfer_values_reduced, cls) (2) 使用TSNE主成分分析 因为t-SNE运行非常慢，所以这里先用PCA将到50维 1234567from sklearn.manifold import TSNEpca = PCA(n_components=50)transfer_values_50d = pca.fit_transform(transfer_values)tsne = TSNE(n_components=2)transfer_values_reduced = tsne.fit_transform(transfer_values_50d)print(\"最终降维后：\", transfer_values_reduced.shape)plot_scatter(transfer_values_reduced, cls) 数据区分还是比较明显的 3、创建我们自己的网络 使用prettytensor创建一个全连接层，使用softmax作为分类 12345678910'''创建网络'''transfer_len = model.transfer_len # 获取transfer values的大小，这里是2048x = tf.placeholder(tf.float32, shape=[None, transfer_len], name=\"x\")y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name=\"y\")y_true_cls = tf.argmax(y_true, axis=1)x_pretty = pt.wrap(x)with pt.defaults_scope(activation_fn=tf.nn.relu): y_pred, loss = x_pretty.\\ fully_connected(1024, name=\"layer_fc1\").\\ softmax_classifier(num_classes, labels=y_true) 优化器 123'''优化器'''global_step = tf.Variable(initial_value=0, name=\"global_step\", trainable=False)optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss, global_step) 准确度 1234'''accuracy'''y_pred_cls = tf.argmax(y_pred, axis=1)correct_prediction = tf.equal(y_pred_cls, y_true_cls)accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) SGD训练 1234567891011121314151617181920212223242526'''SGD 训练'''session = tf.Session()session.run(tf.initialize_all_variables())train_batch_size = 64def random_batch(): num_images = len(images_train) idx = np.random.choice(num_images, size=train_batch_size, replace=False) x_batch = transfer_values_train[idx] y_batch = labels_train[idx] return x_batch, y_batchdef optimize(num_iterations): start_time = time.time() for i in range(num_iterations): x_batch, y_true_batch = random_batch() feed_dict_train = &#123;x: x_batch, y_true: y_true_batch&#125; i_global, _ = session.run([global_step, optimizer], feed_dict=feed_dict_train) if (i_global % 100 == 0) or (i==num_iterations-1): batch_acc = session.run(accuracy, feed_dict=feed_dict_train) msg = \"Global Step: &#123;0:&gt;6&#125;, Training Batch Accuracy: &#123;1:&gt;6.1%&#125;\" print(msg.format(i_global, batch_acc)) end_time = time.time() time_diff = end_time - start_time print(\"耗时：\", str(timedelta(seconds=int(round(time_diff))))) 使用batch size预测测试集数据 1234567891011121314'''batch 预测'''batch_size = 256def predict_cls(transfer_values, labels, cls_true): num_images = len(images_test) cls_pred = np.zeros(shape=num_images, dtype=np.int) i = 0 while i &lt; num_images: j = min(i + batch_size, num_images) feed_dict = &#123;x: transfer_values[i:j], y_true: labels[i:j]&#125; cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict) i = j correct = (cls_true == cls_pred) return correct, cls_pred","comments":true,"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://lawlite.cn/tags/DeepLearning/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://lawlite.cn/tags/Tensorflow/"}]},{"title":"Python科学计算","date":"2016-11-09T14:25:43.000Z","path":"2016/11/09/Python科学计算/","text":"一、Numpy1、Numpy特征和导入 （1）用于多维数组的第三方Python包 （2）更接近于底层和硬件 (高效) （3）专注于科学计算 (方便) （4）导入包：import numpy as np 2、list转为数组 （1）a = np.array([0,1,2,3]) （2）输出为：[0 1 2 3] （3）数据类型：&lt;type &#39;numpy.ndarray&#39;&gt; 3、一维数组 （1）a = np.array([1,2,3,4])属性a.ndim–&gt;维度为1a.shape–&gt;形状，返回(4,)len(a)–&gt;长度，4 （2）访问数组a[1:5:2]下标1-5，下标关系+2 （3）逆序 a[::-1] 4、多维数组 （1）二维：a = np.array([[0,1,2,3],[1,2,3,4]])输出为： [[0 1 2 3] [1 2 3 4]]a.ndm –&gt;2a.shape –&gt;(2,4)–&gt;行数，列数len(a) –&gt;2–&gt;第一维大小 （2）三维：a = np.array([[[0],[1]],[[2],[4]]])a.shape–&gt;(2,2,1) 5、用函数创建数组 （1）np.arange() a = np.arange(0, 10)b = np.arange(10)c = np.arange(0,10,2)输出： [0 1 2 3 4 5 6 7 8 9][0 1 2 3 4 5 6 7 8 9][0 2 4 6 8] （2）np.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)等距离产生num个数 （3）np.logspace(start, stop, num=50, endpoint=True, base=10.0, dtype=None)以log函数取 6、常用数组 （1）a = np.ones((3,3))输出： [[ 1. 1. 1.][ 1. 1. 1.][ 1. 1. 1.]] （2）np.zeros((3,3)) （3）np.eye(2)单位矩阵 （4）np.diag([1,2,3],k=0)对角矩阵，k为对角线的偏移 7、随机数矩阵 （1）a = np.random.rand(4)输出：[ 0.99890402 0.41171695 0.40725671 0.42501804]范围在[0,1]之间 （2）a = np.random.randn(4) Gaussian函数， （3）生成100个0-m的随机数: [t for t in [np.random.randint(x-x, m) for x in range(100)]] 也可以12m_arr = np.arange(0,m) # 生成0-m-1np.random.shuffle(m_arr) # 打乱m_arr顺序 然后取前100个即可 8、查看数据类型 （1）a.dtype 9、数组复制 （1）共享内存123a = np.array([1,2,3,4,5])b = aprint np.may_share_memory(a,b) 输出：True说明使用的同一个存储区域，修改一个数组同时另外的也会修改 （2）不共享内存b = a.copy() 10、布尔型 （1）1234a = np.random.random_integers(0,20,5)print aprint a%3==0print a[a % 3 == 0] 输出： [14 3 6 15 4] [False True True True False] [ 3 6 15] 11、中间数、平均值 （1）中间数np.median(a) （2）平均值np.mean(a), 若是矩阵，不指定axis默认求所有元素的均值 axis=0,求列的均值 axis=1，求行的均值 12、矩阵操作 （1）乘积np.dot(a,b)123a = np.array([[1,2,3],[2,3,4]])b = np.array([[1,2],[2,3],[2,2]])print np.dot(a,b) 或者使用np.matrix()生成矩阵，相乘需要满足矩阵相乘的条件 （2）内积np.inner(a,b)行相乘 （3）逆矩阵np.linalg.inv(a) （4）列的最大值np.max(a[:,0])–&gt;返回第一列的最大值 （5）每列的和np.sum(a,0) （6）每行的平均数np.mean(a,1) （7）求交集p.intersect1d(a,b)，返回一维数组 （8）转置：np.transpose(a) （9）两个矩阵对应对应元素相乘（点乘）：a*b 13、文件操作 （1）保存：tofile()123a = np.arange(10)a.shape=2,5a.tofile(&quot;test.bin&quot;) 读取：（需要注意指定保存的数据类型）12a = np.fromfile(&quot;test.bin&quot;,dtype=np.int32)print a （2）保存：np.save(&quot;test&quot;,a)–&gt;会保存成test.npy文件读取：a = np.load(&quot;test&quot;) 14、组合两个数组 （1）垂直组合 1234a = np.array([1,2,3])b = np.array([[1,2,3],[4,5,6]])c = np.vstack((b,a)) （2）水平组合 1234a = np.array([[1,2],[3,4]])b = np.array([[1,2,3],[4,5,6]])c = np.hstack((a,b)) 15、读声音Wave文件 （1）wave 1234567891011121314151617181920212223242526272829import wavefrom matplotlib import pyplot as pltimport numpy as np# 打开WAV文档f = wave.open(r&quot;c:\\WINDOWS\\Media\\ding.wav&quot;, &quot;rb&quot;)# 读取格式信息# (nchannels, sampwidth, framerate, nframes, comptype, compname)params = f.getparams()nchannels, sampwidth, framerate, nframes = params[:4]# 读取波形数据str_data = f.readframes(nframes)f.close()#将波形数据转换为数组wave_data = np.fromstring(str_data, dtype=np.short)wave_data.shape = -1, 2wave_data = wave_data.Ttime = np.arange(0, nframes) * (1.0 / framerate)# 绘制波形plt.subplot(211) plt.plot(time, wave_data[0])plt.subplot(212) plt.plot(time, wave_data[1], c=&quot;g&quot;)plt.xlabel(&quot;time (seconds)&quot;)plt.show() 16、where （1）找到y数组中=1的位置：np.where(y==1) 17、np.ravel(y) 将二维的转化为一维的，eg:(5000,1)--&gt;(5000,) 18、ndarray.flat函数 将数据展开对应的数组，可以进行访问 应用：0/1映射123456def dense_to_one_hot(label_dense,num_classes): num_labels = label_dense.shape[0] index_offset = np.arange(num_labels)*num_classes labels_one_hot = numpy.zeros((num_labels, num_classes)) labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1 return labels_one_hot 19、数组访问 X = np.array([[1,2],[3,4]]) X[0:1]和X[0:1,:]等价，都是系那是第一行数据 20、np.c_() 按照第二维度，即列拼接数据 np.c_[np.array([[1,2,3]]), 0, 0, np.array([[4,5,6]])]输出：array([[1, 2, 3, 0, 0, 4, 5, 6]]) 两个列表list拼接，长度要一致 np.c_[[1,2,3],[2,3,4]] np.c_[range(1,5),range(2,6)] 二、Matplotlib1、关于pyplot （1）matplotlib的pyplot子库提供了和matlab类似的绘图API，方便用户快速绘制2D图表。 （2）导入包：from matplotlib import pyplot as plt 2、绘图基础 （1）sin和cos 1234567x = np.linspace(-np.pi, np.pi,256,endpoint=True)C,S = np.cos(x),np.sin(x)plt.plot(x,C)plt.plot(x,S)plt.xlabel(&quot;x&quot;)plt.ylabel(&quot;y&quot;)plt.show() （2）指定绘图的大小 plt.figure(figsize=(8,6), dpi=80) （3）指定线的颜色、粗细和类型 plt.plot(x,C,color=”blue”,linewidth=2.0,linestyle=”-“,label=”cos”) 蓝色、宽度、连续、label（使用legend会显示这个label） （4）指定x坐标轴范围 plt.xlim(-4.0,4.0) （5）设置y抽刻度间隔plt.yticks(np.linspace(-1, 1, 15, endpoint=True)) （6）显示图例 plt.legend(loc=”upper left”) 显示在左上方 （7）一个figure上画多个图subplot方式 plt.subplot(1, 2, 1) plt.subplot(1, 2, 2) 例如：plt.subplot(m, n, p) 代表图共有的m行，n列，第p个图 p是指第几个图，横向数 上面代表有一行，两个图 [更详细解释]：231,232,233表示第一行的1,2,3个位置，接着的223表示把整个矩形分成4分，所以第3个位置就是第二行的第一个位置，但是相比第一行占了1.5列（每次subplot划分都是整个图重新划分） （8）一个figure上画多个图，axes方式 plt.axes([.1, .1, .8, .8]) plt.axes([.2, .2, .3, .3]) （9）填充 plt.fill_between(x, y1, y2=0, where=None, interpolate=False, step=None, hold=None, data=None) eg: 12plt.fill_between(X, 1, C+1, C+1&gt;1,color=&quot;red&quot;)plt.fill_between(X, 1, C+1, C+1&lt;1,color=&quot;blue&quot;) 3、散点图 （1） plt.scatter(X,Y) 4、条形图 （1） plt.bar(X, Y, facecolor=&quot;red&quot;, edgecolor=&quot;blue&quot; ) 填充颜色为facecolor,边界颜色为edgecolor 5、等高线图 （1）只显示等高线contour （2）显示表面contourf （3）注意三维图要用到meshgrid转化为网格12345678910111213def f(x,y): return (1 - x / 2 + x**5 + y**3) * np.exp(-x**2 -y**2)n = 256x = np.linspace(-3,3,n)y = np.linspace(-3,3,n)X,Y = np.meshgrid(x,y)plt.contourf(X,Y,f(X,Y),alpha=.5)C = plt.contour(X,Y,f(X, Y),colors=&quot;black&quot;,linewidth=.5)plt.clabel(C)plt.show() 6、显示图片imshow （1）123456789def f(x,y):return (1 - x / 2 + x ** 5 + y ** 3 ) * np.exp(-x ** 2 - y ** 2)n = 10x = np.linspace(-3, 3, 3.5 * n)y = np.linspace(-3, 3, 3.0 * n)X, Y = np.meshgrid(x, y)z = f(X,Y)plt.imshow(z)plt.show() 7、饼图pie （1）传入一个序列12345plt.figure(figsize=(8,8))n = 20Z = np.arange(10)plt.pie(Z)plt.show() 8、三维表面图* （1）需要导入包：from mpl_toolkits.mplot3d import Axes3D （2）1234567891011fig = plt.figure()ax = Axes3D(fig)X = np.arange(-4, 4, 0.25)Y = np.arange(-4, 4, 0.25)X, Y = np.meshgrid(X, Y)R = np.sqrt(X ** 2 + Y ** 2)Z = np.sin(R)ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=plt.cm.hot)ax.contourf(X, Y, Z, zdir=&apos;z&apos;, offset=-2, cmap=plt.cm.hot)ax.set_zlim(-2, 2)plt.show() 9、legend显示问题 （1）12345p1, = plt.plot(np.ravel(X[pos,0]),np.ravel(X[pos,1]),&apos;ro&apos;,markersize=8)p2, = plt.plot(np.ravel(X[neg,0]),np.ravel(X[neg,1]),&apos;g^&apos;,markersize=8)plt.xlabel(&quot;X1&quot;)plt.ylabel(&quot;X2&quot;)plt.legend([p1,p2],[&quot;y==1&quot;,&quot;y==0&quot;]) 注意 p1后要加上,逗号，里面的数据要是一维的，使用np.ravel()转化一下 10、显示网格 （1）plt.grid(True, linestyle = &quot;-.&quot;, color = &quot;b&quot;, linewidth = &quot;1&quot;) 11、显示正方形的坐标区域 （1）plt.axis(&#39;square&#39;) 三、Scipy1、 Scipy特征 （1）内置了图像处理， 优化，统计等等相关问题的子模块 （2）scipy 是Python科学计算环境的核心。 它被设计为利用 numpy 数组进行高效的运行。从这个角度来讲，scipy和numpy是密不可分的。 2、文件操作io （1）导包：from scipy import io as spio （2）保存mat格式文件 spio.savemat(&quot;test.mat&quot;, {&#39;a&#39;:a}) （3）加载mat文件 data = spio.loadmat(&quot;test.mat&quot;) 访问值：data[‘a’]–&gt;相当于map （4）读取图片文件导包：from scipy import misc读取：data = misc.imread(&quot;123.png&quot;)[注1]：与matplotlib中plt.imread(&#39;fname.png&#39;)类似[注2]：执行misc.imread时可能提醒不存在这个模块，那就安装pillow的包 3、线性代数操作linalg （1）求行列式det res = linalg.det(a) （2）求逆矩阵inv res = linalg.inv(a) 若是矩阵不可逆，则会抛异常LinAlgError: singular matrix （3）奇异值分解svd u,s,v = linalg.svd(a) [注1]：s为a的特征值（一维），降序排列， [注2]：a = u*s*v’（需要将s转换一下才能相乘）12t = np.diag(s)print u.dot(t).dot(v) 4、梯度下降优化算法 （1）fmin_bfgs 1234def f(x): return x**2-2*xinitial_x = 0optimize.fmin_bfgs(f,initial_x) [注]：initial_x为初始点（此方法可能会得到局部最小值） （2）fmin()、fmin_cg等等方法 5、拟合（最小二乘法） （1）curve_fit123456789101112131415161718#产生数据def f(x): return x**2 + 10*np.sin(x)xdata = np.linspace(-10, 10, num=20)ydata = f(xdata)+np.random.randn(xdata.size)plt.scatter(xdata, ydata, linewidths=3.0, edgecolors=&quot;red&quot;)#plt.show()#拟合def f2(x,a,b): return a*x**2 + b*np.sin(x)guess = [2,2]params, params_covariance = optimize.curve_fit(f2, xdata, ydata, guess)#画出拟合的曲线x1 = np.linspace(-10,10,256)y1 = f2(x1,params[0],params[1])plt.plot(x1,y1)plt.show() 6、统计检验 （1）T-检验stats.ttest_ind123a = np.random.normal(0, 1, size=10)b = np.random.normal(1, 1, size=10)print stats.ttest_ind(a, b) 输出：(-2.6694785119868358, 0.015631342180817954)后面的是概率p: 两个过程相同的概率。如果其值接近1，那么两个过程几乎可以确定是相同的，如果其值接近0，那么它们很可能拥有不同的均值。 7、插值 （1）导入包：from scipy.interpolate import interp1d12345678910111213141516#产生一些数据x = np.linspace(0, 1, 10)y = np.sin(2 * np.pi * x)computed_time = np.linspace(0, 1, 50)#线性插值linear_interp = interp1d(x, y)linear_results = linear_interp(computed_time)#三次方插值cubic_interp = interp1d(x, y, kind=&apos;cubic&apos;)cubic_results = cubic_interp(computed_time)#作图plt.plot(x, y, &apos;o&apos;, ms=6, label=&apos;y&apos;)plt.plot(computed_time, linear_results, label=&apos;linear interp&apos;)plt.plot(computed_time, cubic_results, label=&apos;cubic interp&apos;)plt.legend()plt.show() 8、求解非线性方程组 （1）optimize中的fsolve1234567from scipy.optimize import fsolvedef func(x): x0,x1,x2 = x.tolist() return [5*x1-25,5*x0*x0-x1*x2,x2*x0-27]initial_x = [1,1,1]result = fsolve(func, initial_x)print result 四、pandas1、pandas特征与导入 （1）包含高级的数据结构和精巧的工具 （2）pandas建造在NumPy之上 （3）导入：12from pandas import Series, DataFrameimport pandas as pd 2、pandas数据结构（1）Series 一维的类似的数组对象 包含一个数组的数据（任何NumPy的数据类型）和一个与数组关联的索引 不指定索引：a = Series([1,2,3]) ，输出为 1230 11 22 3 包含属性a.index,a.values，对应索引和值 指定索引：a = Series([1,2,3],index=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;])可以通过索引访问a[&#39;b&#39;] 判断某个索引是否存在：&#39;b&#39; in a 通过字典建立Series12dict = &#123;&apos;china&apos;:10,&apos;america&apos;:30,&apos;indian&apos;:20&#125;print Series(dict) 输出：1234america 30china 10indian 20dtype: int64 判断哪个索引值缺失：1234dict = &#123;&apos;china&apos;:10,&apos;america&apos;:30,&apos;indian&apos;:20&#125;state = [&apos;china&apos;,&apos;america&apos;,&apos;test&apos;]a = Series(dict,state)print a.isnull() 输出：（test索引没有对应值）1234china Falseamerica Falsetest Truedtype: bool 在算术运算中它会自动对齐不同索引的数据123a = Series([10,20],[&apos;china&apos;,&apos;test&apos;])b = Series([10,20],[&apos;test&apos;,&apos;china&apos;])print a+b 输出：123china 30test 30dtype: int64 指定Series对象的name和index的name属性1234a = Series([10,20],[&apos;china&apos;,&apos;test&apos;])a.index.name = &apos;state&apos;a.name = &apos;number&apos;print a 输出：1234statechina 10test 20Name: number, dtype: int64 （2）DataFrame Datarame表示一个表格，类似电子表格的数据结构 包含一个经过排序的列表集（按列名排序） 每一个都可以有不同的类型值（数字，字符串，布尔等等） DataFrame在内部把数据存储为一个二维数组的格式，因此你可以采用分层索引以表格格式来表示高维的数据 创建： 通过字典12345data = &#123;&apos;state&apos;: [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;d&apos;], &apos;year&apos;: [2000, 2001, 2002, 2001, 2002], &apos;pop&apos;: [1.5, 1.7, 3.6, 2.4, 2.9]&#125;frame = DataFrame(data)print frame 输出：(按照列名排好序的[若是手动分配列名，会按照你设定的]，并且索引会自动分配) 123456 pop state year0 1.5 a 20001 1.7 b 20012 3.6 c 20023 2.4 d 20014 2.9 d 2002 访问 列：与Series一样，通过列名访问：frame[&#39;state&#39;]或者frame.state 行：ix 索引成员（field），frame.ix[2]，返回每一列的第3行数据 赋值：frame2[&#39;debt&#39;] = np.arange(5.)，若没有debt列名，则会新增一列 删除某一列：del frame2[&#39;eastern&#39;] 像Series一样， values 属性返回一个包含在DataFrame中的数据的二维ndarray 返回所有的列信息：frame.columns 转置：frame2.T （3）索引对象 pandas的索引对象用来保存坐标轴标签和其它元数据（如坐标轴名或名称） 索引对象是不可变的，因此不能由用户改变 创建index = pd.Index([1,2,3]) 常用操作 append–&gt;链接额外的索引对象，产生一个新的索引 diff –&gt;计算索引的差集 intersection –&gt;计算交集 union –&gt;计算并集 isin –&gt;计算出一个布尔数组表示每一个值是否包含在所传递的集合里 delete –&gt;计算删除位置i的元素的索引 drop –&gt;计算删除所传递的值后的索引 insert –&gt;计算在位置i插入元素后的索引 is_monotonic –&gt;返回True，如果每一个元素都比它前面的元素大或相等 is_unique –&gt;返回True，如果索引没有重复的值 unique –&gt;计算索引的唯一值数组 3、重新索引reindex（1）Series （1）重新排列 123a = Series([2,3,1],index=[&apos;b&apos;,&apos;a&apos;,&apos;c&apos;])b = a.reindex([&apos;a&apos;,&apos;b&apos;,&apos;c&apos;])print b （2）重新排列，没有的索引补充为0,b=a.reindex([&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;],fill_value=0) （3）重建索引时对值进行内插或填充123a = Series([&apos;a&apos;,&apos;b&apos;,&apos;c&apos;],index=[0,2,4])b = a.reindex(range(6),method=&apos;ffill&apos;)print b 输出：12345670 a1 a2 b3 b4 c5 cdata_linkdtype: object method的参数ffill或pad—-&gt;前向（或进位）填充bfill或backfill—-&gt;后向（或进位）填充 （3）DataFrame 与Series一样，reindex index 还可以reindex column列，frame.reindex(columns=[&#39;a&#39;,&#39;b&#39;]) 4、从一个坐标轴删除条目（1）Series a.drop([&#39;a&#39;,&#39;b&#39;]) 删除a，b索引项（2）DataFrame 索引项的删除与Series一样 删除column—&gt;a.drop([&#39;one&#39;], axis=1) 删除column名为one的一列 5、索引，挑选和过滤（1）Series 可以通过index值或者整数值来访问数据，eg：对于a = Series(np.arange(4.), index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])，a[&#39;b&#39;]和a[1]是一样的 使用标签来切片和正常的Python切片并不一样，它会把结束点也包括在内12a = Series(np.arange(4.), index=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])print a[&apos;b&apos;:&apos;c&apos;] 输出包含c索引对应的值 （2）DataFrame 显示前两行：a[:2] 布尔值访问：a[a[&#39;two&#39;]&gt;5] 索引字段 ix 的使用 index为2，column为’one’和’two’—&gt;a.ix[[2],[&#39;one&#39;,&#39;two&#39;]] index为2的一行：a.ix[2] 6、DataFrame和Series运算 （1）DataFrame每一行都减去一个Series12345a = pd.DataFrame(np.arange(16).reshape(4,4),index=[0,1,2,3],columns=[&apos;one&apos;, &apos;two&apos;,&apos;three&apos;,&apos;four&apos;])print ab = Series([0,1,2,3],index=[&apos;one&apos;,&apos;two&apos;,&apos;three&apos;,&apos;four&apos;])print bprint a-b 输出：123456789101112131415 one two three four0 0 1 2 31 4 5 6 72 8 9 10 113 12 13 14 15one 0two 1three 2four 3dtype: int64 one two three four0 0 0 0 01 4 4 4 42 8 8 8 83 12 12 12 12 7、读取文件 （1）csv文件pd.read_csv(r&quot;data/train.csv&quot;)，返回的数据类型是DataFrame类型 8、查看DataFrame的信息 （1）train_data.describe()eg:123456789 PassengerId Survived Pclass Age SibSp \\count 891.000000 891.000000 891.000000 714.000000 891.000000 mean 446.000000 0.383838 2.308642 29.699118 0.523008 std 257.353842 0.486592 0.836071 14.526497 1.102743 min 1.000000 0.000000 1.000000 0.420000 0.000000 25% 223.500000 0.000000 2.000000 20.125000 0.000000 50% 446.000000 0.000000 3.000000 28.000000 0.000000 75% 668.500000 1.000000 3.000000 38.000000 1.000000 max 891.000000 1.000000 3.000000 80.000000 8.000000 9、定位到一列并替换 df.loc[df.Age.isnull(),&#39;Age&#39;] = 23 #&#39;Age&#39;列为空的内容补上数字23 10、将分类变量转化为指示变量get_dummies() 12s = pd.Series(list(&apos;abca&apos;))pd.get_dummies(s) 12345 a b c0 1 0 01 0 1 02 0 0 13 1 0 0 11、list和string互相转化 string转list 1234&gt;&gt;&gt; str = &apos;abcde&apos;&gt;&gt;&gt; list = list(str)&gt;&gt;&gt; list[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;] list转string 123&gt;&gt;&gt; str_convert = &apos;,&apos;.join(list)&gt;&gt;&gt; str_convert&apos;a,b,c,d,e&apos; 12、删除原来的索引，重新从0-n索引 x = x.reset_index(drop=True) 13、apply函数 DataFrame.apply(func, axis=0, broadcast=False, raw=False, reduce=None, ….. df.apply(numpy.sqrt) # returns DataFrame 等价==》df.apply(lambda x : numpy.sqrt(x))==&gt;使用更灵活 df.apply(numpy.sum, axis=0) # equiv to df.sum(0) df.apply(numpy.sum, axis=1) # equiv to df.sum(1) 13、re.search().group()函数 re.search(pattern, string, flags=0) group(num=0)函数返回匹配的字符，默认num=0,可以指定多个组号，例如group(0,1) 14、pandas.cut()函数 pandas.cut(x, bins, right=True, labels=None, retbins=False, precision=3, include_lowest=False) x为以为数组 bins可以是int值或者序列 若是int值就根据x分为bins个数的区间 若是序列就是自己指定的区间 right包含最右边的区间，默认为True labels 数组或者一个布尔值 若是数组，需要与对应bins的结果一致 若是布尔值False，返回bin中的一个值 eg:pd.cut(full[“FamilySize”], bins=[0,1,4,20], labels=[0,1,2]) 15、添加一行数据 定义空的dataframe: data_process = pd.DataFrame(columns=[&#39;route&#39;,&#39;date&#39;,&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;5&#39;,&#39;6&#39;,&#39;7&#39;,&#39;8&#39;,&#39;9&#39;,&#39;10&#39;,&#39;11&#39;,&#39;12&#39;]) 定义一行新的数据，new = pd.DataFrame(columns=[&#39;route&#39;,&#39;date&#39;,&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;5&#39;,&#39;6&#39;,&#39;7&#39;,&#39;8&#39;,&#39;9&#39;,&#39;10&#39;,&#39;11&#39;,&#39;12&#39;],index=[j]) 这里index可以随意设置，若是想指定就指定 添加：data_process = data_process.append(new, ignore_index=True)， 注意这里是data_process = data_process....... 五、scikit-learn1、手写数字识别（SVM）1234567891011121314151617181920212223242526272829from sklearn import datasetsfrom sklearn import svmimport numpy as npfrom matplotlib import pyplot as plt&apos;&apos;&apos;使用sciki-learn中的数据集，一般有data,target,DESCR等属性属性&apos;&apos;&apos;digits = datasets.load_digits() #加载scikit-learn中的数据集clf = svm.SVC(gamma=0.001,C=100) #使用支持向量机进行分类，gamma为核函数的系数clf.fit(digits.data[:-4],digits.target[:-4]) #将除最后4组的数据输入进行训练predict = clf.predict(digits.data[-4:]) #预测最后4组的数据，[-4:]表示最后4行所有数据，而[-4,:]表示倒数第4行数据print &quot;预测值为：&quot;,predictprint &quot;真实值：&quot;,digits.target[-4:]#显示最后四个图像plt.subplot(2,2,1)plt.imshow(digits.data[-4,:].reshape(8,8))plt.subplot(2,2,2)plt.imshow(digits.data[-3,:].reshape(8,8))plt.subplot(2,2,3)plt.imshow(digits.data[-2,:].reshape(8,8))plt.subplot(2,2,4)plt.imshow(digits.data[-1,:].reshape(8,8))plt.show() svm的参数参数解释： （1）C: 目标函数的惩罚系数C，用来平衡分类间隔margin和错分样本的，default C = 1.0； （2）kernel：参数选择有RBF, Linear, Poly, Sigmoid, 默认的是”RBF”; （3）degree：if you choose ‘Poly’ in param 2, this is effective, degree决定了多项式的最高次幂； （4）gamma：核函数的系数(‘Poly’, ‘RBF’ and ‘Sigmoid’), 默认是gamma = 1 / n_features; （5）coef0：核函数中的独立项，’RBF’ and ‘Poly’有效； （6）probablity: 可能性估计是否使用(true or false)； （7）shrinking：是否进行启发式； （8）tol（default = 1e - 3）: svm结束标准的精度; （9）cache_size: 制定训练所需要的内存（以MB为单位）； （10）class_weight:每个类所占据的权重，不同的类设置不同的惩罚参数C,缺省的话自适应； （11）verbose: 跟多线程有关，不大明白啥意思具体； （12）max_iter: 最大迭代次数，default = 1000， if max_iter = -1, no limited; （13）decision_function_shape ： ‘ovo’ 一对一, ‘ovr’ 多对多 or None 无, default=None （14）random_state ：用于概率估计的数据重排时的伪随机数生成器的种子。 2、保存训练过的模型 from sklearn.externals import joblib joblib.dump(clf, &quot;digits.pkl&quot;) #将训练的模型保存成digits.pkl文件 加载模型：clf = joblib.load(&quot;digits.pkl&quot;)其余操作数据即可，预测 3、鸢尾花分类（svm，分离出测试集）1234567891011121314151617181920from sklearn import datasetsfrom sklearn.cross_validation import train_test_splitfrom sklearn.svm import SVCimport numpy as np&apos;&apos;&apos;加载scikit-learn中的鸢尾花数据集&apos;&apos;&apos;#加载鸢尾花数据集iris = datasets.load_iris()iris_data = iris.data; #相当于Xiris_target = iris.target; #对应的label种类，相当于yx_train,x_test,y_train,y_test = train_test_split(iris_data,iris_target,test_size=0.2) #将数据分成训练集x_train和测试集x_test，测试集占总数据的0.2model = SVC().fit(x_train,y_train); #使用svm在训练集上拟合predict = model.predict(x_test) #在测试集上预测right = sum(predict == y_test) #求预测正确的个数print (&apos;测试集准确率：%f%%&apos;%(right*100.0/predict.shape[0])) #求在测试集上预测的正确率，shape[0]返回第一维的长度，即数据个数 [另：留一验证法]：–&gt;每次取一条数据作为测试集，其余作为训练集123456789101112131415161718192021222324from sklearn import datasetsfrom sklearn.svm import SVCimport numpy as npdef data_svc_test(data,target,index): x_train = np.vstack((data[0:index],data[index+1:-1]))#除第index号之外的 数据为训练集 x_test = data[index].reshape(1,-1) #第index号数据为测试集，reshape(1,-1)的作用是只有一条数据时，使用reshap e(1,-1)，否则有个过时方法的警告 y_train = np.hstack((target[0:index],target[index+1:-1])) y_test = target[index] model = SVC().fit(x_train,y_train) #建立SVC模型 predict = model.predict(x_test) return predict == y_test #返回结果是否预测正确#读取数据iris = datasets.load_iris()iris_data = iris.datairis_target = iris.targetm = iris_target.shape[0]right = 0;for i in range(0,m): right += data_svc_test(iris_data,iris_target,i)print (&quot;%f%%&quot;%(right*100.0/m)) 4、房价预测(SVR–&gt;支持向量回归)1234567891011121314151617181920212223from sklearn import datasetsfrom sklearn.svm import SVR #引入支持向量回归所需的SVR模型from sklearn.cross_validation import train_test_splitfrom sklearn.preprocessing import StandardScalerimport numpy as np#加载数据house_dataset = datasets.load_boston()house_data = house_dataset.datahouse_price = house_dataset.target#数据预处理--&gt;归一化x_train,x_test,y_train,y_test = train_test_split(house_data,house_price,test_size=0.2) scaler = StandardScaler()scaler.fit(x_train)x_train = scaler.transform(x_train) #训练集x_test = scaler.transform(x_test) #测试集#回归，预测model = SVR().fit(x_train,y_train) #使用SVR回归拟合predict = model.predict(x_test) #预测result = np.hstack((y_test.reshape(-1,1),predict.reshape(-1,1))) #reshape(-1,1)所有行转为1列向量print(result) 六、sk-learn模型总结0、数据处理（1）均值归一化：from sklearn.preprocessing import StandardScaler scaler = StandardScaler() scaler.fit(X_train) X_train = scaler.transform(X_train) （2）分割数据：from sklearn.cross_validation import train_test_split x_train,x_test,y_train,y_test = train_test_split(iris_data,iris_target,test_size=0.2) 1、线性模型from sklearn import linear_model（1）逻辑回归模型 linear_model.LogisticRegression() 重要参数 C：正则化作用，默认值1.0，值越小，正则化作用越强 max_iter：最大梯度下降执行次数，默认值100 tol：停止执行的容忍度，默认值1e-4 重要返回值 coef_：对应feature的系数 2、svm模型from sklearn import svm（1）分类模型 svm.SVC() 重要参数 kernel：使用的核函数，默认是rbf径向基函数，还有linear，poly，sigmoid ，precomputed核函数 C：正则化作用，默认值1.0，值越大，margin越大 tol：停止执行的容忍度，默认值1e-4 gamma：为核函数的系数，值越大拟合的越好，默认是1/feature的个数 degree：对应poly核函数 重要返回值","comments":true,"tags":[{"name":"Python","slug":"Python","permalink":"http://lawlite.cn/tags/Python/"},{"name":"机器学习","slug":"机器学习","permalink":"http://lawlite.cn/tags/机器学习/"}]},{"title":"搭建自己的VPN","date":"2016-11-05T09:33:50.000Z","path":"2016/11/05/搭建自己的VPN/","text":"一、首先租一个服务器 1、租一个香港的服务器，这里我选的按量付费，如果不使用了释放就可以了，按小时收费的，不过要求你账户上要多于100块钱。 2、操作系统选择的64位CentOS6.5，CentOS7以上下面的命令会有所不同。 3、创建成功后管理控制台会有公网和私网两个ip地址 二、配置VPN 1、安装ppp和pptpd: 1yum install ppp pptpd 2、配置DNS/etc/ppp/options.pptpd文件中的ms-dns配置为： 12ms-dns 8.8.8.8ms-dns 8.8.4.4 3、配置IP/etc/pptpd.conf文件中最后加入： 12localip 192.168.0.1remoteip 192.168.0.2-254 4、配置VPN用户名和密码/etc/ppp/chap-secrets文件中加入： 1userName pptpd password * 就是userName位置写上你的用户名，password位置写上你的密码 5、配置IP转发/etc/sysctl.conf文件中net.ipv4.ip_forward = 0改为1net.ipv4.ip_forward = 1 然后执行：sysctl -p使其生效 三、配置防火墙 1、加入防火墙规则 123iptables -A INPUT -p TCP -i eth1 --dport 1723 --sport 1024:65534 -j ACCEPTiptables -t nat -A POSTROUTING -o eth1 -s 192.168.0.0/24 -j MASQUERADEiptables -I FORWARD -p tcp --syn -i ppp+ -j TCPMSS --set-mss 1356 注意这里指定的网卡是eth1，其对应外网的网卡，否则能够连上VPN，但是是访问不了外网的。 VPN默认的端口是1723 2、保存防火墙配置，启动pptpd，让其开机自启动 1234service iptables saveservice iptables restartservice pptpd start chkconfig pptpd on 四、测试1、window或手机等连接 对应外网IP，设置的用户名和密码 速度是可以的， 我也测试了一下国外的服务器，速度非常慢，还不如免费的VPN软件， 五、shell脚本 1、我写了一个简单的shell脚本放在了github上，github地址：https://github.com/lawlite19/Script 2、运行步骤如下： 下载脚本：wget https://raw.githubusercontent.com/lawlite19/Script/master/shell/vpn_setup.sh 添加执行权限：chmod +x vpn_setup.sh 执行即可：./vpn_setup.sh3、完整代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106#!/bin/bash# Author: Wang Yongzhi(bob)# Date: 2016.11.16echo -e &quot;-----------------------------------------------&quot;echo -e &quot;| Setup VPN... |&quot;echo -e &quot;-----------------------------------------------\\n&quot;# Step 1:install ppp and pptpdyum install -y pppyum install -y pptpdif [ $? -eq 0 ]then echo -e &quot;install ppp and pptpd Success!\\n&quot;else echo -e &quot;Sorry! install ppp and pptpd Failed!\\n&quot; exit 0fi# Step 2:configure pptpd DNSsed -i -e &apos;/#ms-dns 10.0.0.1/a\\ms-dns 8.8.8.8&apos; /etc/ppp/options.pptpdsed -i -e &apos;/#ms-dns 10.0.0.2/a\\ms-dns 8.8.4.4&apos; /etc/ppp/options.pptpdif [ $? -eq 0 ]then echo -e &quot;Configure DNS Success!\\n&quot;else echo -e &quot;Configure DNS Failed!\\n&quot; exit 0fi# Step 3:configure pptpd IPecho localip 192.168.0.1 &gt;&gt; /etc/pptpd.confecho remoteip 192.168.0.2-254 &gt;&gt; /etc/pptpd.confif [ $? -eq 0 ]then echo -e &quot;Configure pptpd IP Success!\\n&quot;else echo -e &quot;Configure pptpd IP Failed!\\n&quot; exit 0fi# Step 4: configure VPN userName and passwordwhile truedo read -p &quot;Please input userName:&quot; userName read -p &quot;Please input passwd: &quot; Passwd echo $userName pptpd $Passwd \\* &gt;&gt; /etc/ppp/chap-secrets read -p &quot;continue?y/N: &quot; flag if [ $flag = &quot;n&quot; -o $flag = &quot;N&quot; ] then break fidone# Step 5: configure forwardingsed -i &apos;s/net.ipv4.ip_forward = 0/net.ipv4.ip_forward = 1/g&apos; /etc/sysctl.confif [ $? -eq 0 ]then echo -e &quot;Configure forwarding Success!\\n&quot;else echo -e &quot;Configure forwarding Failed\\n&quot; exit 0fisysctl -p# Step 6: configure iptables#EXTIF=$(ifconfig | head -n 1 | grep -v lo | cut -d &apos; &apos; -f 1)iptables -A INPUT -p TCP -i eth1 --dport 1723 --sport 1024:65534 -j ACCEPTiptables -t nat -A POSTROUTING -o eth1 -s 192.168.0.0/24 -j MASQUERADEiptables -I FORWARD -p tcp --syn -i ppp+ -j TCPMSS --set-mss 1356# Step 7: configure when start server to start pptpd and iptablesservice iptables saveservice iptables restartservice pptpd start chkconfig pptpd onecho -e &quot;Complete! Now you can connect the VPN throuth your computer or phone!\\n&quot;echo &quot; ***** *****&quot;echo &quot; ********* *********&quot;echo &quot; ************* *************&quot;echo &quot; *****************************&quot;echo &quot; *****************************&quot;echo &quot; *****************************&quot;echo &quot; ***************************&quot;echo &quot; ***********************&quot;echo &quot; *******************&quot;echo &quot; ***************&quot;echo &quot; ***********&quot;echo &quot; *******&quot;echo &quot; ***&quot;echo &quot; *&quot; 六、总结 最初是在租了一个国外的服务器测试的，没有问题，但是后来租用香港的服务器就出现的了错误，同样的系统、同样的配置，后来查看内网绑定的是网卡eth0,外网绑定的是网卡eth1，而我防火墙里设置的是内网的网卡eth0。而国外的那个服务器只要一个网卡，所以没有问题。另外练练shell脚本。","comments":true,"tags":[{"name":"翻墙","slug":"翻墙","permalink":"http://lawlite.cn/tags/翻墙/"}]},{"title":"Scrapy爬虫框架模板","date":"2016-10-09T05:42:56.000Z","path":"2016/10/09/Python爬虫-Scrapy/","text":"说明 github地址：https://github.com/lawlite19/PythonCrawler-Scrapy-Mysql-File-Template 使用scrapy爬虫框架将数据保存Mysql数据库和文件中 settings.py 修改Mysql的配置信息 1234567#Mysql数据库的配置信息MYSQL_HOST = '127.0.0.1'MYSQL_DBNAME = 'testdb' #数据库名字，请修改MYSQL_USER = 'root' #数据库账号，请修改 MYSQL_PASSWD = '123456' #数据库密码，请修改MYSQL_PORT = 3306 #数据库端口，在dbhelper中使用 指定pipelines 1234ITEM_PIPELINES = &#123; 'webCrawler_scrapy.pipelines.WebcrawlerScrapyPipeline': 300,#保存到mysql数据库 'webCrawler_scrapy.pipelines.JsonWithEncodingPipeline': 300,#保存到文件中&#125; items.py 声明需要格式化处理的字段 123456class WebcrawlerScrapyItem(scrapy.Item): '''定义需要格式化的内容（或是需要保存到数据库的字段）''' # define the fields for your item here like: # name = scrapy.Field() name = scrapy.Field() #修改你所需要的字段 url = scrapy.Field() pipelines.py一、保存到数据库的类WebcrawlerScrapyPipeline（在settings中声明） 定义一个类方法from_settings，得到settings中的Mysql数据库配置信息，得到数据库连接池dbpool 12345678910111213141516@classmethoddef from_settings(cls,settings): '''1、@classmethod声明一个类方法，而对于平常我们见到的则叫做实例方法。 2、类方法的第一个参数cls（class的缩写，指这个类本身），而实例方法的第一个参数是self，表示该类的一个实例 3、可以通过类来调用，就像C.f()，相当于java中的静态方法''' dbparams=dict( host=settings['MYSQL_HOST'],#读取settings中的配置 db=settings['MYSQL_DBNAME'], user=settings['MYSQL_USER'], passwd=settings['MYSQL_PASSWD'], charset='utf8',#编码要加上，否则可能出现中文乱码问题 cursorclass=MySQLdb.cursors.DictCursor, use_unicode=False, ) dbpool=adbapi.ConnectionPool('MySQLdb',**dbparams)#**表示将字典扩展为关键字参数,相当于host=xxx,db=yyy.... return cls(dbpool)#相当于dbpool付给了这个类，self中可以得到 __init__中会得到连接池dbpool 12def __init__(self,dbpool): self.dbpool=dbpool process_item方法是pipeline默认调用的，进行数据库操作 12345#pipeline默认调用def process_item(self, item, spider): query=self.dbpool.runInteraction(self._conditional_insert,item)#调用插入的方法 query.addErrback(self._handle_error,item,spider)#调用异常处理方法 return item 插入数据库方法_conditional_insert 123456#写入数据库中def _conditional_insert(self,tx,item): #print item['name'] sql=\"insert into testpictures(name,url) values(%s,%s)\" params=(item[\"name\"],item[\"url\"]) tx.execute(sql,params) 错误处理方法_handle_error 123#错误处理方法def _handle_error(self, failue, item, spider): print failue 二、保存到文件中的类JsonWithEncodingPipeline（在settings中声明） 保存为json格式的文件，比较简单，代码如下 123456789101112class JsonWithEncodingPipeline(object): '''保存到文件中对应的class 1、在settings.py文件中配置 2、在自己实现的爬虫类中yield item,会自动执行''' def __init__(self): self.file = codecs.open('info.json', 'w', encoding='utf-8')#保存为json文件 def process_item(self, item, spider): line = json.dumps(dict(item)) + \"\\n\"#转为json的 self.file.write(line)#写入文件中 return item def spider_closed(self, spider):#爬虫结束时关闭文件 self.file.close() dbhelper.py 自己实现的操作Mysql数据库的类 init方法，获取settings配置文件中的信息 12345678def __init__(self): self.settings=get_project_settings() #获取settings配置，设置需要的信息 self.host=self.settings['MYSQL_HOST'] self.port=self.settings['MYSQL_PORT'] self.user=self.settings['MYSQL_USER'] self.passwd=self.settings['MYSQL_PASSWD'] self.db=self.settings['MYSQL_DBNAME'] 连接到Mysql 123456789#连接到mysql，不是连接到具体的数据库def connectMysql(self): conn=MySQLdb.connect(host=self.host, port=self.port, user=self.user, passwd=self.passwd, #db=self.db,不指定数据库名 charset='utf8') #要指定编码，否则中文可能乱码 return conn 连接到settings配置文件中的数据库名（MYSQL_DBNAME） 123456789#连接到具体的数据库（settings中设置的MYSQL_DBNAME）def connectDatabase(self): conn=MySQLdb.connect(host=self.host, port=self.port, user=self.user, passwd=self.passwd, db=self.db, charset='utf8') #要指定编码，否则中文可能乱码 return conn 创建数据库（settings文件中配置的数据库名） 12345678910#创建数据库def createDatabase(self): '''因为创建数据库直接修改settings中的配置MYSQL_DBNAME即可，所以就不要传sql语句了''' conn=self.connectMysql()#连接数据库 sql=\"create database if not exists \"+self.db cur=conn.cursor() cur.execute(sql)#执行sql语句 cur.close() conn.close() 还有一些数据库操作方法传入sql语句和参数即可（具体看代码） 实现具体的爬虫.py（即模板中的pictureSpider_demo.py文件） 继承scrapy.spiders.Spider 类 声明三个属性 12345name=\"webCrawler_scrapy\" #定义爬虫名，要和settings中的BOT_NAME属性对应的值一致allowed_domains=[\"desk.zol.com.cn\"] #搜索的域名范围，也就是爬虫的约束区域，规定爬虫只爬取这个域名下的网页start_urls=[\"http://desk.zol.com.cn/fengjing/1920x1080/1.html\"] #开始爬取的地址 实现parse方法，该函数名不能改变，因为Scrapy源码中默认callback函数的函数名就是parse 1def parse(self, response): 返回item 123456item=WebcrawlerScrapyItem() #实例item（具体定义的item类）,将要保存的值放到事先声明的item属性中item['name']=file_name item['url']=realUrlprint item[\"name\"],item[\"url\"] yield item #返回item,这时会自定解析item 测试 测试DBHelper创建testdb数据库和testtable表 测试爬虫 在D盘建立文件夹pics; 图片自动保存到该文件夹中。 scrapy crawl webCrawler_scrapy运行爬虫后会将爬取得图片保存到本地，并且将name和url保存到数据库中","comments":true,"tags":[{"name":"Python","slug":"Python","permalink":"http://lawlite.cn/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://lawlite.cn/tags/爬虫/"}]},{"title":"算法练习","date":"2016-09-09T05:35:45.000Z","path":"2016/09/09/算法练习/","text":"说明 github地址：https://github.com/lawlite19/AlgorithmExercises一、 排序算法1. 交换排序 冒泡排序 冒泡排序改进1 冒泡排序改进2 冒泡排序改进3 快速排序 2. 插入排序 直接插入排序 直接插入排序递归版 希尔排序 3. 选择排序 简单选择排序 二元选择排序 堆排序 4. 归并排序 二路归并排序递归版 二路归并排序非递归版 二、 字符串1. 字符串旋转 字符串旋转_暴力法 字符串旋转_三步翻转法 2. 字符串包含 字符串包含判断_遍历 字符串包含判断_排序 字符串包含判断_素数乘积 字符串包含判断_哈希 ★★★ 3. 回文 回文判断 4. 最长回文子串长度 最长回文子串长度_一般解法 最长回文子串长度_Manacher ★★★ 算法说明 5. 全排列 全排列_递归 全排列_字典序排列 字典序全排列 6. 变形词 变形词判断 7. 字符串中数字串之和 字符串中数字串之和 ★ 8. 去除字符串中连续K个0串 去除字符串中连续K个0串 9. 整数字符串转整数值 整数字符串转整数值 ★★ 10. 字符串匹配问题 字符串匹配_KMP ★★★★★ 算法说明 三、 数组和矩阵1. 二维数组查找 二维数组查找 2. 矩阵相关操作 转圈打印矩阵 3. 最小的k个元素 最小的k个元素_堆 最小的k个元素_BFPRT ★★★★★ 算法说明 4.中间数 中间数_辅助数组 ★ 5.非负数组和为K的最长子数组 非负数组和为K的最长子数组_双指针 ★★★ 8.次数出现大于N/K的数 次数出现大于N/2的数 ★ 次数出现大于N/K的数 ★★★ 9.逆序对 逆序对数_分治归并★ 10.两个有序数组的中位数 两个有序数组的中位数_分治★★★★ 算法说明 四、 递归和动态规划1. 斐波那契问题 矩形覆盖_递归 矩形覆盖_dp ★ 矩阵覆盖_矩阵转化_class实现 ★★★ 矩阵覆盖_矩阵转化_vector实现 ★★★ 算法说明 爬楼梯_递归 爬楼梯_dp ★ 变态跳台阶_递归 变态跳台阶_直接计算 ★ 2. 最大子数组和相关问题 最大子数组和_dp ★ 两个不相容子数组最大和_辅助数组 ★★ 3. 最长递增子序列相关问题 最长递增子序列_一般dp 最长递增子序列_dp优化 ★★ 摞数组问题(俄国沙皇问题)_纯代码实现 ★★★★ 摞数组问题（俄国沙皇问题）_借助stl ★★★★ 五、 栈和队列1. getMin功能栈 getMin功能栈_方案1 getMin功能栈_方案2 2. 两个栈实现队列功能 两个栈实现队列 七、二叉树1. 遍历 先、中、后序遍历_递归 先、中、后序遍历_非递归 ★★ 八、位运算 出现奇数次的数","comments":true,"tags":[{"name":"算法","slug":"算法","permalink":"http://lawlite.cn/tags/算法/"}]},{"title":"非极大值抑制","date":"1018-11-20T03:19:08.000Z","path":"1018/11/20/非极大值抑制/","text":"一、","comments":true,"tags":[{"name":"ObjectDetection","slug":"ObjectDetection","permalink":"http://lawlite.cn/tags/ObjectDetection/"}]}]